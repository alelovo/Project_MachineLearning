{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r df_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# package that we need\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.metrics import MeanAbsolutePercentageError\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay,accuracy_score, precision_score, recall_score,f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# essential\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "#correlation\n",
    "import seaborn as sns\n",
    "\n",
    "#! pip install pydot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE AND TARGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = [\n",
    "    'spotify_track_duration_minute', 'danceability', 'energy', 'loudness',\n",
    "    'mode', 'speechiness', 'acousticness',\n",
    "    'spotify_track_popularity', 'instrumentalness', 'liveness']\n",
    "\n",
    "genre_features = [col for col in df_one_hot.columns if col.startswith('genre_')]\n",
    "\n",
    "# UNION OF THE TWO \n",
    "total_features = numerical_features + genre_features\n",
    "\n",
    "target='valence'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOT\n",
    "\n",
    "interesting plots for visualize the output of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_for_model(history):\n",
    "\n",
    "    #plot loss\n",
    "    plt.figure()\n",
    "    plt.plot(history.history['loss'],color='blue',label='loss')\n",
    "    plt.plot(history.history['val_loss'],color='red',label='val_loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss function through epoch')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    #plot mean\n",
    "    plt.figure()\n",
    "    plt.plot(history.history['mae'],color='blue',label='mae')\n",
    "    plt.plot(history.history['val_mae'],color='red',label='val_mae')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('mae')\n",
    "    plt.title('Mae function through epoch')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPLIT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_train_test_for_cross(train_index, test_index, df):\n",
    "    #extract the feature and target\n",
    "    x = df[total_features]\n",
    "    y = df[target]\n",
    "\n",
    "    #normalization\n",
    "    scaler = StandardScaler()\n",
    "    x[numerical_features] = scaler.fit_transform(x[numerical_features])\n",
    "    #display(x)\n",
    "\n",
    "    x_train, x_test = x.iloc[train_index], x.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    #display(x_train)\n",
    "\n",
    "    return x_train,x_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create the model\n",
    "def create_model_user(shape_x_train): #number of columns -> shape\n",
    "    \n",
    "    \n",
    "    '''model_user_i = Sequential([\n",
    "        Dense(32, input_dim=shape_x_train, activation='relu', name='first_layer'),\n",
    "        Dense(16, activation='relu', name='secod_layer'),\n",
    "        Dense(1, activation='sigmoid', name='final_layer')\n",
    "    ])'''\n",
    "\n",
    "    model_user_i = Sequential([\n",
    "        \n",
    "        Dense(32,input_dim=shape_x_train,activation='relu',name='first_layer',kernel_regularizer=l2(0.01)),\n",
    "        Dropout(0.3),\n",
    "        Dense(16,activation='relu',name='secod_layer',kernel_regularizer=l2(0.01)),\n",
    "        Dropout(0.2),\n",
    "        #Dense(1,activation='linear',name='final_layer')\n",
    "        Dense(1,activation='sigmoid',name='final_layer') \n",
    "    ])\n",
    "\n",
    "    #compile the model\n",
    "    model_user_i.compile(optimizer = 'adam', loss = 'mse', metrics = ['mae'])\n",
    "\n",
    "    #summary\n",
    "    #display(model_user_i.summary())\n",
    "\n",
    "    #return  the model\n",
    "    return model_user_i\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIT MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to train the model\n",
    "def fit_model(model, x_train, y_train, x_test, y_test):\n",
    "\n",
    "    history_model = model.fit(\n",
    "        x_train,y_train,\n",
    "        validation_data = [x_test, y_test],\n",
    "        #epochs = 1,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        #verbose=1\n",
    "    )\n",
    "\n",
    "    return history_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RECOMANDATION FUNCTION + CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reco_function_conf_matrix(y_test, y_hat, threshold):\n",
    "    \n",
    "    #initialize dataframe    \n",
    "    data = {'Original Test': y_test,\n",
    "        'Prediction Test': y_hat.flatten(),\n",
    "        }\n",
    "    df_prediction = pd.DataFrame(data = data)\n",
    "    df_prediction['Original over Thrashold'] = df_prediction['Original Test'] > threshold\n",
    "    df_prediction['Predicted over Thrashold'] = df_prediction['Prediction Test'] > threshold\n",
    "    #display(df_prediction)\n",
    "\n",
    "    #plot confusion matrix of reccomandation\n",
    "    cm = confusion_matrix(df_prediction['Original over Thrashold'], df_prediction['Predicted over Thrashold'])\n",
    "\n",
    "    # METRIX FOR EVALUATE RECCOMANDATION \n",
    "    # Extract TP, TN, FP, FN\n",
    "    TN, FP, FN, TP = cm.ravel()\n",
    "\n",
    "    # Calculate metrics manually\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    '''plt.figure()\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['True', 'False'], yticklabels=['True', 'False'])\n",
    "    plt.title('Confiusion matrix')\n",
    "    plt.xlabel('predicted')\n",
    "    plt.ylabel('actual')\n",
    "    plt.show()'''\n",
    "\n",
    "    # Store metrics in a DataFrame\n",
    "    df_metrics_cm = pd.DataFrame(\n",
    "        data =\n",
    "        #'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-score'],\n",
    "        {'Value': [accuracy, precision, recall, f1]},\n",
    "        index = ['Accuracy', 'Precision', 'Recall', 'F1-score']\n",
    "    )\n",
    "\n",
    "    #display(df_metrics_cm.round(2))\n",
    "\n",
    "    return df_prediction,df_metrics_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "USER 0\n",
      "---------------------------------------------------------\n",
      "K 0 FOLD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elped\\AppData\\Local\\Temp\\ipykernel_15892\\330544952.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[numerical_features] = scaler.fit_transform(x[numerical_features])\n",
      "c:\\Users\\elped\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.4411 - mae: 0.1950 - val_loss: 0.1857 - val_mae: 0.1662\n",
      "Epoch 2/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1511 - mae: 0.1713 - val_loss: 0.0747 - val_mae: 0.1560\n",
      "Epoch 3/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0676 - mae: 0.1615 - val_loss: 0.0460 - val_mae: 0.1475\n",
      "Epoch 4/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0460 - mae: 0.1530 - val_loss: 0.0393 - val_mae: 0.1450\n",
      "Epoch 5/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0414 - mae: 0.1519 - val_loss: 0.0376 - val_mae: 0.1440\n",
      "Epoch 6/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0398 - mae: 0.1483 - val_loss: 0.0369 - val_mae: 0.1433\n",
      "Epoch 7/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0396 - mae: 0.1482 - val_loss: 0.0365 - val_mae: 0.1439\n",
      "Epoch 8/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0390 - mae: 0.1499 - val_loss: 0.0364 - val_mae: 0.1417\n",
      "Epoch 9/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0394 - mae: 0.1505 - val_loss: 0.0359 - val_mae: 0.1414\n",
      "Epoch 10/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0385 - mae: 0.1483 - val_loss: 0.0357 - val_mae: 0.1410\n",
      "Epoch 11/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0378 - mae: 0.1471 - val_loss: 0.0354 - val_mae: 0.1425\n",
      "Epoch 12/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0383 - mae: 0.1480 - val_loss: 0.0360 - val_mae: 0.1437\n",
      "Epoch 13/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0387 - mae: 0.1485 - val_loss: 0.0352 - val_mae: 0.1410\n",
      "Epoch 14/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0372 - mae: 0.1453 - val_loss: 0.0350 - val_mae: 0.1406\n",
      "Epoch 15/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0370 - mae: 0.1451 - val_loss: 0.0352 - val_mae: 0.1395\n",
      "Epoch 16/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0382 - mae: 0.1482 - val_loss: 0.0348 - val_mae: 0.1411\n",
      "Epoch 17/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0374 - mae: 0.1477 - val_loss: 0.0348 - val_mae: 0.1403\n",
      "Epoch 18/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0371 - mae: 0.1454 - val_loss: 0.0348 - val_mae: 0.1394\n",
      "Epoch 19/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0361 - mae: 0.1429 - val_loss: 0.0346 - val_mae: 0.1417\n",
      "Epoch 20/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0363 - mae: 0.1433 - val_loss: 0.0344 - val_mae: 0.1394\n",
      "Epoch 21/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0377 - mae: 0.1465 - val_loss: 0.0342 - val_mae: 0.1401\n",
      "Epoch 22/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0374 - mae: 0.1479 - val_loss: 0.0340 - val_mae: 0.1396\n",
      "Epoch 23/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0366 - mae: 0.1451 - val_loss: 0.0339 - val_mae: 0.1401\n",
      "Epoch 24/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0371 - mae: 0.1462 - val_loss: 0.0342 - val_mae: 0.1392\n",
      "Epoch 25/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0361 - mae: 0.1444 - val_loss: 0.0341 - val_mae: 0.1403\n",
      "Epoch 26/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0367 - mae: 0.1461 - val_loss: 0.0341 - val_mae: 0.1388\n",
      "Epoch 27/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0355 - mae: 0.1421 - val_loss: 0.0338 - val_mae: 0.1402\n",
      "Epoch 28/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0364 - mae: 0.1447 - val_loss: 0.0336 - val_mae: 0.1371\n",
      "Epoch 29/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0365 - mae: 0.1446 - val_loss: 0.0346 - val_mae: 0.1393\n",
      "Epoch 30/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0362 - mae: 0.1445 - val_loss: 0.0333 - val_mae: 0.1383\n",
      "Epoch 31/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0359 - mae: 0.1440 - val_loss: 0.0333 - val_mae: 0.1377\n",
      "Epoch 32/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0361 - mae: 0.1445 - val_loss: 0.0336 - val_mae: 0.1367\n",
      "Epoch 33/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0368 - mae: 0.1466 - val_loss: 0.0337 - val_mae: 0.1378\n",
      "Epoch 34/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0353 - mae: 0.1429 - val_loss: 0.0330 - val_mae: 0.1376\n",
      "Epoch 35/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0348 - mae: 0.1427 - val_loss: 0.0335 - val_mae: 0.1370\n",
      "Epoch 36/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0360 - mae: 0.1438 - val_loss: 0.0332 - val_mae: 0.1386\n",
      "Epoch 37/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0349 - mae: 0.1424 - val_loss: 0.0331 - val_mae: 0.1377\n",
      "Epoch 38/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0363 - mae: 0.1452 - val_loss: 0.0327 - val_mae: 0.1380\n",
      "Epoch 39/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0349 - mae: 0.1422 - val_loss: 0.0328 - val_mae: 0.1375\n",
      "Epoch 40/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0345 - mae: 0.1414 - val_loss: 0.0327 - val_mae: 0.1362\n",
      "Epoch 41/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0350 - mae: 0.1414 - val_loss: 0.0326 - val_mae: 0.1389\n",
      "Epoch 42/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0350 - mae: 0.1443 - val_loss: 0.0330 - val_mae: 0.1382\n",
      "Epoch 43/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0351 - mae: 0.1427 - val_loss: 0.0331 - val_mae: 0.1372\n",
      "Epoch 44/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0348 - mae: 0.1418 - val_loss: 0.0327 - val_mae: 0.1365\n",
      "Epoch 45/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0343 - mae: 0.1405 - val_loss: 0.0327 - val_mae: 0.1376\n",
      "Epoch 46/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0362 - mae: 0.1464 - val_loss: 0.0332 - val_mae: 0.1367\n",
      "Epoch 47/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0341 - mae: 0.1404 - val_loss: 0.0323 - val_mae: 0.1379\n",
      "Epoch 48/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0342 - mae: 0.1412 - val_loss: 0.0323 - val_mae: 0.1375\n",
      "Epoch 49/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0351 - mae: 0.1434 - val_loss: 0.0324 - val_mae: 0.1376\n",
      "Epoch 50/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0338 - mae: 0.1397 - val_loss: 0.0323 - val_mae: 0.1367\n",
      "Epoch 51/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0338 - mae: 0.1402 - val_loss: 0.0325 - val_mae: 0.1370\n",
      "Epoch 52/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0345 - mae: 0.1420 - val_loss: 0.0322 - val_mae: 0.1368\n",
      "Epoch 53/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0337 - mae: 0.1402 - val_loss: 0.0323 - val_mae: 0.1374\n",
      "Epoch 54/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0351 - mae: 0.1450 - val_loss: 0.0322 - val_mae: 0.1356\n",
      "Epoch 55/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0349 - mae: 0.1421 - val_loss: 0.0322 - val_mae: 0.1358\n",
      "Epoch 56/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0347 - mae: 0.1432 - val_loss: 0.0331 - val_mae: 0.1399\n",
      "Epoch 57/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0347 - mae: 0.1429 - val_loss: 0.0328 - val_mae: 0.1375\n",
      "Epoch 58/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0337 - mae: 0.1399 - val_loss: 0.0323 - val_mae: 0.1364\n",
      "Epoch 59/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0342 - mae: 0.1419 - val_loss: 0.0327 - val_mae: 0.1367\n",
      "Epoch 60/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0347 - mae: 0.1425 - val_loss: 0.0320 - val_mae: 0.1383\n",
      "Epoch 61/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0342 - mae: 0.1423 - val_loss: 0.0320 - val_mae: 0.1370\n",
      "Epoch 62/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0345 - mae: 0.1423 - val_loss: 0.0321 - val_mae: 0.1364\n",
      "Epoch 63/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0343 - mae: 0.1428 - val_loss: 0.0327 - val_mae: 0.1361\n",
      "Epoch 64/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0330 - mae: 0.1387 - val_loss: 0.0324 - val_mae: 0.1359\n",
      "Epoch 65/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0341 - mae: 0.1415 - val_loss: 0.0319 - val_mae: 0.1373\n",
      "Epoch 66/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0340 - mae: 0.1408 - val_loss: 0.0322 - val_mae: 0.1375\n",
      "Epoch 67/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0338 - mae: 0.1398 - val_loss: 0.0318 - val_mae: 0.1378\n",
      "Epoch 68/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0339 - mae: 0.1423 - val_loss: 0.0322 - val_mae: 0.1377\n",
      "Epoch 69/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0327 - mae: 0.1380 - val_loss: 0.0322 - val_mae: 0.1355\n",
      "Epoch 70/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0342 - mae: 0.1415 - val_loss: 0.0317 - val_mae: 0.1353\n",
      "Epoch 71/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0348 - mae: 0.1435 - val_loss: 0.0319 - val_mae: 0.1368\n",
      "Epoch 72/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0339 - mae: 0.1409 - val_loss: 0.0326 - val_mae: 0.1389\n",
      "Epoch 73/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0348 - mae: 0.1432 - val_loss: 0.0321 - val_mae: 0.1359\n",
      "Epoch 74/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0333 - mae: 0.1388 - val_loss: 0.0329 - val_mae: 0.1407\n",
      "Epoch 75/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0337 - mae: 0.1408 - val_loss: 0.0324 - val_mae: 0.1371\n",
      "Epoch 76/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0347 - mae: 0.1428 - val_loss: 0.0319 - val_mae: 0.1358\n",
      "Epoch 77/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0349 - mae: 0.1438 - val_loss: 0.0320 - val_mae: 0.1369\n",
      "Epoch 78/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0337 - mae: 0.1401 - val_loss: 0.0318 - val_mae: 0.1346\n",
      "Epoch 79/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0335 - mae: 0.1393 - val_loss: 0.0317 - val_mae: 0.1379\n",
      "Epoch 80/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0340 - mae: 0.1418 - val_loss: 0.0319 - val_mae: 0.1357\n",
      "Epoch 81/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0336 - mae: 0.1408 - val_loss: 0.0315 - val_mae: 0.1353\n",
      "Epoch 82/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0330 - mae: 0.1390 - val_loss: 0.0320 - val_mae: 0.1380\n",
      "Epoch 83/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0335 - mae: 0.1408 - val_loss: 0.0313 - val_mae: 0.1343\n",
      "Epoch 84/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0335 - mae: 0.1394 - val_loss: 0.0316 - val_mae: 0.1372\n",
      "Epoch 85/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0319 - mae: 0.1378 - val_loss: 0.0320 - val_mae: 0.1370\n",
      "Epoch 86/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0328 - mae: 0.1393 - val_loss: 0.0314 - val_mae: 0.1356\n",
      "Epoch 87/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0330 - mae: 0.1390 - val_loss: 0.0316 - val_mae: 0.1349\n",
      "Epoch 88/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0336 - mae: 0.1413 - val_loss: 0.0314 - val_mae: 0.1353\n",
      "Epoch 89/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0334 - mae: 0.1410 - val_loss: 0.0321 - val_mae: 0.1362\n",
      "Epoch 90/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0347 - mae: 0.1430 - val_loss: 0.0317 - val_mae: 0.1355\n",
      "Epoch 91/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0337 - mae: 0.1405 - val_loss: 0.0317 - val_mae: 0.1367\n",
      "Epoch 92/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0327 - mae: 0.1383 - val_loss: 0.0315 - val_mae: 0.1379\n",
      "Epoch 93/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0346 - mae: 0.1432 - val_loss: 0.0318 - val_mae: 0.1357\n",
      "Epoch 94/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0330 - mae: 0.1388 - val_loss: 0.0318 - val_mae: 0.1352\n",
      "Epoch 95/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0335 - mae: 0.1403 - val_loss: 0.0319 - val_mae: 0.1355\n",
      "Epoch 96/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0337 - mae: 0.1407 - val_loss: 0.0323 - val_mae: 0.1392\n",
      "Epoch 97/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0330 - mae: 0.1386 - val_loss: 0.0321 - val_mae: 0.1375\n",
      "Epoch 98/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0334 - mae: 0.1402 - val_loss: 0.0317 - val_mae: 0.1375\n",
      "Epoch 99/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0334 - mae: 0.1410 - val_loss: 0.0316 - val_mae: 0.1348\n",
      "Epoch 100/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0333 - mae: 0.1404 - val_loss: 0.0316 - val_mae: 0.1349\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0307 - mae: 0.1330 \n",
      "---------------------------------------------------------\n",
      "K 1 FOLD\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elped\\AppData\\Local\\Temp\\ipykernel_15892\\330544952.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[numerical_features] = scaler.fit_transform(x[numerical_features])\n",
      "c:\\Users\\elped\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.4904 - mae: 0.2549 - val_loss: 0.2016 - val_mae: 0.1752\n",
      "Epoch 2/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1626 - mae: 0.1724 - val_loss: 0.0860 - val_mae: 0.1703\n",
      "Epoch 3/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0754 - mae: 0.1683 - val_loss: 0.0545 - val_mae: 0.1640\n",
      "Epoch 4/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0530 - mae: 0.1647 - val_loss: 0.0456 - val_mae: 0.1587\n",
      "Epoch 5/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0442 - mae: 0.1566 - val_loss: 0.0425 - val_mae: 0.1557\n",
      "Epoch 6/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0423 - mae: 0.1549 - val_loss: 0.0416 - val_mae: 0.1536\n",
      "Epoch 7/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0407 - mae: 0.1526 - val_loss: 0.0406 - val_mae: 0.1519\n",
      "Epoch 8/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0412 - mae: 0.1531 - val_loss: 0.0401 - val_mae: 0.1515\n",
      "Epoch 9/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0393 - mae: 0.1504 - val_loss: 0.0397 - val_mae: 0.1500\n",
      "Epoch 10/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0390 - mae: 0.1490 - val_loss: 0.0391 - val_mae: 0.1482\n",
      "Epoch 11/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0394 - mae: 0.1491 - val_loss: 0.0388 - val_mae: 0.1497\n",
      "Epoch 12/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0392 - mae: 0.1505 - val_loss: 0.0387 - val_mae: 0.1497\n",
      "Epoch 13/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0399 - mae: 0.1533 - val_loss: 0.0390 - val_mae: 0.1490\n",
      "Epoch 14/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0397 - mae: 0.1524 - val_loss: 0.0380 - val_mae: 0.1482\n",
      "Epoch 15/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0396 - mae: 0.1521 - val_loss: 0.0388 - val_mae: 0.1463\n",
      "Epoch 16/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0393 - mae: 0.1500 - val_loss: 0.0380 - val_mae: 0.1477\n",
      "Epoch 17/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0384 - mae: 0.1492 - val_loss: 0.0381 - val_mae: 0.1476\n",
      "Epoch 18/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0388 - mae: 0.1507 - val_loss: 0.0374 - val_mae: 0.1472\n",
      "Epoch 19/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0372 - mae: 0.1463 - val_loss: 0.0377 - val_mae: 0.1470\n",
      "Epoch 20/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0381 - mae: 0.1489 - val_loss: 0.0370 - val_mae: 0.1449\n",
      "Epoch 21/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0369 - mae: 0.1453 - val_loss: 0.0368 - val_mae: 0.1456\n",
      "Epoch 22/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0374 - mae: 0.1483 - val_loss: 0.0363 - val_mae: 0.1434\n",
      "Epoch 23/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0367 - mae: 0.1447 - val_loss: 0.0369 - val_mae: 0.1457\n",
      "Epoch 24/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0363 - mae: 0.1456 - val_loss: 0.0368 - val_mae: 0.1463\n",
      "Epoch 25/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0381 - mae: 0.1487 - val_loss: 0.0364 - val_mae: 0.1443\n",
      "Epoch 26/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0365 - mae: 0.1459 - val_loss: 0.0362 - val_mae: 0.1448\n",
      "Epoch 27/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0374 - mae: 0.1472 - val_loss: 0.0364 - val_mae: 0.1428\n",
      "Epoch 28/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0367 - mae: 0.1452 - val_loss: 0.0368 - val_mae: 0.1458\n",
      "Epoch 29/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0367 - mae: 0.1467 - val_loss: 0.0362 - val_mae: 0.1429\n",
      "Epoch 30/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0369 - mae: 0.1456 - val_loss: 0.0357 - val_mae: 0.1434\n",
      "Epoch 31/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0368 - mae: 0.1463 - val_loss: 0.0359 - val_mae: 0.1441\n",
      "Epoch 32/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0359 - mae: 0.1452 - val_loss: 0.0357 - val_mae: 0.1432\n",
      "Epoch 33/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0364 - mae: 0.1459 - val_loss: 0.0364 - val_mae: 0.1433\n",
      "Epoch 34/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0361 - mae: 0.1448 - val_loss: 0.0360 - val_mae: 0.1456\n",
      "Epoch 35/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0366 - mae: 0.1470 - val_loss: 0.0356 - val_mae: 0.1429\n",
      "Epoch 36/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0353 - mae: 0.1438 - val_loss: 0.0357 - val_mae: 0.1421\n",
      "Epoch 37/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0355 - mae: 0.1437 - val_loss: 0.0349 - val_mae: 0.1421\n",
      "Epoch 38/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0367 - mae: 0.1473 - val_loss: 0.0354 - val_mae: 0.1427\n",
      "Epoch 39/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0365 - mae: 0.1454 - val_loss: 0.0358 - val_mae: 0.1433\n",
      "Epoch 40/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0352 - mae: 0.1439 - val_loss: 0.0347 - val_mae: 0.1423\n",
      "Epoch 41/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0349 - mae: 0.1425 - val_loss: 0.0351 - val_mae: 0.1415\n",
      "Epoch 42/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0347 - mae: 0.1423 - val_loss: 0.0348 - val_mae: 0.1427\n",
      "Epoch 43/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0355 - mae: 0.1445 - val_loss: 0.0356 - val_mae: 0.1460\n",
      "Epoch 44/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0351 - mae: 0.1433 - val_loss: 0.0348 - val_mae: 0.1426\n",
      "Epoch 45/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0352 - mae: 0.1453 - val_loss: 0.0348 - val_mae: 0.1419\n",
      "Epoch 46/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0350 - mae: 0.1438 - val_loss: 0.0352 - val_mae: 0.1405\n",
      "Epoch 47/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0348 - mae: 0.1422 - val_loss: 0.0343 - val_mae: 0.1393\n",
      "Epoch 48/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0349 - mae: 0.1428 - val_loss: 0.0347 - val_mae: 0.1427\n",
      "Epoch 49/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0346 - mae: 0.1421 - val_loss: 0.0349 - val_mae: 0.1427\n",
      "Epoch 50/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0359 - mae: 0.1469 - val_loss: 0.0343 - val_mae: 0.1409\n",
      "Epoch 51/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0367 - mae: 0.1473 - val_loss: 0.0346 - val_mae: 0.1416\n",
      "Epoch 52/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0351 - mae: 0.1439 - val_loss: 0.0340 - val_mae: 0.1413\n",
      "Epoch 53/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0354 - mae: 0.1431 - val_loss: 0.0346 - val_mae: 0.1421\n",
      "Epoch 54/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0341 - mae: 0.1416 - val_loss: 0.0343 - val_mae: 0.1425\n",
      "Epoch 55/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0350 - mae: 0.1439 - val_loss: 0.0340 - val_mae: 0.1395\n",
      "Epoch 56/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0352 - mae: 0.1423 - val_loss: 0.0346 - val_mae: 0.1404\n",
      "Epoch 57/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0338 - mae: 0.1405 - val_loss: 0.0342 - val_mae: 0.1403\n",
      "Epoch 58/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0350 - mae: 0.1440 - val_loss: 0.0348 - val_mae: 0.1422\n",
      "Epoch 59/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0342 - mae: 0.1418 - val_loss: 0.0345 - val_mae: 0.1420\n",
      "Epoch 60/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0348 - mae: 0.1445 - val_loss: 0.0341 - val_mae: 0.1401\n",
      "Epoch 61/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0351 - mae: 0.1435 - val_loss: 0.0343 - val_mae: 0.1403\n",
      "Epoch 62/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0357 - mae: 0.1466 - val_loss: 0.0336 - val_mae: 0.1389\n",
      "Epoch 63/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0340 - mae: 0.1424 - val_loss: 0.0340 - val_mae: 0.1409\n",
      "Epoch 64/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0335 - mae: 0.1399 - val_loss: 0.0337 - val_mae: 0.1395\n",
      "Epoch 65/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0336 - mae: 0.1407 - val_loss: 0.0334 - val_mae: 0.1388\n",
      "Epoch 66/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0347 - mae: 0.1427 - val_loss: 0.0333 - val_mae: 0.1391\n",
      "Epoch 67/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0353 - mae: 0.1452 - val_loss: 0.0335 - val_mae: 0.1401\n",
      "Epoch 68/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0349 - mae: 0.1442 - val_loss: 0.0339 - val_mae: 0.1394\n",
      "Epoch 69/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0340 - mae: 0.1425 - val_loss: 0.0333 - val_mae: 0.1380\n",
      "Epoch 70/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0340 - mae: 0.1419 - val_loss: 0.0337 - val_mae: 0.1395\n",
      "Epoch 71/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0343 - mae: 0.1423 - val_loss: 0.0338 - val_mae: 0.1418\n",
      "Epoch 72/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0333 - mae: 0.1402 - val_loss: 0.0336 - val_mae: 0.1410\n",
      "Epoch 73/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0352 - mae: 0.1457 - val_loss: 0.0340 - val_mae: 0.1425\n",
      "Epoch 74/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0340 - mae: 0.1418 - val_loss: 0.0339 - val_mae: 0.1421\n",
      "Epoch 75/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0342 - mae: 0.1436 - val_loss: 0.0345 - val_mae: 0.1418\n",
      "Epoch 76/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0352 - mae: 0.1451 - val_loss: 0.0335 - val_mae: 0.1412\n",
      "Epoch 77/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0339 - mae: 0.1425 - val_loss: 0.0334 - val_mae: 0.1402\n",
      "Epoch 78/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0342 - mae: 0.1430 - val_loss: 0.0332 - val_mae: 0.1399\n",
      "Epoch 79/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0342 - mae: 0.1424 - val_loss: 0.0333 - val_mae: 0.1376\n",
      "Epoch 80/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0334 - mae: 0.1417 - val_loss: 0.0330 - val_mae: 0.1381\n",
      "Epoch 81/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0336 - mae: 0.1411 - val_loss: 0.0331 - val_mae: 0.1393\n",
      "Epoch 82/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0343 - mae: 0.1428 - val_loss: 0.0339 - val_mae: 0.1407\n",
      "Epoch 83/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0346 - mae: 0.1429 - val_loss: 0.0336 - val_mae: 0.1401\n",
      "Epoch 84/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0346 - mae: 0.1442 - val_loss: 0.0333 - val_mae: 0.1392\n",
      "Epoch 85/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0350 - mae: 0.1443 - val_loss: 0.0334 - val_mae: 0.1398\n",
      "Epoch 86/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0338 - mae: 0.1423 - val_loss: 0.0329 - val_mae: 0.1395\n",
      "Epoch 87/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0347 - mae: 0.1425 - val_loss: 0.0341 - val_mae: 0.1393\n",
      "Epoch 88/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0341 - mae: 0.1417 - val_loss: 0.0340 - val_mae: 0.1405\n",
      "Epoch 89/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0341 - mae: 0.1416 - val_loss: 0.0330 - val_mae: 0.1390\n",
      "Epoch 90/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0339 - mae: 0.1409 - val_loss: 0.0333 - val_mae: 0.1394\n",
      "Epoch 91/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0351 - mae: 0.1449 - val_loss: 0.0337 - val_mae: 0.1423\n",
      "Epoch 92/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0341 - mae: 0.1421 - val_loss: 0.0331 - val_mae: 0.1394\n",
      "Epoch 93/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0344 - mae: 0.1430 - val_loss: 0.0324 - val_mae: 0.1382\n",
      "Epoch 94/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0341 - mae: 0.1417 - val_loss: 0.0331 - val_mae: 0.1385\n",
      "Epoch 95/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0343 - mae: 0.1431 - val_loss: 0.0330 - val_mae: 0.1376\n",
      "Epoch 96/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0327 - mae: 0.1379 - val_loss: 0.0332 - val_mae: 0.1392\n",
      "Epoch 97/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0349 - mae: 0.1428 - val_loss: 0.0329 - val_mae: 0.1400\n",
      "Epoch 98/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0332 - mae: 0.1414 - val_loss: 0.0329 - val_mae: 0.1393\n",
      "Epoch 99/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0349 - mae: 0.1447 - val_loss: 0.0327 - val_mae: 0.1390\n",
      "Epoch 100/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0337 - mae: 0.1417 - val_loss: 0.0332 - val_mae: 0.1399\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0317 - mae: 0.1366 \n",
      "---------------------------------------------------------\n",
      "K 2 FOLD\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elped\\AppData\\Local\\Temp\\ipykernel_15892\\330544952.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[numerical_features] = scaler.fit_transform(x[numerical_features])\n",
      "c:\\Users\\elped\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.4341 - mae: 0.1871 - val_loss: 0.1847 - val_mae: 0.1794\n",
      "Epoch 2/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1458 - mae: 0.1723 - val_loss: 0.0751 - val_mae: 0.1690\n",
      "Epoch 3/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0653 - mae: 0.1642 - val_loss: 0.0477 - val_mae: 0.1595\n",
      "Epoch 4/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0465 - mae: 0.1588 - val_loss: 0.0420 - val_mae: 0.1558\n",
      "Epoch 5/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0411 - mae: 0.1519 - val_loss: 0.0405 - val_mae: 0.1541\n",
      "Epoch 6/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0411 - mae: 0.1539 - val_loss: 0.0396 - val_mae: 0.1514\n",
      "Epoch 7/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0391 - mae: 0.1478 - val_loss: 0.0391 - val_mae: 0.1507\n",
      "Epoch 8/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0396 - mae: 0.1498 - val_loss: 0.0387 - val_mae: 0.1503\n",
      "Epoch 9/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0393 - mae: 0.1494 - val_loss: 0.0388 - val_mae: 0.1506\n",
      "Epoch 10/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0382 - mae: 0.1482 - val_loss: 0.0385 - val_mae: 0.1488\n",
      "Epoch 11/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0388 - mae: 0.1474 - val_loss: 0.0380 - val_mae: 0.1481\n",
      "Epoch 12/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0381 - mae: 0.1473 - val_loss: 0.0381 - val_mae: 0.1502\n",
      "Epoch 13/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0386 - mae: 0.1497 - val_loss: 0.0375 - val_mae: 0.1475\n",
      "Epoch 14/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0372 - mae: 0.1463 - val_loss: 0.0372 - val_mae: 0.1468\n",
      "Epoch 15/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0363 - mae: 0.1431 - val_loss: 0.0368 - val_mae: 0.1455\n",
      "Epoch 16/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0380 - mae: 0.1481 - val_loss: 0.0381 - val_mae: 0.1501\n",
      "Epoch 17/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0374 - mae: 0.1469 - val_loss: 0.0372 - val_mae: 0.1473\n",
      "Epoch 18/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0369 - mae: 0.1443 - val_loss: 0.0372 - val_mae: 0.1476\n",
      "Epoch 19/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0383 - mae: 0.1479 - val_loss: 0.0364 - val_mae: 0.1462\n",
      "Epoch 20/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0371 - mae: 0.1468 - val_loss: 0.0367 - val_mae: 0.1470\n",
      "Epoch 21/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0366 - mae: 0.1451 - val_loss: 0.0369 - val_mae: 0.1467\n",
      "Epoch 22/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0370 - mae: 0.1461 - val_loss: 0.0365 - val_mae: 0.1475\n",
      "Epoch 23/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0370 - mae: 0.1467 - val_loss: 0.0362 - val_mae: 0.1470\n",
      "Epoch 24/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0362 - mae: 0.1455 - val_loss: 0.0362 - val_mae: 0.1464\n",
      "Epoch 25/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0361 - mae: 0.1435 - val_loss: 0.0364 - val_mae: 0.1459\n",
      "Epoch 26/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0369 - mae: 0.1465 - val_loss: 0.0359 - val_mae: 0.1454\n",
      "Epoch 27/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0360 - mae: 0.1437 - val_loss: 0.0355 - val_mae: 0.1436\n",
      "Epoch 28/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0358 - mae: 0.1445 - val_loss: 0.0354 - val_mae: 0.1421\n",
      "Epoch 29/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0368 - mae: 0.1465 - val_loss: 0.0357 - val_mae: 0.1449\n",
      "Epoch 30/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0356 - mae: 0.1431 - val_loss: 0.0353 - val_mae: 0.1441\n",
      "Epoch 31/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0360 - mae: 0.1447 - val_loss: 0.0355 - val_mae: 0.1440\n",
      "Epoch 32/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0353 - mae: 0.1426 - val_loss: 0.0358 - val_mae: 0.1455\n",
      "Epoch 33/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0350 - mae: 0.1423 - val_loss: 0.0354 - val_mae: 0.1443\n",
      "Epoch 34/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0355 - mae: 0.1436 - val_loss: 0.0353 - val_mae: 0.1437\n",
      "Epoch 35/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0343 - mae: 0.1404 - val_loss: 0.0346 - val_mae: 0.1426\n",
      "Epoch 36/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0352 - mae: 0.1433 - val_loss: 0.0350 - val_mae: 0.1430\n",
      "Epoch 37/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0356 - mae: 0.1433 - val_loss: 0.0352 - val_mae: 0.1425\n",
      "Epoch 38/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0359 - mae: 0.1449 - val_loss: 0.0349 - val_mae: 0.1437\n",
      "Epoch 39/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0350 - mae: 0.1430 - val_loss: 0.0351 - val_mae: 0.1435\n",
      "Epoch 40/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0347 - mae: 0.1416 - val_loss: 0.0347 - val_mae: 0.1425\n",
      "Epoch 41/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0347 - mae: 0.1413 - val_loss: 0.0346 - val_mae: 0.1409\n",
      "Epoch 42/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0359 - mae: 0.1438 - val_loss: 0.0347 - val_mae: 0.1425\n",
      "Epoch 43/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0358 - mae: 0.1445 - val_loss: 0.0349 - val_mae: 0.1440\n",
      "Epoch 44/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0351 - mae: 0.1424 - val_loss: 0.0347 - val_mae: 0.1428\n",
      "Epoch 45/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0357 - mae: 0.1442 - val_loss: 0.0341 - val_mae: 0.1408\n",
      "Epoch 46/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0346 - mae: 0.1413 - val_loss: 0.0342 - val_mae: 0.1419\n",
      "Epoch 47/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0346 - mae: 0.1421 - val_loss: 0.0349 - val_mae: 0.1429\n",
      "Epoch 48/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0347 - mae: 0.1412 - val_loss: 0.0347 - val_mae: 0.1441\n",
      "Epoch 49/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0342 - mae: 0.1410 - val_loss: 0.0341 - val_mae: 0.1401\n",
      "Epoch 50/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0349 - mae: 0.1429 - val_loss: 0.0341 - val_mae: 0.1423\n",
      "Epoch 51/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0352 - mae: 0.1438 - val_loss: 0.0343 - val_mae: 0.1438\n",
      "Epoch 52/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0351 - mae: 0.1440 - val_loss: 0.0341 - val_mae: 0.1406\n",
      "Epoch 53/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0340 - mae: 0.1408 - val_loss: 0.0342 - val_mae: 0.1405\n",
      "Epoch 54/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0349 - mae: 0.1426 - val_loss: 0.0344 - val_mae: 0.1432\n",
      "Epoch 55/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0351 - mae: 0.1434 - val_loss: 0.0342 - val_mae: 0.1423\n",
      "Epoch 56/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0337 - mae: 0.1401 - val_loss: 0.0343 - val_mae: 0.1420\n",
      "Epoch 57/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0349 - mae: 0.1423 - val_loss: 0.0336 - val_mae: 0.1395\n",
      "Epoch 58/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0344 - mae: 0.1411 - val_loss: 0.0343 - val_mae: 0.1427\n",
      "Epoch 59/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0347 - mae: 0.1426 - val_loss: 0.0341 - val_mae: 0.1435\n",
      "Epoch 60/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0338 - mae: 0.1414 - val_loss: 0.0338 - val_mae: 0.1430\n",
      "Epoch 61/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0346 - mae: 0.1423 - val_loss: 0.0335 - val_mae: 0.1407\n",
      "Epoch 62/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0335 - mae: 0.1403 - val_loss: 0.0336 - val_mae: 0.1415\n",
      "Epoch 63/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0342 - mae: 0.1421 - val_loss: 0.0335 - val_mae: 0.1411\n",
      "Epoch 64/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0330 - mae: 0.1405 - val_loss: 0.0341 - val_mae: 0.1421\n",
      "Epoch 65/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0340 - mae: 0.1412 - val_loss: 0.0340 - val_mae: 0.1426\n",
      "Epoch 66/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0336 - mae: 0.1409 - val_loss: 0.0342 - val_mae: 0.1425\n",
      "Epoch 67/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0347 - mae: 0.1426 - val_loss: 0.0345 - val_mae: 0.1426\n",
      "Epoch 68/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0345 - mae: 0.1429 - val_loss: 0.0332 - val_mae: 0.1393\n",
      "Epoch 69/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0334 - mae: 0.1399 - val_loss: 0.0342 - val_mae: 0.1429\n",
      "Epoch 70/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0335 - mae: 0.1401 - val_loss: 0.0333 - val_mae: 0.1404\n",
      "Epoch 71/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0337 - mae: 0.1405 - val_loss: 0.0336 - val_mae: 0.1417\n",
      "Epoch 72/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0341 - mae: 0.1417 - val_loss: 0.0335 - val_mae: 0.1416\n",
      "Epoch 73/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0336 - mae: 0.1404 - val_loss: 0.0333 - val_mae: 0.1391\n",
      "Epoch 74/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0330 - mae: 0.1395 - val_loss: 0.0333 - val_mae: 0.1412\n",
      "Epoch 75/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0334 - mae: 0.1399 - val_loss: 0.0340 - val_mae: 0.1423\n",
      "Epoch 76/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0334 - mae: 0.1396 - val_loss: 0.0332 - val_mae: 0.1412\n",
      "Epoch 77/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0340 - mae: 0.1422 - val_loss: 0.0336 - val_mae: 0.1410\n",
      "Epoch 78/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0344 - mae: 0.1431 - val_loss: 0.0335 - val_mae: 0.1417\n",
      "Epoch 79/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0331 - mae: 0.1402 - val_loss: 0.0334 - val_mae: 0.1411\n",
      "Epoch 80/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0326 - mae: 0.1378 - val_loss: 0.0336 - val_mae: 0.1409\n",
      "Epoch 81/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0325 - mae: 0.1383 - val_loss: 0.0331 - val_mae: 0.1390\n",
      "Epoch 82/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0333 - mae: 0.1393 - val_loss: 0.0335 - val_mae: 0.1403\n",
      "Epoch 83/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0325 - mae: 0.1379 - val_loss: 0.0333 - val_mae: 0.1405\n",
      "Epoch 84/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0332 - mae: 0.1395 - val_loss: 0.0336 - val_mae: 0.1393\n",
      "Epoch 85/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0326 - mae: 0.1376 - val_loss: 0.0330 - val_mae: 0.1399\n",
      "Epoch 86/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0341 - mae: 0.1418 - val_loss: 0.0327 - val_mae: 0.1394\n",
      "Epoch 87/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0338 - mae: 0.1427 - val_loss: 0.0339 - val_mae: 0.1421\n",
      "Epoch 88/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0334 - mae: 0.1402 - val_loss: 0.0332 - val_mae: 0.1402\n",
      "Epoch 89/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0331 - mae: 0.1385 - val_loss: 0.0334 - val_mae: 0.1417\n",
      "Epoch 90/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0343 - mae: 0.1421 - val_loss: 0.0334 - val_mae: 0.1415\n",
      "Epoch 91/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0341 - mae: 0.1416 - val_loss: 0.0333 - val_mae: 0.1415\n",
      "Epoch 92/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0335 - mae: 0.1414 - val_loss: 0.0330 - val_mae: 0.1398\n",
      "Epoch 93/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0344 - mae: 0.1428 - val_loss: 0.0327 - val_mae: 0.1399\n",
      "Epoch 94/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0339 - mae: 0.1418 - val_loss: 0.0333 - val_mae: 0.1405\n",
      "Epoch 95/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0335 - mae: 0.1398 - val_loss: 0.0330 - val_mae: 0.1408\n",
      "Epoch 96/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0332 - mae: 0.1400 - val_loss: 0.0327 - val_mae: 0.1393\n",
      "Epoch 97/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0335 - mae: 0.1407 - val_loss: 0.0330 - val_mae: 0.1397\n",
      "Epoch 98/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0324 - mae: 0.1390 - val_loss: 0.0329 - val_mae: 0.1386\n",
      "Epoch 99/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0320 - mae: 0.1373 - val_loss: 0.0330 - val_mae: 0.1406\n",
      "Epoch 100/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0334 - mae: 0.1410 - val_loss: 0.0328 - val_mae: 0.1393\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0338 - mae: 0.1406 \n",
      "---------------------------------------------------------\n",
      "K 3 FOLD\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elped\\AppData\\Local\\Temp\\ipykernel_15892\\330544952.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[numerical_features] = scaler.fit_transform(x[numerical_features])\n",
      "c:\\Users\\elped\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.4316 - mae: 0.1947 - val_loss: 0.1836 - val_mae: 0.1667\n",
      "Epoch 2/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1501 - mae: 0.1710 - val_loss: 0.0743 - val_mae: 0.1574\n",
      "Epoch 3/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0668 - mae: 0.1603 - val_loss: 0.0455 - val_mae: 0.1503\n",
      "Epoch 4/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0458 - mae: 0.1548 - val_loss: 0.0392 - val_mae: 0.1483\n",
      "Epoch 5/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0413 - mae: 0.1520 - val_loss: 0.0372 - val_mae: 0.1452\n",
      "Epoch 6/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0404 - mae: 0.1523 - val_loss: 0.0372 - val_mae: 0.1466\n",
      "Epoch 7/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0406 - mae: 0.1527 - val_loss: 0.0360 - val_mae: 0.1429\n",
      "Epoch 8/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0398 - mae: 0.1518 - val_loss: 0.0360 - val_mae: 0.1436\n",
      "Epoch 9/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0387 - mae: 0.1475 - val_loss: 0.0357 - val_mae: 0.1443\n",
      "Epoch 10/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0392 - mae: 0.1507 - val_loss: 0.0357 - val_mae: 0.1422\n",
      "Epoch 11/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0385 - mae: 0.1485 - val_loss: 0.0350 - val_mae: 0.1409\n",
      "Epoch 12/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0384 - mae: 0.1489 - val_loss: 0.0347 - val_mae: 0.1403\n",
      "Epoch 13/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0385 - mae: 0.1492 - val_loss: 0.0350 - val_mae: 0.1434\n",
      "Epoch 14/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0383 - mae: 0.1495 - val_loss: 0.0347 - val_mae: 0.1410\n",
      "Epoch 15/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0375 - mae: 0.1466 - val_loss: 0.0350 - val_mae: 0.1417\n",
      "Epoch 16/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0386 - mae: 0.1488 - val_loss: 0.0343 - val_mae: 0.1398\n",
      "Epoch 17/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0371 - mae: 0.1467 - val_loss: 0.0350 - val_mae: 0.1440\n",
      "Epoch 18/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0381 - mae: 0.1495 - val_loss: 0.0341 - val_mae: 0.1406\n",
      "Epoch 19/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0374 - mae: 0.1468 - val_loss: 0.0339 - val_mae: 0.1383\n",
      "Epoch 20/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0366 - mae: 0.1451 - val_loss: 0.0341 - val_mae: 0.1393\n",
      "Epoch 21/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0377 - mae: 0.1471 - val_loss: 0.0334 - val_mae: 0.1382\n",
      "Epoch 22/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0379 - mae: 0.1478 - val_loss: 0.0342 - val_mae: 0.1408\n",
      "Epoch 23/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0363 - mae: 0.1438 - val_loss: 0.0341 - val_mae: 0.1434\n",
      "Epoch 24/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0358 - mae: 0.1454 - val_loss: 0.0340 - val_mae: 0.1389\n",
      "Epoch 25/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0365 - mae: 0.1449 - val_loss: 0.0336 - val_mae: 0.1390\n",
      "Epoch 26/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0370 - mae: 0.1467 - val_loss: 0.0345 - val_mae: 0.1417\n",
      "Epoch 27/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0361 - mae: 0.1448 - val_loss: 0.0345 - val_mae: 0.1434\n",
      "Epoch 28/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0361 - mae: 0.1444 - val_loss: 0.0332 - val_mae: 0.1406\n",
      "Epoch 29/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0363 - mae: 0.1457 - val_loss: 0.0330 - val_mae: 0.1381\n",
      "Epoch 30/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0367 - mae: 0.1453 - val_loss: 0.0332 - val_mae: 0.1401\n",
      "Epoch 31/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0369 - mae: 0.1470 - val_loss: 0.0325 - val_mae: 0.1367\n",
      "Epoch 32/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0354 - mae: 0.1432 - val_loss: 0.0329 - val_mae: 0.1392\n",
      "Epoch 33/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0361 - mae: 0.1455 - val_loss: 0.0322 - val_mae: 0.1366\n",
      "Epoch 34/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0353 - mae: 0.1432 - val_loss: 0.0328 - val_mae: 0.1401\n",
      "Epoch 35/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0364 - mae: 0.1467 - val_loss: 0.0325 - val_mae: 0.1380\n",
      "Epoch 36/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0355 - mae: 0.1441 - val_loss: 0.0321 - val_mae: 0.1357\n",
      "Epoch 37/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0358 - mae: 0.1444 - val_loss: 0.0327 - val_mae: 0.1387\n",
      "Epoch 38/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0358 - mae: 0.1458 - val_loss: 0.0321 - val_mae: 0.1364\n",
      "Epoch 39/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0368 - mae: 0.1467 - val_loss: 0.0325 - val_mae: 0.1387\n",
      "Epoch 40/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0362 - mae: 0.1456 - val_loss: 0.0322 - val_mae: 0.1373\n",
      "Epoch 41/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0354 - mae: 0.1438 - val_loss: 0.0335 - val_mae: 0.1416\n",
      "Epoch 42/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0353 - mae: 0.1445 - val_loss: 0.0323 - val_mae: 0.1383\n",
      "Epoch 43/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0350 - mae: 0.1444 - val_loss: 0.0318 - val_mae: 0.1365\n",
      "Epoch 44/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0352 - mae: 0.1437 - val_loss: 0.0322 - val_mae: 0.1393\n",
      "Epoch 45/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0352 - mae: 0.1446 - val_loss: 0.0320 - val_mae: 0.1372\n",
      "Epoch 46/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0358 - mae: 0.1453 - val_loss: 0.0320 - val_mae: 0.1371\n",
      "Epoch 47/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0363 - mae: 0.1465 - val_loss: 0.0321 - val_mae: 0.1385\n",
      "Epoch 48/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0350 - mae: 0.1441 - val_loss: 0.0323 - val_mae: 0.1396\n",
      "Epoch 49/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0361 - mae: 0.1467 - val_loss: 0.0315 - val_mae: 0.1350\n",
      "Epoch 50/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0353 - mae: 0.1437 - val_loss: 0.0319 - val_mae: 0.1376\n",
      "Epoch 51/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0350 - mae: 0.1439 - val_loss: 0.0316 - val_mae: 0.1350\n",
      "Epoch 52/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0351 - mae: 0.1444 - val_loss: 0.0322 - val_mae: 0.1381\n",
      "Epoch 53/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0338 - mae: 0.1415 - val_loss: 0.0334 - val_mae: 0.1405\n",
      "Epoch 54/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0353 - mae: 0.1439 - val_loss: 0.0326 - val_mae: 0.1387\n",
      "Epoch 55/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0354 - mae: 0.1443 - val_loss: 0.0318 - val_mae: 0.1364\n",
      "Epoch 56/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0351 - mae: 0.1434 - val_loss: 0.0321 - val_mae: 0.1380\n",
      "Epoch 57/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0351 - mae: 0.1424 - val_loss: 0.0316 - val_mae: 0.1371\n",
      "Epoch 58/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0357 - mae: 0.1450 - val_loss: 0.0321 - val_mae: 0.1371\n",
      "Epoch 59/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0354 - mae: 0.1443 - val_loss: 0.0315 - val_mae: 0.1365\n",
      "Epoch 60/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0336 - mae: 0.1413 - val_loss: 0.0324 - val_mae: 0.1402\n",
      "Epoch 61/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0344 - mae: 0.1424 - val_loss: 0.0317 - val_mae: 0.1351\n",
      "Epoch 62/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0342 - mae: 0.1418 - val_loss: 0.0312 - val_mae: 0.1353\n",
      "Epoch 63/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0351 - mae: 0.1427 - val_loss: 0.0316 - val_mae: 0.1360\n",
      "Epoch 64/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0341 - mae: 0.1420 - val_loss: 0.0313 - val_mae: 0.1360\n",
      "Epoch 65/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0345 - mae: 0.1432 - val_loss: 0.0319 - val_mae: 0.1391\n",
      "Epoch 66/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0344 - mae: 0.1431 - val_loss: 0.0318 - val_mae: 0.1384\n",
      "Epoch 67/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0351 - mae: 0.1437 - val_loss: 0.0313 - val_mae: 0.1371\n",
      "Epoch 68/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0340 - mae: 0.1414 - val_loss: 0.0316 - val_mae: 0.1373\n",
      "Epoch 69/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0366 - mae: 0.1469 - val_loss: 0.0316 - val_mae: 0.1380\n",
      "Epoch 70/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0353 - mae: 0.1453 - val_loss: 0.0316 - val_mae: 0.1374\n",
      "Epoch 71/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0343 - mae: 0.1432 - val_loss: 0.0309 - val_mae: 0.1335\n",
      "Epoch 72/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0344 - mae: 0.1428 - val_loss: 0.0309 - val_mae: 0.1342\n",
      "Epoch 73/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0324 - mae: 0.1381 - val_loss: 0.0315 - val_mae: 0.1371\n",
      "Epoch 74/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0342 - mae: 0.1417 - val_loss: 0.0310 - val_mae: 0.1346\n",
      "Epoch 75/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0333 - mae: 0.1399 - val_loss: 0.0316 - val_mae: 0.1378\n",
      "Epoch 76/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0344 - mae: 0.1448 - val_loss: 0.0309 - val_mae: 0.1348\n",
      "Epoch 77/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0352 - mae: 0.1439 - val_loss: 0.0311 - val_mae: 0.1337\n",
      "Epoch 78/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0341 - mae: 0.1416 - val_loss: 0.0308 - val_mae: 0.1343\n",
      "Epoch 79/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0334 - mae: 0.1403 - val_loss: 0.0312 - val_mae: 0.1366\n",
      "Epoch 80/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0343 - mae: 0.1422 - val_loss: 0.0307 - val_mae: 0.1351\n",
      "Epoch 81/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0340 - mae: 0.1413 - val_loss: 0.0321 - val_mae: 0.1390\n",
      "Epoch 82/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0344 - mae: 0.1431 - val_loss: 0.0312 - val_mae: 0.1348\n",
      "Epoch 83/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0341 - mae: 0.1409 - val_loss: 0.0310 - val_mae: 0.1352\n",
      "Epoch 84/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0334 - mae: 0.1406 - val_loss: 0.0307 - val_mae: 0.1356\n",
      "Epoch 85/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0332 - mae: 0.1398 - val_loss: 0.0307 - val_mae: 0.1341\n",
      "Epoch 86/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0348 - mae: 0.1428 - val_loss: 0.0312 - val_mae: 0.1364\n",
      "Epoch 87/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0336 - mae: 0.1412 - val_loss: 0.0309 - val_mae: 0.1358\n",
      "Epoch 88/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0339 - mae: 0.1420 - val_loss: 0.0308 - val_mae: 0.1353\n",
      "Epoch 89/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0339 - mae: 0.1415 - val_loss: 0.0307 - val_mae: 0.1341\n",
      "Epoch 90/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0341 - mae: 0.1423 - val_loss: 0.0306 - val_mae: 0.1344\n",
      "Epoch 91/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0335 - mae: 0.1409 - val_loss: 0.0303 - val_mae: 0.1337\n",
      "Epoch 92/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0339 - mae: 0.1422 - val_loss: 0.0319 - val_mae: 0.1390\n",
      "Epoch 93/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0334 - mae: 0.1409 - val_loss: 0.0310 - val_mae: 0.1360\n",
      "Epoch 94/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0346 - mae: 0.1424 - val_loss: 0.0306 - val_mae: 0.1332\n",
      "Epoch 95/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0337 - mae: 0.1392 - val_loss: 0.0308 - val_mae: 0.1358\n",
      "Epoch 96/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0343 - mae: 0.1415 - val_loss: 0.0306 - val_mae: 0.1346\n",
      "Epoch 97/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0334 - mae: 0.1407 - val_loss: 0.0316 - val_mae: 0.1392\n",
      "Epoch 98/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0331 - mae: 0.1389 - val_loss: 0.0308 - val_mae: 0.1357\n",
      "Epoch 99/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0340 - mae: 0.1420 - val_loss: 0.0311 - val_mae: 0.1353\n",
      "Epoch 100/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0341 - mae: 0.1412 - val_loss: 0.0306 - val_mae: 0.1344\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0303 - mae: 0.1345\n",
      "---------------------------------------------------------\n",
      "K 4 FOLD\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elped\\AppData\\Local\\Temp\\ipykernel_15892\\330544952.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[numerical_features] = scaler.fit_transform(x[numerical_features])\n",
      "c:\\Users\\elped\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.4555 - mae: 0.2148 - val_loss: 0.1946 - val_mae: 0.1802\n",
      "Epoch 2/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1567 - mae: 0.1812 - val_loss: 0.0793 - val_mae: 0.1678\n",
      "Epoch 3/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0686 - mae: 0.1646 - val_loss: 0.0488 - val_mae: 0.1575\n",
      "Epoch 4/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0466 - mae: 0.1572 - val_loss: 0.0417 - val_mae: 0.1528\n",
      "Epoch 5/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0412 - mae: 0.1511 - val_loss: 0.0400 - val_mae: 0.1518\n",
      "Epoch 6/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0414 - mae: 0.1547 - val_loss: 0.0391 - val_mae: 0.1502\n",
      "Epoch 7/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0407 - mae: 0.1533 - val_loss: 0.0388 - val_mae: 0.1496\n",
      "Epoch 8/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0390 - mae: 0.1501 - val_loss: 0.0381 - val_mae: 0.1474\n",
      "Epoch 9/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0402 - mae: 0.1519 - val_loss: 0.0379 - val_mae: 0.1473\n",
      "Epoch 10/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0402 - mae: 0.1521 - val_loss: 0.0380 - val_mae: 0.1474\n",
      "Epoch 11/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0392 - mae: 0.1496 - val_loss: 0.0376 - val_mae: 0.1464\n",
      "Epoch 12/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0391 - mae: 0.1504 - val_loss: 0.0370 - val_mae: 0.1450\n",
      "Epoch 13/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0389 - mae: 0.1494 - val_loss: 0.0370 - val_mae: 0.1455\n",
      "Epoch 14/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0383 - mae: 0.1482 - val_loss: 0.0366 - val_mae: 0.1457\n",
      "Epoch 15/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0390 - mae: 0.1502 - val_loss: 0.0368 - val_mae: 0.1456\n",
      "Epoch 16/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0374 - mae: 0.1458 - val_loss: 0.0366 - val_mae: 0.1444\n",
      "Epoch 17/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0381 - mae: 0.1489 - val_loss: 0.0368 - val_mae: 0.1452\n",
      "Epoch 18/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0382 - mae: 0.1487 - val_loss: 0.0365 - val_mae: 0.1447\n",
      "Epoch 19/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0371 - mae: 0.1481 - val_loss: 0.0367 - val_mae: 0.1455\n",
      "Epoch 20/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0370 - mae: 0.1470 - val_loss: 0.0361 - val_mae: 0.1453\n",
      "Epoch 21/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0379 - mae: 0.1499 - val_loss: 0.0358 - val_mae: 0.1440\n",
      "Epoch 22/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0375 - mae: 0.1472 - val_loss: 0.0356 - val_mae: 0.1428\n",
      "Epoch 23/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0365 - mae: 0.1436 - val_loss: 0.0357 - val_mae: 0.1449\n",
      "Epoch 24/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0364 - mae: 0.1473 - val_loss: 0.0351 - val_mae: 0.1417\n",
      "Epoch 25/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0366 - mae: 0.1446 - val_loss: 0.0355 - val_mae: 0.1435\n",
      "Epoch 26/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0375 - mae: 0.1473 - val_loss: 0.0354 - val_mae: 0.1427\n",
      "Epoch 27/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0365 - mae: 0.1455 - val_loss: 0.0352 - val_mae: 0.1422\n",
      "Epoch 28/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0372 - mae: 0.1463 - val_loss: 0.0351 - val_mae: 0.1426\n",
      "Epoch 29/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0368 - mae: 0.1471 - val_loss: 0.0352 - val_mae: 0.1438\n",
      "Epoch 30/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0373 - mae: 0.1478 - val_loss: 0.0353 - val_mae: 0.1422\n",
      "Epoch 31/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0365 - mae: 0.1451 - val_loss: 0.0349 - val_mae: 0.1416\n",
      "Epoch 32/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0370 - mae: 0.1480 - val_loss: 0.0348 - val_mae: 0.1421\n",
      "Epoch 33/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0357 - mae: 0.1433 - val_loss: 0.0345 - val_mae: 0.1426\n",
      "Epoch 34/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0357 - mae: 0.1445 - val_loss: 0.0352 - val_mae: 0.1428\n",
      "Epoch 35/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0353 - mae: 0.1422 - val_loss: 0.0344 - val_mae: 0.1417\n",
      "Epoch 36/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0372 - mae: 0.1479 - val_loss: 0.0345 - val_mae: 0.1409\n",
      "Epoch 37/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0355 - mae: 0.1429 - val_loss: 0.0346 - val_mae: 0.1425\n",
      "Epoch 38/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0350 - mae: 0.1432 - val_loss: 0.0345 - val_mae: 0.1419\n",
      "Epoch 39/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0356 - mae: 0.1437 - val_loss: 0.0343 - val_mae: 0.1418\n",
      "Epoch 40/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0362 - mae: 0.1451 - val_loss: 0.0341 - val_mae: 0.1396\n",
      "Epoch 41/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0369 - mae: 0.1475 - val_loss: 0.0351 - val_mae: 0.1434\n",
      "Epoch 42/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0354 - mae: 0.1451 - val_loss: 0.0343 - val_mae: 0.1419\n",
      "Epoch 43/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0362 - mae: 0.1459 - val_loss: 0.0346 - val_mae: 0.1415\n",
      "Epoch 44/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0360 - mae: 0.1443 - val_loss: 0.0343 - val_mae: 0.1408\n",
      "Epoch 45/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0359 - mae: 0.1466 - val_loss: 0.0337 - val_mae: 0.1390\n",
      "Epoch 46/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0358 - mae: 0.1441 - val_loss: 0.0346 - val_mae: 0.1425\n",
      "Epoch 47/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0355 - mae: 0.1444 - val_loss: 0.0342 - val_mae: 0.1419\n",
      "Epoch 48/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0346 - mae: 0.1418 - val_loss: 0.0340 - val_mae: 0.1400\n",
      "Epoch 49/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0350 - mae: 0.1431 - val_loss: 0.0340 - val_mae: 0.1396\n",
      "Epoch 50/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0343 - mae: 0.1419 - val_loss: 0.0342 - val_mae: 0.1407\n",
      "Epoch 51/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0349 - mae: 0.1430 - val_loss: 0.0338 - val_mae: 0.1402\n",
      "Epoch 52/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0358 - mae: 0.1448 - val_loss: 0.0335 - val_mae: 0.1390\n",
      "Epoch 53/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0347 - mae: 0.1420 - val_loss: 0.0336 - val_mae: 0.1404\n",
      "Epoch 54/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0347 - mae: 0.1431 - val_loss: 0.0338 - val_mae: 0.1406\n",
      "Epoch 55/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0344 - mae: 0.1422 - val_loss: 0.0341 - val_mae: 0.1432\n",
      "Epoch 56/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0353 - mae: 0.1443 - val_loss: 0.0336 - val_mae: 0.1390\n",
      "Epoch 57/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0352 - mae: 0.1435 - val_loss: 0.0340 - val_mae: 0.1408\n",
      "Epoch 58/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0347 - mae: 0.1426 - val_loss: 0.0338 - val_mae: 0.1402\n",
      "Epoch 59/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0351 - mae: 0.1435 - val_loss: 0.0333 - val_mae: 0.1386\n",
      "Epoch 60/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0355 - mae: 0.1453 - val_loss: 0.0333 - val_mae: 0.1397\n",
      "Epoch 61/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0337 - mae: 0.1404 - val_loss: 0.0331 - val_mae: 0.1398\n",
      "Epoch 62/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0344 - mae: 0.1413 - val_loss: 0.0335 - val_mae: 0.1407\n",
      "Epoch 63/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0349 - mae: 0.1432 - val_loss: 0.0335 - val_mae: 0.1410\n",
      "Epoch 64/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0345 - mae: 0.1428 - val_loss: 0.0335 - val_mae: 0.1418\n",
      "Epoch 65/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0357 - mae: 0.1457 - val_loss: 0.0332 - val_mae: 0.1397\n",
      "Epoch 66/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0346 - mae: 0.1429 - val_loss: 0.0333 - val_mae: 0.1397\n",
      "Epoch 67/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0342 - mae: 0.1426 - val_loss: 0.0330 - val_mae: 0.1392\n",
      "Epoch 68/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0356 - mae: 0.1450 - val_loss: 0.0330 - val_mae: 0.1401\n",
      "Epoch 69/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0345 - mae: 0.1431 - val_loss: 0.0329 - val_mae: 0.1387\n",
      "Epoch 70/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0356 - mae: 0.1462 - val_loss: 0.0330 - val_mae: 0.1380\n",
      "Epoch 71/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0336 - mae: 0.1402 - val_loss: 0.0332 - val_mae: 0.1391\n",
      "Epoch 72/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0348 - mae: 0.1430 - val_loss: 0.0332 - val_mae: 0.1407\n",
      "Epoch 73/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0336 - mae: 0.1417 - val_loss: 0.0334 - val_mae: 0.1409\n",
      "Epoch 74/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0341 - mae: 0.1428 - val_loss: 0.0332 - val_mae: 0.1397\n",
      "Epoch 75/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0330 - mae: 0.1389 - val_loss: 0.0337 - val_mae: 0.1400\n",
      "Epoch 76/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0327 - mae: 0.1395 - val_loss: 0.0344 - val_mae: 0.1421\n",
      "Epoch 77/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0344 - mae: 0.1430 - val_loss: 0.0326 - val_mae: 0.1379\n",
      "Epoch 78/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0342 - mae: 0.1424 - val_loss: 0.0335 - val_mae: 0.1407\n",
      "Epoch 79/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0340 - mae: 0.1417 - val_loss: 0.0331 - val_mae: 0.1377\n",
      "Epoch 80/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0355 - mae: 0.1450 - val_loss: 0.0328 - val_mae: 0.1388\n",
      "Epoch 81/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0341 - mae: 0.1417 - val_loss: 0.0332 - val_mae: 0.1404\n",
      "Epoch 82/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0336 - mae: 0.1409 - val_loss: 0.0331 - val_mae: 0.1388\n",
      "Epoch 83/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0333 - mae: 0.1393 - val_loss: 0.0334 - val_mae: 0.1404\n",
      "Epoch 84/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0338 - mae: 0.1404 - val_loss: 0.0329 - val_mae: 0.1395\n",
      "Epoch 85/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0346 - mae: 0.1427 - val_loss: 0.0327 - val_mae: 0.1384\n",
      "Epoch 86/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0334 - mae: 0.1397 - val_loss: 0.0328 - val_mae: 0.1395\n",
      "Epoch 87/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0347 - mae: 0.1427 - val_loss: 0.0331 - val_mae: 0.1393\n",
      "Epoch 88/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0348 - mae: 0.1437 - val_loss: 0.0330 - val_mae: 0.1383\n",
      "Epoch 89/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0337 - mae: 0.1428 - val_loss: 0.0325 - val_mae: 0.1394\n",
      "Epoch 90/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0341 - mae: 0.1430 - val_loss: 0.0326 - val_mae: 0.1380\n",
      "Epoch 91/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0343 - mae: 0.1429 - val_loss: 0.0327 - val_mae: 0.1386\n",
      "Epoch 92/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0337 - mae: 0.1418 - val_loss: 0.0332 - val_mae: 0.1408\n",
      "Epoch 93/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0337 - mae: 0.1415 - val_loss: 0.0329 - val_mae: 0.1400\n",
      "Epoch 94/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0331 - mae: 0.1398 - val_loss: 0.0325 - val_mae: 0.1379\n",
      "Epoch 95/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0343 - mae: 0.1431 - val_loss: 0.0324 - val_mae: 0.1372\n",
      "Epoch 96/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0332 - mae: 0.1402 - val_loss: 0.0327 - val_mae: 0.1383\n",
      "Epoch 97/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0343 - mae: 0.1433 - val_loss: 0.0341 - val_mae: 0.1406\n",
      "Epoch 98/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0348 - mae: 0.1441 - val_loss: 0.0329 - val_mae: 0.1399\n",
      "Epoch 99/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0340 - mae: 0.1421 - val_loss: 0.0327 - val_mae: 0.1388\n",
      "Epoch 100/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0332 - mae: 0.1406 - val_loss: 0.0327 - val_mae: 0.1400\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0329 - mae: 0.1401\n",
      "---------------------------------------------------------\n",
      "USER 1\n",
      "---------------------------------------------------------\n",
      "K 0 FOLD\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elped\\AppData\\Local\\Temp\\ipykernel_15892\\330544952.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[numerical_features] = scaler.fit_transform(x[numerical_features])\n",
      "c:\\Users\\elped\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.4754 - mae: 0.2199 - val_loss: 0.2399 - val_mae: 0.2015\n",
      "Epoch 2/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2015 - mae: 0.2038 - val_loss: 0.1082 - val_mae: 0.1789\n",
      "Epoch 3/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0936 - mae: 0.1753 - val_loss: 0.0615 - val_mae: 0.1591\n",
      "Epoch 4/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0603 - mae: 0.1657 - val_loss: 0.0474 - val_mae: 0.1516\n",
      "Epoch 5/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0482 - mae: 0.1565 - val_loss: 0.0437 - val_mae: 0.1520\n",
      "Epoch 6/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0468 - mae: 0.1598 - val_loss: 0.0421 - val_mae: 0.1476\n",
      "Epoch 7/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0432 - mae: 0.1517 - val_loss: 0.0415 - val_mae: 0.1475\n",
      "Epoch 8/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0436 - mae: 0.1532 - val_loss: 0.0401 - val_mae: 0.1456\n",
      "Epoch 9/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0431 - mae: 0.1533 - val_loss: 0.0400 - val_mae: 0.1447\n",
      "Epoch 10/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0430 - mae: 0.1540 - val_loss: 0.0396 - val_mae: 0.1445\n",
      "Epoch 11/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0434 - mae: 0.1548 - val_loss: 0.0388 - val_mae: 0.1427\n",
      "Epoch 12/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0416 - mae: 0.1494 - val_loss: 0.0385 - val_mae: 0.1431\n",
      "Epoch 13/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0399 - mae: 0.1471 - val_loss: 0.0386 - val_mae: 0.1429\n",
      "Epoch 14/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0409 - mae: 0.1480 - val_loss: 0.0385 - val_mae: 0.1422\n",
      "Epoch 15/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0405 - mae: 0.1491 - val_loss: 0.0379 - val_mae: 0.1421\n",
      "Epoch 16/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0401 - mae: 0.1479 - val_loss: 0.0379 - val_mae: 0.1432\n",
      "Epoch 17/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0407 - mae: 0.1507 - val_loss: 0.0374 - val_mae: 0.1399\n",
      "Epoch 18/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0415 - mae: 0.1521 - val_loss: 0.0375 - val_mae: 0.1410\n",
      "Epoch 19/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0399 - mae: 0.1482 - val_loss: 0.0368 - val_mae: 0.1408\n",
      "Epoch 20/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0394 - mae: 0.1463 - val_loss: 0.0369 - val_mae: 0.1398\n",
      "Epoch 21/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0392 - mae: 0.1458 - val_loss: 0.0368 - val_mae: 0.1413\n",
      "Epoch 22/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0404 - mae: 0.1512 - val_loss: 0.0366 - val_mae: 0.1391\n",
      "Epoch 23/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0390 - mae: 0.1472 - val_loss: 0.0368 - val_mae: 0.1408\n",
      "Epoch 24/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0388 - mae: 0.1452 - val_loss: 0.0363 - val_mae: 0.1391\n",
      "Epoch 25/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0377 - mae: 0.1435 - val_loss: 0.0365 - val_mae: 0.1409\n",
      "Epoch 26/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0384 - mae: 0.1445 - val_loss: 0.0362 - val_mae: 0.1391\n",
      "Epoch 27/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0385 - mae: 0.1474 - val_loss: 0.0360 - val_mae: 0.1383\n",
      "Epoch 28/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0378 - mae: 0.1445 - val_loss: 0.0358 - val_mae: 0.1374\n",
      "Epoch 29/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0384 - mae: 0.1451 - val_loss: 0.0369 - val_mae: 0.1400\n",
      "Epoch 30/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0372 - mae: 0.1426 - val_loss: 0.0355 - val_mae: 0.1389\n",
      "Epoch 31/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0377 - mae: 0.1450 - val_loss: 0.0362 - val_mae: 0.1413\n",
      "Epoch 32/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0387 - mae: 0.1469 - val_loss: 0.0354 - val_mae: 0.1388\n",
      "Epoch 33/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0375 - mae: 0.1439 - val_loss: 0.0352 - val_mae: 0.1367\n",
      "Epoch 34/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0368 - mae: 0.1430 - val_loss: 0.0349 - val_mae: 0.1369\n",
      "Epoch 35/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0366 - mae: 0.1416 - val_loss: 0.0350 - val_mae: 0.1383\n",
      "Epoch 36/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0377 - mae: 0.1456 - val_loss: 0.0357 - val_mae: 0.1407\n",
      "Epoch 37/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0390 - mae: 0.1482 - val_loss: 0.0348 - val_mae: 0.1385\n",
      "Epoch 38/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0370 - mae: 0.1446 - val_loss: 0.0358 - val_mae: 0.1416\n",
      "Epoch 39/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0375 - mae: 0.1442 - val_loss: 0.0345 - val_mae: 0.1382\n",
      "Epoch 40/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0360 - mae: 0.1418 - val_loss: 0.0351 - val_mae: 0.1409\n",
      "Epoch 41/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0364 - mae: 0.1438 - val_loss: 0.0345 - val_mae: 0.1370\n",
      "Epoch 42/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0380 - mae: 0.1454 - val_loss: 0.0346 - val_mae: 0.1393\n",
      "Epoch 43/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0373 - mae: 0.1458 - val_loss: 0.0344 - val_mae: 0.1361\n",
      "Epoch 44/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0369 - mae: 0.1435 - val_loss: 0.0345 - val_mae: 0.1385\n",
      "Epoch 45/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0359 - mae: 0.1431 - val_loss: 0.0340 - val_mae: 0.1371\n",
      "Epoch 46/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0364 - mae: 0.1427 - val_loss: 0.0342 - val_mae: 0.1369\n",
      "Epoch 47/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0363 - mae: 0.1414 - val_loss: 0.0344 - val_mae: 0.1362\n",
      "Epoch 48/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0354 - mae: 0.1415 - val_loss: 0.0344 - val_mae: 0.1391\n",
      "Epoch 49/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0363 - mae: 0.1437 - val_loss: 0.0337 - val_mae: 0.1341\n",
      "Epoch 50/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0371 - mae: 0.1441 - val_loss: 0.0341 - val_mae: 0.1369\n",
      "Epoch 51/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0356 - mae: 0.1412 - val_loss: 0.0343 - val_mae: 0.1389\n",
      "Epoch 52/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0361 - mae: 0.1423 - val_loss: 0.0335 - val_mae: 0.1347\n",
      "Epoch 53/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0357 - mae: 0.1406 - val_loss: 0.0336 - val_mae: 0.1349\n",
      "Epoch 54/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0358 - mae: 0.1418 - val_loss: 0.0343 - val_mae: 0.1391\n",
      "Epoch 55/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0358 - mae: 0.1426 - val_loss: 0.0337 - val_mae: 0.1371\n",
      "Epoch 56/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0360 - mae: 0.1427 - val_loss: 0.0334 - val_mae: 0.1354\n",
      "Epoch 57/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0356 - mae: 0.1418 - val_loss: 0.0332 - val_mae: 0.1339\n",
      "Epoch 58/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0356 - mae: 0.1417 - val_loss: 0.0333 - val_mae: 0.1351\n",
      "Epoch 59/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0350 - mae: 0.1411 - val_loss: 0.0333 - val_mae: 0.1347\n",
      "Epoch 60/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0346 - mae: 0.1397 - val_loss: 0.0331 - val_mae: 0.1354\n",
      "Epoch 61/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0338 - mae: 0.1375 - val_loss: 0.0330 - val_mae: 0.1352\n",
      "Epoch 62/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0344 - mae: 0.1385 - val_loss: 0.0333 - val_mae: 0.1370\n",
      "Epoch 63/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0346 - mae: 0.1405 - val_loss: 0.0332 - val_mae: 0.1354\n",
      "Epoch 64/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0351 - mae: 0.1407 - val_loss: 0.0326 - val_mae: 0.1335\n",
      "Epoch 65/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0336 - mae: 0.1370 - val_loss: 0.0333 - val_mae: 0.1365\n",
      "Epoch 66/100\n",
      "\u001b[1m107/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0349 - mae: 0.1404"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 47\u001b[0m\n\u001b[0;32m     44\u001b[0m model_user_i \u001b[38;5;241m=\u001b[39m create_model_user(x_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m#fit the model with the different x, y train (for different user)\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m history_model_user_i \u001b[38;5;241m=\u001b[39m \u001b[43mfit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_user_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m#prediction\u001b[39;00m\n\u001b[0;32m     50\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m model_user_i\u001b[38;5;241m.\u001b[39mpredict(x_test)\n",
      "Cell \u001b[1;32mIn[30], line 4\u001b[0m, in \u001b[0;36mfit_model\u001b[1;34m(model, x_train, y_train, x_test, y_test)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_model\u001b[39m(model, x_train, y_train, x_test, y_test):\n\u001b[1;32m----> 4\u001b[0m     history_model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#epochs = 1,\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#verbose=1\u001b[39;49;00m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m history_model\n",
      "File \u001b[1;32mc:\\Users\\elped\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\elped\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:343\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_epoch_iterator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    333\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_epoch_iterator \u001b[38;5;241m=\u001b[39m TFEpochIterator(\n\u001b[0;32m    334\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m    335\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    341\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    342\u001b[0m     )\n\u001b[1;32m--> 343\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    353\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    354\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    355\u001b[0m }\n\u001b[0;32m    356\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32mc:\\Users\\elped\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\elped\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:427\u001b[0m, in \u001b[0;36mTensorFlowTrainer.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_metrics()\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[1;32m--> 427\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menumerate_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_test_batch_begin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\elped\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:649\u001b[0m, in \u001b[0;36mTFEpochIterator.enumerate_epoch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    647\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_iterator\n\u001b[0;32m    648\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 649\u001b[0m     iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distributed_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    650\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches:\n\u001b[0;32m    651\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\n\u001b[0;32m    652\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps_per_execution\n\u001b[0;32m    653\u001b[0m         ):\n",
      "File \u001b[1;32mc:\\Users\\elped\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:501\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly() \u001b[38;5;129;01mor\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minside_function():\n\u001b[0;32m    500\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[1;32m--> 501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43miterator_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOwnedIterator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    503\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration in eager mode or within tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\elped\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:709\u001b[0m, in \u001b[0;36mOwnedIterator.__init__\u001b[1;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[0;32m    705\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m element_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    707\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    708\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot be specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 709\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    711\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_next_call_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\elped\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:748\u001b[0m, in \u001b[0;36mOwnedIterator._create_iterator\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    745\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fulltype\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[0;32m    746\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_types)\n\u001b[0;32m    747\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource\u001b[38;5;241m.\u001b[39mop\u001b[38;5;241m.\u001b[39mexperimental_set_type(fulltype)\n\u001b[1;32m--> 748\u001b[0m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_variant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\elped\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3509\u001b[0m, in \u001b[0;36mmake_iterator\u001b[1;34m(dataset, iterator, name)\u001b[0m\n\u001b[0;32m   3507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m   3508\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3509\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3510\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMakeIterator\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   3512\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dizio_model_user = {} #in this dizio we store the model for each user\n",
    "dizio_accuracy = {} #accuracy of the model\n",
    "\n",
    "# DICTIONARY TO STORE SONG RECOMMENDATION PER USER\n",
    "reccomandations_songs_per_user={}\n",
    "\n",
    "#threshold\n",
    "threshold = 0.7\n",
    "\n",
    "#value k for k-fold\n",
    "k = 5\n",
    "\n",
    "#loop creation user and model\n",
    "for i in range(0, len(df_one_hot['User'].unique())): #i indica lo user   \n",
    "\n",
    "    print('---------------------------------------------------------')\n",
    "    print(f'USER {i}')\n",
    "\n",
    "    #def dizio\n",
    "    df_metrics_kfold = pd.DataFrame()\n",
    "\n",
    "    #select user\n",
    "    mask_user = df_one_hot['User'] == i\n",
    "    #display(mask_user)\n",
    "    user_i_df = df_one_hot[mask_user]\n",
    "    #display(user_i_df) \n",
    "\n",
    "    #cross-validation k-fold\n",
    "    kf = KFold(n_splits = k, shuffle= True, random_state= 42)\n",
    "    score_fold = []\n",
    "\n",
    "    #loop on the k-th folder\n",
    "    loop = 0\n",
    "    for train_index, test_index in kf.split(user_i_df):\n",
    "        \n",
    "        print('---------------------------------------------------------')\n",
    "        print(f'K {loop} FOLD') \n",
    "        loop = loop + 1\n",
    "\n",
    "        #return train and test\n",
    "        x_train,x_test,y_train,y_test = return_train_test_for_cross(train_index, test_index, user_i_df) #da modificare\n",
    "\n",
    "        #creation model for the specific user\n",
    "        model_user_i = create_model_user(x_train.shape[1])\n",
    "        \n",
    "        #fit the model with the different x, y train (for different user)\n",
    "        history_model_user_i = fit_model(model_user_i, x_train, y_train, x_test, y_test)\n",
    "        \n",
    "        #prediction\n",
    "        y_hat = model_user_i.predict(x_test)\n",
    "\n",
    "        #plot the metrics of the model\n",
    "        #plot_for_model(history_model_user_i)\n",
    "\n",
    "        #accuracy\n",
    "        test_loss, test_mae = model_user_i.evaluate(x_test,y_test,verbose=1)\n",
    "        #print('MSE: ', test_loss)\n",
    "        #print('MAE:', test_mae)\n",
    "\n",
    "        score_fold.append(test_mae)\n",
    "\n",
    "        #reccomandation\n",
    "        reccomandation_df = reco_function_conf_matrix(y_test, y_hat, threshold)\n",
    "        df_metrics_kfold = pd.concat([df_metrics_kfold,reccomandation_df[1]], axis = 1)\n",
    "\n",
    "    #save the model in the dictionary\n",
    "    #add also the raccomandations\n",
    "    dizio_model_user[f\"User{i}\"] = {#'model_user_i' : model_user_i,\n",
    "                                    #'history_model_user_i': history_model_user_i,\n",
    "                                    #'x_train': x_train,\n",
    "                                    #'x_test': x_test,\n",
    "                                    #'y_train': y_train,\n",
    "                                    #'y_test': y_test,\n",
    "                                    #'y_hat': y_hat,\n",
    "                                    #'recommendations:': reccomandation_df\n",
    "                                    'score_fold': score_fold,\n",
    "                                    'df_metrics_kfold_mean': pd.DataFrame(data = df_metrics_kfold.mean(axis=1), columns=['Mean_Metrics'])\n",
    "                                    } \n",
    "    #save accuracy \n",
    "    dizio_accuracy[f'User{i}'] = {\n",
    "        #'MAE' : mean_absolute_error(y_test, y_hat),\n",
    "        #'MSE' : mean_squared_error(y_test, y_hat)\n",
    "        'Mean MAE': np.mean(score_fold)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DISPLAY DICTIONARY ACCURAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'User0': {'Mean MAE': 0.13768224120140077},\n",
       " 'User1': {'Mean MAE': 0.13333794772624968},\n",
       " 'User2': {'Mean MAE': 0.09675337672233582},\n",
       " 'User3': {'Mean MAE': 0.13251740336418152},\n",
       " 'User4': {'Mean MAE': 0.13890121281147003}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dizio_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DISPLAY DF METRICS CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Mean_Metrics",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "ba41a1fb-ef10-4fda-a845-1699ea8b6e49",
       "rows": [
        [
         "Accuracy",
         "0.6383982954860479"
        ],
        [
         "Precision",
         "0.7082706766917293"
        ],
        [
         "Recall",
         "0.030630416268519034"
        ],
        [
         "F1-score",
         "0.057895971143370216"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean_Metrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.638398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.708271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.030630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-score</th>\n",
       "      <td>0.057896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Mean_Metrics\n",
       "Accuracy       0.638398\n",
       "Precision      0.708271\n",
       "Recall         0.030630\n",
       "F1-score       0.057896"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dizio_model_user['User4']['df_metrics_kfold_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "User0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "User1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "User2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "User3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "User4",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "e358f59b-f6f0-439c-89a1-bb203239dd97",
       "rows": [
        [
         "Accuracy",
         "0.6141004060573179",
         "0.6286233306021651",
         "0.7373480289859198",
         "0.7609261326908385",
         "0.6383982954860479"
        ],
        [
         "Precision",
         "0.7405555555555556",
         "0.6572682044323835",
         "0.8529758181022264",
         "0.4",
         "0.7082706766917293"
        ],
        [
         "Recall",
         "0.02368118051689751",
         "0.048071865034234315",
         "0.260069886573336",
         "0.0023976023976023976",
         "0.030630416268519034"
        ],
        [
         "F1-score",
         "0.04480153871701707",
         "0.08432743417657038",
         "0.3915957719347297",
         "0.004766437511017099",
         "0.057895971143370216"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User0</th>\n",
       "      <th>User1</th>\n",
       "      <th>User2</th>\n",
       "      <th>User3</th>\n",
       "      <th>User4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.614100</td>\n",
       "      <td>0.628623</td>\n",
       "      <td>0.737348</td>\n",
       "      <td>0.760926</td>\n",
       "      <td>0.638398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.740556</td>\n",
       "      <td>0.657268</td>\n",
       "      <td>0.852976</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.708271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.023681</td>\n",
       "      <td>0.048072</td>\n",
       "      <td>0.260070</td>\n",
       "      <td>0.002398</td>\n",
       "      <td>0.030630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-score</th>\n",
       "      <td>0.044802</td>\n",
       "      <td>0.084327</td>\n",
       "      <td>0.391596</td>\n",
       "      <td>0.004766</td>\n",
       "      <td>0.057896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              User0     User1     User2     User3     User4\n",
       "Accuracy   0.614100  0.628623  0.737348  0.760926  0.638398\n",
       "Precision  0.740556  0.657268  0.852976  0.400000  0.708271\n",
       "Recall     0.023681  0.048072  0.260070  0.002398  0.030630\n",
       "F1-score   0.044802  0.084327  0.391596  0.004766  0.057896"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_metrics_total = pd.concat([dizio_model_user['User0']['df_metrics_kfold_mean'],dizio_model_user['User1']['df_metrics_kfold_mean'],dizio_model_user['User2']['df_metrics_kfold_mean'],dizio_model_user['User3']['df_metrics_kfold_mean'],dizio_model_user['User4']['df_metrics_kfold_mean']], axis=1)\n",
    "#type(df_metrics_total)\n",
    "#df_metrics_total.columns(colume_name = ['User0','User1','User2','User3','User4'])\n",
    "df_metrics_total.columns = ['User0','User1','User2','User3','User4']\n",
    "display(df_metrics_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Mean_Metrics",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "31cf743f-ba26-4e1f-8933-d13af546a110",
       "rows": [
        [
         "Accuracy",
         "0.6758792387644578"
        ],
        [
         "Precision",
         "0.671814050956379"
        ],
        [
         "Recall",
         "0.07297019015811786"
        ],
        [
         "F1-score",
         "0.1166774306965409"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean_Metrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.675879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.671814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.072970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-score</th>\n",
       "      <td>0.116677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Mean_Metrics\n",
       "Accuracy       0.675879\n",
       "Precision      0.671814\n",
       "Recall         0.072970\n",
       "F1-score       0.116677"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_metrics_mean = pd.DataFrame(data = df_metrics_total.mean(axis=1), columns=['Mean_Metrics'])\n",
    "display(df_metrics_mean.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
