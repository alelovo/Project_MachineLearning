{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DF + LIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df that have:\n",
    "# user as numeric feature (from 0 to 5) \n",
    "%store -r merge_unique_numain_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# package that we need\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.metrics import MeanAbsolutePercentageError\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "#for the CROSS-VALIDATION\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# essential\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# not necessary in this case\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CROSS VALIDATION \n",
    "\n",
    "we want to try this approach in order to optimize our recomandation system, more in detail our NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENARALIZE CRSS VALIDATION - all users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TARGET_var\n",
    "target='valence'\n",
    "\n",
    "#FEATURES\n",
    "features=[    'spotify_track_duration_minute', 'danceability', 'energy', 'key', 'loudness',\n",
    "    'mode', 'speechiness', 'acousticness', 'tempo', 'time_signature',\n",
    "    'spotify_track_popularity', 'instrumentalness', 'liveness']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create the model\n",
    "def create_model_user(shape_x_train): #number of columns -> shape\n",
    "    \n",
    "    \n",
    "    '''model_user_i = Sequential([\n",
    "        Dense(32, input_dim=shape_x_train, activation='relu', name='first_layer'),\n",
    "        # 64 as the number of initial layer is a common choice when we build a NN --> VEDIAMO COME FUNZIA POI NEL CASO SI SISTEMA IN SEGUITO\n",
    "        # input_dim: take the dimension of the x_train array --> that is equivalent to the number of feature in input\n",
    "        \n",
    "        # SI POSSONO AGGIUNGERE PER OGNI LAYER --> Dropout(0.3) per evitare overfitting\n",
    "        \n",
    "\n",
    "        Dense(16, activation='relu', name='secod_layer'),\n",
    "        Dense(1, activation='linear', name='final_layer')\n",
    "    ])'''\n",
    "\n",
    "    model_user_i = Sequential([\n",
    "        \n",
    "        Dense(32,input_dim=shape_x_train,activation='relu',name='first_layer',kernel_regularizer=l2(0.01)),\n",
    "        # 64 as the number of initial layer is a common choice when we build a NN --> VEDIAMO COME FUNZIA POI NEL CASO SI SISTEMA IN SEGUITO\n",
    "        # input_dim: take the dimension of the x_train array --> that is equivalent to the number of feature in input\n",
    "        \n",
    "        # SI POSSONO AGGIUNGERE PER OGNI LAYER --> Dropout(0.3) per evitare overfitting\n",
    "        Dropout(0.3),\n",
    "        Dense(16,activation='relu',name='secod_layer',kernel_regularizer=l2(0.01)),\n",
    "        Dropout(0.2),\n",
    "        #Dense(1,activation='linear',name='final_layer')\n",
    "        Dense(1,activation='sigmoid',name='final_layer') \n",
    "        #ATENZION PROVIAMO SIGMOID PRCHè CI SERVE UN OUTPUT NEL RANGE DI O E 1\n",
    "    \n",
    "    ])\n",
    "\n",
    "    #compile the model\n",
    "    model_user_i.compile(optimizer = 'adam', loss = 'mse', metrics = ['mae'])\n",
    "\n",
    "    #summary\n",
    "    #display(model_user_i.summary())\n",
    "\n",
    "    #return  the model\n",
    "    return model_user_i\n",
    "\n",
    "#function to train the model\n",
    "def fit_model(model, x_train, y_train, x_test, y_test):\n",
    "\n",
    "    history_model = model.fit(\n",
    "        x_train,y_train,\n",
    "        #validation_split=0.2,\n",
    "        validation_data = [x_test, y_test],\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        #verbose=1\n",
    "    )\n",
    "\n",
    "    return history_model\n",
    "\n",
    "def plot_for_model(history, y_hat, x_test):\n",
    "\n",
    "    #plot loss\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(history.history['loss'],color='blue',label='loss')\n",
    "    plt.plot(history.history['val_loss'],color='red',label='val_loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss function through epoch')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    #plot mean\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(history.history['mae'],color='blue',label='mae')\n",
    "    plt.plot(history.history['val_mae'],color='red',label='val_mae')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('mae')\n",
    "    plt.title('Mae function through epoch')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()   \n",
    "\n",
    "def return_train_test_for_cross(train_index, test_index, df):\n",
    "    #extract the feature and target\n",
    "    x = df[features]\n",
    "    y = df[target]\n",
    "\n",
    "    #normalization\n",
    "    scaler = StandardScaler()\n",
    "    x[features] = scaler.fit_transform(x[features])\n",
    "    #display(x)\n",
    "\n",
    "    x_train, x_test = x.iloc[train_index], x.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    #display(x_train)\n",
    "\n",
    "    return x_train,x_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "USER 0\n",
      "---------------------------------------------------------\n",
      "K 0 FOLD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elped\\AppData\\Local\\Temp\\ipykernel_13956\\4226922763.py:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[features] = scaler.fit_transform(x[features])\n",
      "c:\\Users\\elped\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.3765 - mae: 0.2001 - val_loss: 0.1739 - val_mae: 0.1652\n",
      "Epoch 2/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1484 - mae: 0.1765 - val_loss: 0.0778 - val_mae: 0.1596\n",
      "Epoch 3/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0723 - mae: 0.1667 - val_loss: 0.0490 - val_mae: 0.1547\n",
      "Epoch 4/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0502 - mae: 0.1631 - val_loss: 0.0414 - val_mae: 0.1506\n",
      "Epoch 5/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0451 - mae: 0.1616 - val_loss: 0.0393 - val_mae: 0.1503\n",
      "Epoch 6/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0422 - mae: 0.1565 - val_loss: 0.0384 - val_mae: 0.1480\n",
      "Epoch 7/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0409 - mae: 0.1540 - val_loss: 0.0380 - val_mae: 0.1473\n",
      "Epoch 8/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0412 - mae: 0.1542 - val_loss: 0.0378 - val_mae: 0.1469\n",
      "Epoch 9/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0410 - mae: 0.1538 - val_loss: 0.0373 - val_mae: 0.1458\n",
      "Epoch 10/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0404 - mae: 0.1532 - val_loss: 0.0372 - val_mae: 0.1444\n",
      "Epoch 11/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0403 - mae: 0.1527 - val_loss: 0.0367 - val_mae: 0.1466\n",
      "Epoch 12/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0404 - mae: 0.1546 - val_loss: 0.0369 - val_mae: 0.1435\n",
      "Epoch 13/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0396 - mae: 0.1508 - val_loss: 0.0364 - val_mae: 0.1438\n",
      "Epoch 14/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0407 - mae: 0.1537 - val_loss: 0.0367 - val_mae: 0.1461\n",
      "Epoch 15/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0395 - mae: 0.1513 - val_loss: 0.0359 - val_mae: 0.1442\n",
      "Epoch 16/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0392 - mae: 0.1496 - val_loss: 0.0363 - val_mae: 0.1443\n",
      "Epoch 17/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0388 - mae: 0.1501 - val_loss: 0.0357 - val_mae: 0.1427\n",
      "Epoch 18/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0388 - mae: 0.1495 - val_loss: 0.0357 - val_mae: 0.1437\n",
      "Epoch 19/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0387 - mae: 0.1503 - val_loss: 0.0357 - val_mae: 0.1432\n",
      "Epoch 20/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0394 - mae: 0.1514 - val_loss: 0.0354 - val_mae: 0.1442\n",
      "Epoch 21/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0382 - mae: 0.1499 - val_loss: 0.0353 - val_mae: 0.1427\n",
      "Epoch 22/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0381 - mae: 0.1482 - val_loss: 0.0354 - val_mae: 0.1441\n",
      "Epoch 23/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0376 - mae: 0.1475 - val_loss: 0.0350 - val_mae: 0.1427\n",
      "Epoch 24/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0378 - mae: 0.1492 - val_loss: 0.0354 - val_mae: 0.1437\n",
      "Epoch 25/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0367 - mae: 0.1469 - val_loss: 0.0351 - val_mae: 0.1411\n",
      "Epoch 26/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0386 - mae: 0.1506 - val_loss: 0.0352 - val_mae: 0.1435\n",
      "Epoch 27/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0377 - mae: 0.1491 - val_loss: 0.0351 - val_mae: 0.1422\n",
      "Epoch 28/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0382 - mae: 0.1498 - val_loss: 0.0347 - val_mae: 0.1414\n",
      "Epoch 29/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0372 - mae: 0.1475 - val_loss: 0.0347 - val_mae: 0.1424\n",
      "Epoch 30/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0376 - mae: 0.1485 - val_loss: 0.0351 - val_mae: 0.1441\n",
      "Epoch 31/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0386 - mae: 0.1512 - val_loss: 0.0345 - val_mae: 0.1417\n",
      "Epoch 32/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0374 - mae: 0.1486 - val_loss: 0.0348 - val_mae: 0.1417\n",
      "Epoch 33/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0367 - mae: 0.1471 - val_loss: 0.0344 - val_mae: 0.1427\n",
      "Epoch 34/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0370 - mae: 0.1476 - val_loss: 0.0345 - val_mae: 0.1433\n",
      "Epoch 35/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0359 - mae: 0.1451 - val_loss: 0.0344 - val_mae: 0.1426\n",
      "Epoch 36/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0376 - mae: 0.1496 - val_loss: 0.0342 - val_mae: 0.1422\n",
      "Epoch 37/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0367 - mae: 0.1473 - val_loss: 0.0344 - val_mae: 0.1428\n",
      "Epoch 38/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0361 - mae: 0.1462 - val_loss: 0.0345 - val_mae: 0.1421\n",
      "Epoch 39/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0363 - mae: 0.1461 - val_loss: 0.0340 - val_mae: 0.1420\n",
      "Epoch 40/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0366 - mae: 0.1468 - val_loss: 0.0347 - val_mae: 0.1410\n",
      "Epoch 41/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0373 - mae: 0.1485 - val_loss: 0.0346 - val_mae: 0.1425\n",
      "Epoch 42/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0362 - mae: 0.1459 - val_loss: 0.0342 - val_mae: 0.1423\n",
      "Epoch 43/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0350 - mae: 0.1440 - val_loss: 0.0340 - val_mae: 0.1412\n",
      "Epoch 44/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0357 - mae: 0.1448 - val_loss: 0.0341 - val_mae: 0.1426\n",
      "Epoch 45/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0359 - mae: 0.1461 - val_loss: 0.0341 - val_mae: 0.1410\n",
      "Epoch 46/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0366 - mae: 0.1471 - val_loss: 0.0340 - val_mae: 0.1413\n",
      "Epoch 47/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0370 - mae: 0.1496 - val_loss: 0.0342 - val_mae: 0.1405\n",
      "Epoch 48/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0356 - mae: 0.1458 - val_loss: 0.0336 - val_mae: 0.1405\n",
      "Epoch 49/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0363 - mae: 0.1461 - val_loss: 0.0341 - val_mae: 0.1406\n",
      "Epoch 50/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0366 - mae: 0.1481 - val_loss: 0.0351 - val_mae: 0.1460\n",
      "Epoch 51/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0356 - mae: 0.1448 - val_loss: 0.0350 - val_mae: 0.1453\n",
      "Epoch 52/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0361 - mae: 0.1457 - val_loss: 0.0336 - val_mae: 0.1415\n",
      "Epoch 53/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0354 - mae: 0.1444 - val_loss: 0.0350 - val_mae: 0.1456\n",
      "Epoch 54/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0365 - mae: 0.1464 - val_loss: 0.0335 - val_mae: 0.1412\n",
      "Epoch 55/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0357 - mae: 0.1454 - val_loss: 0.0333 - val_mae: 0.1404\n",
      "Epoch 56/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0359 - mae: 0.1466 - val_loss: 0.0336 - val_mae: 0.1399\n",
      "Epoch 57/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0369 - mae: 0.1485 - val_loss: 0.0335 - val_mae: 0.1415\n",
      "Epoch 58/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0354 - mae: 0.1453 - val_loss: 0.0335 - val_mae: 0.1418\n",
      "Epoch 59/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0349 - mae: 0.1450 - val_loss: 0.0333 - val_mae: 0.1401\n",
      "Epoch 60/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0356 - mae: 0.1452 - val_loss: 0.0337 - val_mae: 0.1415\n",
      "Epoch 61/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0366 - mae: 0.1483 - val_loss: 0.0333 - val_mae: 0.1402\n",
      "Epoch 62/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0358 - mae: 0.1446 - val_loss: 0.0335 - val_mae: 0.1407\n",
      "Epoch 63/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0348 - mae: 0.1440 - val_loss: 0.0337 - val_mae: 0.1430\n",
      "Epoch 64/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0357 - mae: 0.1464 - val_loss: 0.0333 - val_mae: 0.1395\n",
      "Epoch 65/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0345 - mae: 0.1420 - val_loss: 0.0333 - val_mae: 0.1416\n",
      "Epoch 66/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0344 - mae: 0.1432 - val_loss: 0.0332 - val_mae: 0.1402\n",
      "Epoch 67/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0356 - mae: 0.1461 - val_loss: 0.0333 - val_mae: 0.1422\n",
      "Epoch 68/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0356 - mae: 0.1458 - val_loss: 0.0330 - val_mae: 0.1394\n",
      "Epoch 69/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0347 - mae: 0.1441 - val_loss: 0.0332 - val_mae: 0.1408\n",
      "Epoch 70/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0348 - mae: 0.1438 - val_loss: 0.0332 - val_mae: 0.1399\n",
      "Epoch 71/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0352 - mae: 0.1453 - val_loss: 0.0334 - val_mae: 0.1404\n",
      "Epoch 72/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0339 - mae: 0.1414 - val_loss: 0.0338 - val_mae: 0.1411\n",
      "Epoch 73/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0355 - mae: 0.1447 - val_loss: 0.0333 - val_mae: 0.1397\n",
      "Epoch 74/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0359 - mae: 0.1465 - val_loss: 0.0334 - val_mae: 0.1414\n",
      "Epoch 75/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0352 - mae: 0.1448 - val_loss: 0.0333 - val_mae: 0.1415\n",
      "Epoch 76/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0350 - mae: 0.1441 - val_loss: 0.0332 - val_mae: 0.1416\n",
      "Epoch 77/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0358 - mae: 0.1475 - val_loss: 0.0332 - val_mae: 0.1397\n",
      "Epoch 78/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0341 - mae: 0.1411 - val_loss: 0.0327 - val_mae: 0.1408\n",
      "Epoch 79/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0347 - mae: 0.1433 - val_loss: 0.0334 - val_mae: 0.1406\n",
      "Epoch 80/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0350 - mae: 0.1433 - val_loss: 0.0331 - val_mae: 0.1389\n",
      "Epoch 81/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0344 - mae: 0.1435 - val_loss: 0.0329 - val_mae: 0.1398\n",
      "Epoch 82/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0355 - mae: 0.1457 - val_loss: 0.0329 - val_mae: 0.1390\n",
      "Epoch 83/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0355 - mae: 0.1455 - val_loss: 0.0331 - val_mae: 0.1404\n",
      "Epoch 84/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0357 - mae: 0.1471 - val_loss: 0.0334 - val_mae: 0.1442\n",
      "Epoch 85/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0350 - mae: 0.1454 - val_loss: 0.0328 - val_mae: 0.1403\n",
      "Epoch 86/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0358 - mae: 0.1472 - val_loss: 0.0327 - val_mae: 0.1400\n",
      "Epoch 87/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0355 - mae: 0.1449 - val_loss: 0.0335 - val_mae: 0.1405\n",
      "Epoch 88/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0346 - mae: 0.1430 - val_loss: 0.0331 - val_mae: 0.1416\n",
      "Epoch 89/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0337 - mae: 0.1415 - val_loss: 0.0324 - val_mae: 0.1386\n",
      "Epoch 90/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0356 - mae: 0.1457 - val_loss: 0.0326 - val_mae: 0.1397\n",
      "Epoch 91/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0346 - mae: 0.1435 - val_loss: 0.0328 - val_mae: 0.1398\n",
      "Epoch 92/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0356 - mae: 0.1475 - val_loss: 0.0331 - val_mae: 0.1400\n",
      "Epoch 93/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0351 - mae: 0.1440 - val_loss: 0.0326 - val_mae: 0.1391\n",
      "Epoch 94/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0346 - mae: 0.1440 - val_loss: 0.0326 - val_mae: 0.1397\n",
      "Epoch 95/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0344 - mae: 0.1435 - val_loss: 0.0327 - val_mae: 0.1393\n",
      "Epoch 96/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0354 - mae: 0.1456 - val_loss: 0.0326 - val_mae: 0.1398\n",
      "Epoch 97/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0355 - mae: 0.1459 - val_loss: 0.0324 - val_mae: 0.1394\n",
      "Epoch 98/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0351 - mae: 0.1445 - val_loss: 0.0327 - val_mae: 0.1401\n",
      "Epoch 99/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0356 - mae: 0.1461 - val_loss: 0.0321 - val_mae: 0.1383\n",
      "Epoch 100/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0341 - mae: 0.1430 - val_loss: 0.0327 - val_mae: 0.1386\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0316 - mae: 0.1353 \n",
      "---------------------------------------------------------\n",
      "K 1 FOLD\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elped\\AppData\\Local\\Temp\\ipykernel_13956\\4226922763.py:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[features] = scaler.fit_transform(x[features])\n",
      "c:\\Users\\elped\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.3608 - mae: 0.1916 - val_loss: 0.1712 - val_mae: 0.1748\n",
      "Epoch 2/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1418 - mae: 0.1746 - val_loss: 0.0792 - val_mae: 0.1693\n",
      "Epoch 3/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0700 - mae: 0.1675 - val_loss: 0.0513 - val_mae: 0.1620\n",
      "Epoch 4/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0487 - mae: 0.1607 - val_loss: 0.0439 - val_mae: 0.1596\n",
      "Epoch 5/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0442 - mae: 0.1595 - val_loss: 0.0416 - val_mae: 0.1558\n",
      "Epoch 6/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0420 - mae: 0.1568 - val_loss: 0.0410 - val_mae: 0.1527\n",
      "Epoch 7/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0399 - mae: 0.1526 - val_loss: 0.0402 - val_mae: 0.1514\n",
      "Epoch 8/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0406 - mae: 0.1536 - val_loss: 0.0400 - val_mae: 0.1534\n",
      "Epoch 9/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0400 - mae: 0.1530 - val_loss: 0.0394 - val_mae: 0.1514\n",
      "Epoch 10/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0400 - mae: 0.1521 - val_loss: 0.0390 - val_mae: 0.1491\n",
      "Epoch 11/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0391 - mae: 0.1505 - val_loss: 0.0386 - val_mae: 0.1492\n",
      "Epoch 12/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0384 - mae: 0.1494 - val_loss: 0.0383 - val_mae: 0.1479\n",
      "Epoch 13/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0387 - mae: 0.1497 - val_loss: 0.0384 - val_mae: 0.1473\n",
      "Epoch 14/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0389 - mae: 0.1498 - val_loss: 0.0378 - val_mae: 0.1463\n",
      "Epoch 15/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0383 - mae: 0.1503 - val_loss: 0.0376 - val_mae: 0.1468\n",
      "Epoch 16/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0386 - mae: 0.1498 - val_loss: 0.0375 - val_mae: 0.1452\n",
      "Epoch 17/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0376 - mae: 0.1480 - val_loss: 0.0374 - val_mae: 0.1460\n",
      "Epoch 18/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0378 - mae: 0.1487 - val_loss: 0.0374 - val_mae: 0.1485\n",
      "Epoch 19/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0363 - mae: 0.1455 - val_loss: 0.0370 - val_mae: 0.1459\n",
      "Epoch 20/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0359 - mae: 0.1432 - val_loss: 0.0371 - val_mae: 0.1441\n",
      "Epoch 21/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0379 - mae: 0.1486 - val_loss: 0.0368 - val_mae: 0.1452\n",
      "Epoch 22/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0373 - mae: 0.1476 - val_loss: 0.0371 - val_mae: 0.1479\n",
      "Epoch 23/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0378 - mae: 0.1485 - val_loss: 0.0378 - val_mae: 0.1457\n",
      "Epoch 24/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0382 - mae: 0.1498 - val_loss: 0.0364 - val_mae: 0.1447\n",
      "Epoch 25/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0369 - mae: 0.1470 - val_loss: 0.0365 - val_mae: 0.1441\n",
      "Epoch 26/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0371 - mae: 0.1484 - val_loss: 0.0365 - val_mae: 0.1433\n",
      "Epoch 27/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0370 - mae: 0.1475 - val_loss: 0.0369 - val_mae: 0.1474\n",
      "Epoch 28/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0364 - mae: 0.1455 - val_loss: 0.0361 - val_mae: 0.1447\n",
      "Epoch 29/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0355 - mae: 0.1445 - val_loss: 0.0363 - val_mae: 0.1462\n",
      "Epoch 30/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0358 - mae: 0.1456 - val_loss: 0.0358 - val_mae: 0.1422\n",
      "Epoch 31/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0365 - mae: 0.1466 - val_loss: 0.0361 - val_mae: 0.1457\n",
      "Epoch 32/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0358 - mae: 0.1462 - val_loss: 0.0360 - val_mae: 0.1460\n",
      "Epoch 33/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0363 - mae: 0.1471 - val_loss: 0.0375 - val_mae: 0.1461\n",
      "Epoch 34/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0365 - mae: 0.1472 - val_loss: 0.0361 - val_mae: 0.1433\n",
      "Epoch 35/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0368 - mae: 0.1468 - val_loss: 0.0361 - val_mae: 0.1459\n",
      "Epoch 36/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0360 - mae: 0.1447 - val_loss: 0.0359 - val_mae: 0.1455\n",
      "Epoch 37/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0367 - mae: 0.1486 - val_loss: 0.0357 - val_mae: 0.1408\n",
      "Epoch 38/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0363 - mae: 0.1451 - val_loss: 0.0364 - val_mae: 0.1450\n",
      "Epoch 39/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0358 - mae: 0.1461 - val_loss: 0.0354 - val_mae: 0.1427\n",
      "Epoch 40/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0355 - mae: 0.1448 - val_loss: 0.0352 - val_mae: 0.1424\n",
      "Epoch 41/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0353 - mae: 0.1440 - val_loss: 0.0354 - val_mae: 0.1428\n",
      "Epoch 42/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0358 - mae: 0.1459 - val_loss: 0.0356 - val_mae: 0.1455\n",
      "Epoch 43/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0362 - mae: 0.1472 - val_loss: 0.0356 - val_mae: 0.1439\n",
      "Epoch 44/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0359 - mae: 0.1449 - val_loss: 0.0355 - val_mae: 0.1424\n",
      "Epoch 45/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0353 - mae: 0.1447 - val_loss: 0.0354 - val_mae: 0.1431\n",
      "Epoch 46/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0351 - mae: 0.1445 - val_loss: 0.0350 - val_mae: 0.1410\n",
      "Epoch 47/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0353 - mae: 0.1445 - val_loss: 0.0356 - val_mae: 0.1427\n",
      "Epoch 48/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0359 - mae: 0.1452 - val_loss: 0.0349 - val_mae: 0.1410\n",
      "Epoch 49/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0352 - mae: 0.1436 - val_loss: 0.0351 - val_mae: 0.1443\n",
      "Epoch 50/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0361 - mae: 0.1471 - val_loss: 0.0348 - val_mae: 0.1410\n",
      "Epoch 51/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0365 - mae: 0.1465 - val_loss: 0.0351 - val_mae: 0.1437\n",
      "Epoch 52/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0355 - mae: 0.1458 - val_loss: 0.0350 - val_mae: 0.1443\n",
      "Epoch 53/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0344 - mae: 0.1426 - val_loss: 0.0356 - val_mae: 0.1419\n",
      "Epoch 54/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0350 - mae: 0.1441 - val_loss: 0.0344 - val_mae: 0.1411\n",
      "Epoch 55/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0357 - mae: 0.1461 - val_loss: 0.0353 - val_mae: 0.1462\n",
      "Epoch 56/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0351 - mae: 0.1455 - val_loss: 0.0347 - val_mae: 0.1432\n",
      "Epoch 57/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0358 - mae: 0.1465 - val_loss: 0.0349 - val_mae: 0.1434\n",
      "Epoch 58/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0346 - mae: 0.1427 - val_loss: 0.0346 - val_mae: 0.1413\n",
      "Epoch 59/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0359 - mae: 0.1469 - val_loss: 0.0346 - val_mae: 0.1431\n",
      "Epoch 60/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0350 - mae: 0.1449 - val_loss: 0.0352 - val_mae: 0.1448\n",
      "Epoch 61/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0352 - mae: 0.1447 - val_loss: 0.0343 - val_mae: 0.1416\n",
      "Epoch 62/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0344 - mae: 0.1420 - val_loss: 0.0346 - val_mae: 0.1418\n",
      "Epoch 63/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0351 - mae: 0.1447 - val_loss: 0.0354 - val_mae: 0.1442\n",
      "Epoch 64/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0357 - mae: 0.1461 - val_loss: 0.0348 - val_mae: 0.1417\n",
      "Epoch 65/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0346 - mae: 0.1423 - val_loss: 0.0343 - val_mae: 0.1429\n",
      "Epoch 66/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0359 - mae: 0.1478 - val_loss: 0.0345 - val_mae: 0.1416\n",
      "Epoch 67/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0340 - mae: 0.1417 - val_loss: 0.0347 - val_mae: 0.1435\n",
      "Epoch 68/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0347 - mae: 0.1442 - val_loss: 0.0341 - val_mae: 0.1415\n",
      "Epoch 69/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0344 - mae: 0.1423 - val_loss: 0.0346 - val_mae: 0.1426\n",
      "Epoch 70/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0340 - mae: 0.1432 - val_loss: 0.0342 - val_mae: 0.1425\n",
      "Epoch 71/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0351 - mae: 0.1456 - val_loss: 0.0346 - val_mae: 0.1428\n",
      "Epoch 72/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0357 - mae: 0.1473 - val_loss: 0.0343 - val_mae: 0.1413\n",
      "Epoch 73/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0352 - mae: 0.1458 - val_loss: 0.0342 - val_mae: 0.1426\n",
      "Epoch 74/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0348 - mae: 0.1446 - val_loss: 0.0343 - val_mae: 0.1416\n",
      "Epoch 75/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0350 - mae: 0.1457 - val_loss: 0.0340 - val_mae: 0.1402\n",
      "Epoch 76/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0343 - mae: 0.1429 - val_loss: 0.0347 - val_mae: 0.1416\n",
      "Epoch 77/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0357 - mae: 0.1468 - val_loss: 0.0343 - val_mae: 0.1414\n",
      "Epoch 78/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0342 - mae: 0.1431 - val_loss: 0.0347 - val_mae: 0.1450\n",
      "Epoch 79/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0352 - mae: 0.1445 - val_loss: 0.0345 - val_mae: 0.1422\n",
      "Epoch 80/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0350 - mae: 0.1441 - val_loss: 0.0346 - val_mae: 0.1415\n",
      "Epoch 81/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0342 - mae: 0.1426 - val_loss: 0.0342 - val_mae: 0.1417\n",
      "Epoch 82/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0354 - mae: 0.1452 - val_loss: 0.0344 - val_mae: 0.1423\n",
      "Epoch 83/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0340 - mae: 0.1434 - val_loss: 0.0343 - val_mae: 0.1428\n",
      "Epoch 84/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0344 - mae: 0.1432 - val_loss: 0.0339 - val_mae: 0.1400\n",
      "Epoch 85/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0343 - mae: 0.1430 - val_loss: 0.0341 - val_mae: 0.1410\n",
      "Epoch 86/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0331 - mae: 0.1413 - val_loss: 0.0340 - val_mae: 0.1415\n",
      "Epoch 87/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0347 - mae: 0.1438 - val_loss: 0.0342 - val_mae: 0.1405\n",
      "Epoch 88/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0331 - mae: 0.1414 - val_loss: 0.0340 - val_mae: 0.1406\n",
      "Epoch 89/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0346 - mae: 0.1445 - val_loss: 0.0345 - val_mae: 0.1422\n",
      "Epoch 90/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0353 - mae: 0.1464 - val_loss: 0.0342 - val_mae: 0.1414\n",
      "Epoch 91/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0345 - mae: 0.1437 - val_loss: 0.0343 - val_mae: 0.1398\n",
      "Epoch 92/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0342 - mae: 0.1437 - val_loss: 0.0339 - val_mae: 0.1424\n",
      "Epoch 93/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0331 - mae: 0.1408 - val_loss: 0.0345 - val_mae: 0.1448\n",
      "Epoch 94/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0354 - mae: 0.1452 - val_loss: 0.0340 - val_mae: 0.1421\n",
      "Epoch 95/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0342 - mae: 0.1448 - val_loss: 0.0340 - val_mae: 0.1415\n",
      "Epoch 96/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0348 - mae: 0.1438 - val_loss: 0.0339 - val_mae: 0.1405\n",
      "Epoch 97/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0346 - mae: 0.1439 - val_loss: 0.0339 - val_mae: 0.1413\n",
      "Epoch 98/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0343 - mae: 0.1435 - val_loss: 0.0339 - val_mae: 0.1417\n",
      "Epoch 99/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0351 - mae: 0.1459 - val_loss: 0.0339 - val_mae: 0.1422\n",
      "Epoch 100/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0338 - mae: 0.1428 - val_loss: 0.0342 - val_mae: 0.1443\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0322 - mae: 0.1399 \n",
      "---------------------------------------------------------\n",
      "K 2 FOLD\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elped\\AppData\\Local\\Temp\\ipykernel_13956\\4226922763.py:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[features] = scaler.fit_transform(x[features])\n",
      "c:\\Users\\elped\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.3831 - mae: 0.2216 - val_loss: 0.1730 - val_mae: 0.1811\n",
      "Epoch 2/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1390 - mae: 0.1738 - val_loss: 0.0795 - val_mae: 0.1750\n",
      "Epoch 3/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0700 - mae: 0.1710 - val_loss: 0.0532 - val_mae: 0.1704\n",
      "Epoch 4/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0500 - mae: 0.1655 - val_loss: 0.0458 - val_mae: 0.1647\n",
      "Epoch 5/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0442 - mae: 0.1606 - val_loss: 0.0433 - val_mae: 0.1607\n",
      "Epoch 6/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0415 - mae: 0.1552 - val_loss: 0.0422 - val_mae: 0.1573\n",
      "Epoch 7/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0421 - mae: 0.1558 - val_loss: 0.0416 - val_mae: 0.1573\n",
      "Epoch 8/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0407 - mae: 0.1525 - val_loss: 0.0408 - val_mae: 0.1552\n",
      "Epoch 9/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0408 - mae: 0.1544 - val_loss: 0.0403 - val_mae: 0.1531\n",
      "Epoch 10/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0418 - mae: 0.1559 - val_loss: 0.0400 - val_mae: 0.1537\n",
      "Epoch 11/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0395 - mae: 0.1501 - val_loss: 0.0397 - val_mae: 0.1528\n",
      "Epoch 12/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0402 - mae: 0.1519 - val_loss: 0.0397 - val_mae: 0.1533\n",
      "Epoch 13/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0399 - mae: 0.1504 - val_loss: 0.0392 - val_mae: 0.1521\n",
      "Epoch 14/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0411 - mae: 0.1556 - val_loss: 0.0387 - val_mae: 0.1516\n",
      "Epoch 15/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0389 - mae: 0.1498 - val_loss: 0.0388 - val_mae: 0.1521\n",
      "Epoch 16/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0387 - mae: 0.1488 - val_loss: 0.0380 - val_mae: 0.1499\n",
      "Epoch 17/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0380 - mae: 0.1464 - val_loss: 0.0384 - val_mae: 0.1519\n",
      "Epoch 18/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0382 - mae: 0.1487 - val_loss: 0.0378 - val_mae: 0.1495\n",
      "Epoch 19/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0385 - mae: 0.1505 - val_loss: 0.0375 - val_mae: 0.1480\n",
      "Epoch 20/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0388 - mae: 0.1494 - val_loss: 0.0377 - val_mae: 0.1504\n",
      "Epoch 21/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0387 - mae: 0.1499 - val_loss: 0.0372 - val_mae: 0.1485\n",
      "Epoch 22/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0376 - mae: 0.1478 - val_loss: 0.0372 - val_mae: 0.1485\n",
      "Epoch 23/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0379 - mae: 0.1487 - val_loss: 0.0369 - val_mae: 0.1474\n",
      "Epoch 24/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0375 - mae: 0.1473 - val_loss: 0.0368 - val_mae: 0.1479\n",
      "Epoch 25/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0366 - mae: 0.1458 - val_loss: 0.0368 - val_mae: 0.1477\n",
      "Epoch 26/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0377 - mae: 0.1487 - val_loss: 0.0365 - val_mae: 0.1470\n",
      "Epoch 27/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0380 - mae: 0.1486 - val_loss: 0.0362 - val_mae: 0.1452\n",
      "Epoch 28/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0370 - mae: 0.1455 - val_loss: 0.0362 - val_mae: 0.1468\n",
      "Epoch 29/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0359 - mae: 0.1437 - val_loss: 0.0368 - val_mae: 0.1477\n",
      "Epoch 30/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0371 - mae: 0.1478 - val_loss: 0.0365 - val_mae: 0.1477\n",
      "Epoch 31/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0373 - mae: 0.1489 - val_loss: 0.0360 - val_mae: 0.1473\n",
      "Epoch 32/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0370 - mae: 0.1471 - val_loss: 0.0361 - val_mae: 0.1462\n",
      "Epoch 33/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0384 - mae: 0.1495 - val_loss: 0.0364 - val_mae: 0.1483\n",
      "Epoch 34/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0356 - mae: 0.1448 - val_loss: 0.0364 - val_mae: 0.1491\n",
      "Epoch 35/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0363 - mae: 0.1459 - val_loss: 0.0358 - val_mae: 0.1467\n",
      "Epoch 36/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0366 - mae: 0.1472 - val_loss: 0.0357 - val_mae: 0.1467\n",
      "Epoch 37/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0348 - mae: 0.1418 - val_loss: 0.0355 - val_mae: 0.1464\n",
      "Epoch 38/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0358 - mae: 0.1449 - val_loss: 0.0356 - val_mae: 0.1455\n",
      "Epoch 39/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0366 - mae: 0.1473 - val_loss: 0.0350 - val_mae: 0.1444\n",
      "Epoch 40/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0366 - mae: 0.1464 - val_loss: 0.0359 - val_mae: 0.1473\n",
      "Epoch 41/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0364 - mae: 0.1477 - val_loss: 0.0358 - val_mae: 0.1460\n",
      "Epoch 42/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0369 - mae: 0.1474 - val_loss: 0.0356 - val_mae: 0.1475\n",
      "Epoch 43/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0364 - mae: 0.1466 - val_loss: 0.0349 - val_mae: 0.1455\n",
      "Epoch 44/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0365 - mae: 0.1466 - val_loss: 0.0359 - val_mae: 0.1469\n",
      "Epoch 45/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0366 - mae: 0.1475 - val_loss: 0.0353 - val_mae: 0.1467\n",
      "Epoch 46/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0357 - mae: 0.1467 - val_loss: 0.0352 - val_mae: 0.1464\n",
      "Epoch 47/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0370 - mae: 0.1495 - val_loss: 0.0352 - val_mae: 0.1462\n",
      "Epoch 48/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0367 - mae: 0.1481 - val_loss: 0.0349 - val_mae: 0.1453\n",
      "Epoch 49/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0355 - mae: 0.1457 - val_loss: 0.0365 - val_mae: 0.1479\n",
      "Epoch 50/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0362 - mae: 0.1456 - val_loss: 0.0348 - val_mae: 0.1449\n",
      "Epoch 51/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0361 - mae: 0.1458 - val_loss: 0.0350 - val_mae: 0.1444\n",
      "Epoch 52/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0358 - mae: 0.1446 - val_loss: 0.0345 - val_mae: 0.1446\n",
      "Epoch 53/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0349 - mae: 0.1443 - val_loss: 0.0351 - val_mae: 0.1450\n",
      "Epoch 54/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0357 - mae: 0.1464 - val_loss: 0.0347 - val_mae: 0.1446\n",
      "Epoch 55/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0347 - mae: 0.1426 - val_loss: 0.0344 - val_mae: 0.1449\n",
      "Epoch 56/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0361 - mae: 0.1458 - val_loss: 0.0346 - val_mae: 0.1453\n",
      "Epoch 57/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0351 - mae: 0.1450 - val_loss: 0.0346 - val_mae: 0.1440\n",
      "Epoch 58/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0344 - mae: 0.1432 - val_loss: 0.0345 - val_mae: 0.1450\n",
      "Epoch 59/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0354 - mae: 0.1456 - val_loss: 0.0346 - val_mae: 0.1443\n",
      "Epoch 60/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0358 - mae: 0.1455 - val_loss: 0.0344 - val_mae: 0.1427\n",
      "Epoch 61/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0354 - mae: 0.1440 - val_loss: 0.0344 - val_mae: 0.1443\n",
      "Epoch 62/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0356 - mae: 0.1454 - val_loss: 0.0340 - val_mae: 0.1427\n",
      "Epoch 63/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0349 - mae: 0.1434 - val_loss: 0.0341 - val_mae: 0.1434\n",
      "Epoch 64/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0357 - mae: 0.1467 - val_loss: 0.0341 - val_mae: 0.1439\n",
      "Epoch 65/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0353 - mae: 0.1466 - val_loss: 0.0342 - val_mae: 0.1428\n",
      "Epoch 66/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0341 - mae: 0.1409 - val_loss: 0.0344 - val_mae: 0.1438\n",
      "Epoch 67/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0339 - mae: 0.1421 - val_loss: 0.0344 - val_mae: 0.1446\n",
      "Epoch 68/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0341 - mae: 0.1425 - val_loss: 0.0343 - val_mae: 0.1441\n",
      "Epoch 69/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0352 - mae: 0.1450 - val_loss: 0.0350 - val_mae: 0.1456\n",
      "Epoch 70/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0360 - mae: 0.1467 - val_loss: 0.0341 - val_mae: 0.1436\n",
      "Epoch 71/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0349 - mae: 0.1449 - val_loss: 0.0338 - val_mae: 0.1425\n",
      "Epoch 72/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0350 - mae: 0.1452 - val_loss: 0.0345 - val_mae: 0.1448\n",
      "Epoch 73/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0355 - mae: 0.1469 - val_loss: 0.0338 - val_mae: 0.1428\n",
      "Epoch 74/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0347 - mae: 0.1441 - val_loss: 0.0337 - val_mae: 0.1417\n",
      "Epoch 75/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0358 - mae: 0.1450 - val_loss: 0.0339 - val_mae: 0.1428\n",
      "Epoch 76/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0351 - mae: 0.1458 - val_loss: 0.0342 - val_mae: 0.1442\n",
      "Epoch 77/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0341 - mae: 0.1434 - val_loss: 0.0344 - val_mae: 0.1442\n",
      "Epoch 78/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0346 - mae: 0.1429 - val_loss: 0.0341 - val_mae: 0.1447\n",
      "Epoch 79/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0341 - mae: 0.1429 - val_loss: 0.0342 - val_mae: 0.1443\n",
      "Epoch 80/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0351 - mae: 0.1459 - val_loss: 0.0338 - val_mae: 0.1432\n",
      "Epoch 81/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0345 - mae: 0.1426 - val_loss: 0.0343 - val_mae: 0.1441\n",
      "Epoch 82/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0350 - mae: 0.1446 - val_loss: 0.0344 - val_mae: 0.1455\n",
      "Epoch 83/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0350 - mae: 0.1446 - val_loss: 0.0337 - val_mae: 0.1422\n",
      "Epoch 84/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0345 - mae: 0.1441 - val_loss: 0.0338 - val_mae: 0.1430\n",
      "Epoch 85/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0345 - mae: 0.1432 - val_loss: 0.0337 - val_mae: 0.1427\n",
      "Epoch 86/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0345 - mae: 0.1434 - val_loss: 0.0339 - val_mae: 0.1436\n",
      "Epoch 87/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0358 - mae: 0.1458 - val_loss: 0.0335 - val_mae: 0.1423\n",
      "Epoch 88/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0356 - mae: 0.1457 - val_loss: 0.0335 - val_mae: 0.1420\n",
      "Epoch 89/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0352 - mae: 0.1449 - val_loss: 0.0335 - val_mae: 0.1418\n",
      "Epoch 90/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0356 - mae: 0.1468 - val_loss: 0.0337 - val_mae: 0.1435\n",
      "Epoch 91/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0345 - mae: 0.1432 - val_loss: 0.0338 - val_mae: 0.1425\n",
      "Epoch 92/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0332 - mae: 0.1401 - val_loss: 0.0335 - val_mae: 0.1424\n",
      "Epoch 93/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0348 - mae: 0.1433 - val_loss: 0.0341 - val_mae: 0.1442\n",
      "Epoch 94/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0350 - mae: 0.1449 - val_loss: 0.0337 - val_mae: 0.1433\n",
      "Epoch 95/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0342 - mae: 0.1431 - val_loss: 0.0339 - val_mae: 0.1427\n",
      "Epoch 96/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0348 - mae: 0.1438 - val_loss: 0.0336 - val_mae: 0.1422\n",
      "Epoch 97/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0347 - mae: 0.1431 - val_loss: 0.0338 - val_mae: 0.1425\n",
      "Epoch 98/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0344 - mae: 0.1440 - val_loss: 0.0335 - val_mae: 0.1422\n",
      "Epoch 99/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0354 - mae: 0.1456 - val_loss: 0.0335 - val_mae: 0.1418\n",
      "Epoch 100/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0352 - mae: 0.1446 - val_loss: 0.0338 - val_mae: 0.1429\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0350 - mae: 0.1454 \n",
      "---------------------------------------------------------\n",
      "K 3 FOLD\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elped\\AppData\\Local\\Temp\\ipykernel_13956\\4226922763.py:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[features] = scaler.fit_transform(x[features])\n",
      "c:\\Users\\elped\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.3645 - mae: 0.1920 - val_loss: 0.1746 - val_mae: 0.1721\n",
      "Epoch 2/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1454 - mae: 0.1728 - val_loss: 0.0797 - val_mae: 0.1637\n",
      "Epoch 3/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0725 - mae: 0.1669 - val_loss: 0.0499 - val_mae: 0.1573\n",
      "Epoch 4/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0505 - mae: 0.1616 - val_loss: 0.0415 - val_mae: 0.1538\n",
      "Epoch 5/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0431 - mae: 0.1567 - val_loss: 0.0393 - val_mae: 0.1502\n",
      "Epoch 6/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0408 - mae: 0.1527 - val_loss: 0.0380 - val_mae: 0.1484\n",
      "Epoch 7/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0406 - mae: 0.1523 - val_loss: 0.0375 - val_mae: 0.1474\n",
      "Epoch 8/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0395 - mae: 0.1502 - val_loss: 0.0370 - val_mae: 0.1457\n",
      "Epoch 9/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0397 - mae: 0.1510 - val_loss: 0.0365 - val_mae: 0.1450\n",
      "Epoch 10/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0411 - mae: 0.1545 - val_loss: 0.0368 - val_mae: 0.1469\n",
      "Epoch 11/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0395 - mae: 0.1498 - val_loss: 0.0375 - val_mae: 0.1511\n",
      "Epoch 12/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0377 - mae: 0.1477 - val_loss: 0.0363 - val_mae: 0.1461\n",
      "Epoch 13/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0386 - mae: 0.1493 - val_loss: 0.0362 - val_mae: 0.1466\n",
      "Epoch 14/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0390 - mae: 0.1520 - val_loss: 0.0367 - val_mae: 0.1478\n",
      "Epoch 15/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0370 - mae: 0.1462 - val_loss: 0.0356 - val_mae: 0.1446\n",
      "Epoch 16/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0384 - mae: 0.1488 - val_loss: 0.0354 - val_mae: 0.1432\n",
      "Epoch 17/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0386 - mae: 0.1503 - val_loss: 0.0356 - val_mae: 0.1444\n",
      "Epoch 18/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0373 - mae: 0.1477 - val_loss: 0.0353 - val_mae: 0.1445\n",
      "Epoch 19/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0388 - mae: 0.1510 - val_loss: 0.0356 - val_mae: 0.1439\n",
      "Epoch 20/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0382 - mae: 0.1496 - val_loss: 0.0346 - val_mae: 0.1417\n",
      "Epoch 21/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0379 - mae: 0.1495 - val_loss: 0.0350 - val_mae: 0.1436\n",
      "Epoch 22/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0365 - mae: 0.1459 - val_loss: 0.0346 - val_mae: 0.1419\n",
      "Epoch 23/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0369 - mae: 0.1463 - val_loss: 0.0345 - val_mae: 0.1416\n",
      "Epoch 24/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0377 - mae: 0.1485 - val_loss: 0.0347 - val_mae: 0.1439\n",
      "Epoch 25/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0370 - mae: 0.1472 - val_loss: 0.0347 - val_mae: 0.1435\n",
      "Epoch 26/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0374 - mae: 0.1488 - val_loss: 0.0350 - val_mae: 0.1452\n",
      "Epoch 27/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0381 - mae: 0.1502 - val_loss: 0.0341 - val_mae: 0.1414\n",
      "Epoch 28/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0376 - mae: 0.1500 - val_loss: 0.0345 - val_mae: 0.1425\n",
      "Epoch 29/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0372 - mae: 0.1474 - val_loss: 0.0344 - val_mae: 0.1431\n",
      "Epoch 30/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0360 - mae: 0.1446 - val_loss: 0.0342 - val_mae: 0.1414\n",
      "Epoch 31/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0371 - mae: 0.1479 - val_loss: 0.0337 - val_mae: 0.1409\n",
      "Epoch 32/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0371 - mae: 0.1480 - val_loss: 0.0352 - val_mae: 0.1471\n",
      "Epoch 33/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0363 - mae: 0.1464 - val_loss: 0.0339 - val_mae: 0.1414\n",
      "Epoch 34/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0367 - mae: 0.1475 - val_loss: 0.0344 - val_mae: 0.1440\n",
      "Epoch 35/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0371 - mae: 0.1483 - val_loss: 0.0336 - val_mae: 0.1395\n",
      "Epoch 36/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0359 - mae: 0.1455 - val_loss: 0.0338 - val_mae: 0.1423\n",
      "Epoch 37/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0366 - mae: 0.1474 - val_loss: 0.0344 - val_mae: 0.1410\n",
      "Epoch 38/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0383 - mae: 0.1515 - val_loss: 0.0341 - val_mae: 0.1427\n",
      "Epoch 39/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0360 - mae: 0.1462 - val_loss: 0.0362 - val_mae: 0.1507\n",
      "Epoch 40/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0365 - mae: 0.1480 - val_loss: 0.0334 - val_mae: 0.1409\n",
      "Epoch 41/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0356 - mae: 0.1456 - val_loss: 0.0340 - val_mae: 0.1430\n",
      "Epoch 42/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0360 - mae: 0.1471 - val_loss: 0.0335 - val_mae: 0.1420\n",
      "Epoch 43/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0362 - mae: 0.1474 - val_loss: 0.0336 - val_mae: 0.1415\n",
      "Epoch 44/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0363 - mae: 0.1471 - val_loss: 0.0346 - val_mae: 0.1457\n",
      "Epoch 45/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0361 - mae: 0.1469 - val_loss: 0.0338 - val_mae: 0.1439\n",
      "Epoch 46/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0355 - mae: 0.1454 - val_loss: 0.0344 - val_mae: 0.1451\n",
      "Epoch 47/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0348 - mae: 0.1439 - val_loss: 0.0338 - val_mae: 0.1425\n",
      "Epoch 48/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0357 - mae: 0.1442 - val_loss: 0.0332 - val_mae: 0.1395\n",
      "Epoch 49/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0354 - mae: 0.1449 - val_loss: 0.0340 - val_mae: 0.1436\n",
      "Epoch 50/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0357 - mae: 0.1469 - val_loss: 0.0331 - val_mae: 0.1397\n",
      "Epoch 51/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0360 - mae: 0.1463 - val_loss: 0.0332 - val_mae: 0.1415\n",
      "Epoch 52/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0343 - mae: 0.1424 - val_loss: 0.0336 - val_mae: 0.1422\n",
      "Epoch 53/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0348 - mae: 0.1441 - val_loss: 0.0329 - val_mae: 0.1403\n",
      "Epoch 54/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0361 - mae: 0.1462 - val_loss: 0.0341 - val_mae: 0.1438\n",
      "Epoch 55/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0339 - mae: 0.1419 - val_loss: 0.0328 - val_mae: 0.1388\n",
      "Epoch 56/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0346 - mae: 0.1430 - val_loss: 0.0332 - val_mae: 0.1419\n",
      "Epoch 57/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0354 - mae: 0.1461 - val_loss: 0.0326 - val_mae: 0.1381\n",
      "Epoch 58/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0353 - mae: 0.1445 - val_loss: 0.0330 - val_mae: 0.1393\n",
      "Epoch 59/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0360 - mae: 0.1473 - val_loss: 0.0334 - val_mae: 0.1425\n",
      "Epoch 60/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0365 - mae: 0.1483 - val_loss: 0.0338 - val_mae: 0.1432\n",
      "Epoch 61/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0356 - mae: 0.1449 - val_loss: 0.0326 - val_mae: 0.1396\n",
      "Epoch 62/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0368 - mae: 0.1497 - val_loss: 0.0330 - val_mae: 0.1419\n",
      "Epoch 63/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0354 - mae: 0.1460 - val_loss: 0.0328 - val_mae: 0.1392\n",
      "Epoch 64/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0359 - mae: 0.1448 - val_loss: 0.0327 - val_mae: 0.1401\n",
      "Epoch 65/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0356 - mae: 0.1462 - val_loss: 0.0324 - val_mae: 0.1388\n",
      "Epoch 66/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0357 - mae: 0.1460 - val_loss: 0.0329 - val_mae: 0.1418\n",
      "Epoch 67/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0355 - mae: 0.1464 - val_loss: 0.0326 - val_mae: 0.1392\n",
      "Epoch 68/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0356 - mae: 0.1453 - val_loss: 0.0326 - val_mae: 0.1409\n",
      "Epoch 69/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0350 - mae: 0.1449 - val_loss: 0.0335 - val_mae: 0.1435\n",
      "Epoch 70/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0351 - mae: 0.1452 - val_loss: 0.0325 - val_mae: 0.1402\n",
      "Epoch 71/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0350 - mae: 0.1448 - val_loss: 0.0327 - val_mae: 0.1382\n",
      "Epoch 72/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0369 - mae: 0.1491 - val_loss: 0.0329 - val_mae: 0.1414\n",
      "Epoch 73/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0354 - mae: 0.1451 - val_loss: 0.0327 - val_mae: 0.1394\n",
      "Epoch 74/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0349 - mae: 0.1444 - val_loss: 0.0328 - val_mae: 0.1414\n",
      "Epoch 75/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0360 - mae: 0.1472 - val_loss: 0.0329 - val_mae: 0.1392\n",
      "Epoch 76/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0357 - mae: 0.1457 - val_loss: 0.0326 - val_mae: 0.1411\n",
      "Epoch 77/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0351 - mae: 0.1460 - val_loss: 0.0328 - val_mae: 0.1413\n",
      "Epoch 78/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0355 - mae: 0.1460 - val_loss: 0.0327 - val_mae: 0.1402\n",
      "Epoch 79/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0354 - mae: 0.1450 - val_loss: 0.0327 - val_mae: 0.1413\n",
      "Epoch 80/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0346 - mae: 0.1434 - val_loss: 0.0324 - val_mae: 0.1400\n",
      "Epoch 81/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0348 - mae: 0.1443 - val_loss: 0.0323 - val_mae: 0.1394\n",
      "Epoch 82/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0342 - mae: 0.1427 - val_loss: 0.0329 - val_mae: 0.1426\n",
      "Epoch 83/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0354 - mae: 0.1459 - val_loss: 0.0325 - val_mae: 0.1391\n",
      "Epoch 84/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0357 - mae: 0.1462 - val_loss: 0.0325 - val_mae: 0.1407\n",
      "Epoch 85/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0350 - mae: 0.1453 - val_loss: 0.0328 - val_mae: 0.1416\n",
      "Epoch 86/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0353 - mae: 0.1460 - val_loss: 0.0326 - val_mae: 0.1385\n",
      "Epoch 87/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0355 - mae: 0.1452 - val_loss: 0.0319 - val_mae: 0.1377\n",
      "Epoch 88/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0346 - mae: 0.1437 - val_loss: 0.0320 - val_mae: 0.1377\n",
      "Epoch 89/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0355 - mae: 0.1454 - val_loss: 0.0324 - val_mae: 0.1399\n",
      "Epoch 90/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0346 - mae: 0.1434 - val_loss: 0.0326 - val_mae: 0.1413\n",
      "Epoch 91/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0344 - mae: 0.1440 - val_loss: 0.0326 - val_mae: 0.1393\n",
      "Epoch 92/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0352 - mae: 0.1446 - val_loss: 0.0324 - val_mae: 0.1386\n",
      "Epoch 93/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0350 - mae: 0.1461 - val_loss: 0.0325 - val_mae: 0.1394\n",
      "Epoch 94/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0352 - mae: 0.1445 - val_loss: 0.0323 - val_mae: 0.1389\n",
      "Epoch 95/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0343 - mae: 0.1444 - val_loss: 0.0323 - val_mae: 0.1395\n",
      "Epoch 96/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0365 - mae: 0.1494 - val_loss: 0.0328 - val_mae: 0.1382\n",
      "Epoch 97/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0341 - mae: 0.1427 - val_loss: 0.0317 - val_mae: 0.1368\n",
      "Epoch 98/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0345 - mae: 0.1436 - val_loss: 0.0322 - val_mae: 0.1389\n",
      "Epoch 99/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0344 - mae: 0.1424 - val_loss: 0.0322 - val_mae: 0.1379\n",
      "Epoch 100/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0344 - mae: 0.1432 - val_loss: 0.0322 - val_mae: 0.1399\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0319 - mae: 0.1400 \n",
      "---------------------------------------------------------\n",
      "K 4 FOLD\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elped\\AppData\\Local\\Temp\\ipykernel_13956\\4226922763.py:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[features] = scaler.fit_transform(x[features])\n",
      "c:\\Users\\elped\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.3716 - mae: 0.1887 - val_loss: 0.1797 - val_mae: 0.1749\n",
      "Epoch 2/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1491 - mae: 0.1781 - val_loss: 0.0806 - val_mae: 0.1660\n",
      "Epoch 3/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0699 - mae: 0.1631 - val_loss: 0.0503 - val_mae: 0.1576\n",
      "Epoch 4/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0478 - mae: 0.1565 - val_loss: 0.0421 - val_mae: 0.1534\n",
      "Epoch 5/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0428 - mae: 0.1566 - val_loss: 0.0402 - val_mae: 0.1516\n",
      "Epoch 6/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0403 - mae: 0.1521 - val_loss: 0.0394 - val_mae: 0.1502\n",
      "Epoch 7/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0402 - mae: 0.1523 - val_loss: 0.0389 - val_mae: 0.1493\n",
      "Epoch 8/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0398 - mae: 0.1519 - val_loss: 0.0389 - val_mae: 0.1495\n",
      "Epoch 9/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0401 - mae: 0.1523 - val_loss: 0.0380 - val_mae: 0.1470\n",
      "Epoch 10/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0387 - mae: 0.1496 - val_loss: 0.0380 - val_mae: 0.1472\n",
      "Epoch 11/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0394 - mae: 0.1515 - val_loss: 0.0375 - val_mae: 0.1458\n",
      "Epoch 12/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0388 - mae: 0.1514 - val_loss: 0.0376 - val_mae: 0.1465\n",
      "Epoch 13/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0375 - mae: 0.1471 - val_loss: 0.0374 - val_mae: 0.1474\n",
      "Epoch 14/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0373 - mae: 0.1471 - val_loss: 0.0372 - val_mae: 0.1470\n",
      "Epoch 15/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0392 - mae: 0.1518 - val_loss: 0.0377 - val_mae: 0.1488\n",
      "Epoch 16/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0376 - mae: 0.1491 - val_loss: 0.0368 - val_mae: 0.1458\n",
      "Epoch 17/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0390 - mae: 0.1518 - val_loss: 0.0365 - val_mae: 0.1458\n",
      "Epoch 18/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0375 - mae: 0.1490 - val_loss: 0.0365 - val_mae: 0.1455\n",
      "Epoch 19/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0376 - mae: 0.1487 - val_loss: 0.0366 - val_mae: 0.1455\n",
      "Epoch 20/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0386 - mae: 0.1508 - val_loss: 0.0362 - val_mae: 0.1457\n",
      "Epoch 21/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0367 - mae: 0.1477 - val_loss: 0.0361 - val_mae: 0.1449\n",
      "Epoch 22/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0378 - mae: 0.1497 - val_loss: 0.0363 - val_mae: 0.1454\n",
      "Epoch 23/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0380 - mae: 0.1486 - val_loss: 0.0361 - val_mae: 0.1454\n",
      "Epoch 24/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0365 - mae: 0.1465 - val_loss: 0.0358 - val_mae: 0.1441\n",
      "Epoch 25/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0361 - mae: 0.1453 - val_loss: 0.0363 - val_mae: 0.1452\n",
      "Epoch 26/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0370 - mae: 0.1469 - val_loss: 0.0358 - val_mae: 0.1447\n",
      "Epoch 27/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0357 - mae: 0.1442 - val_loss: 0.0357 - val_mae: 0.1429\n",
      "Epoch 28/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0373 - mae: 0.1482 - val_loss: 0.0356 - val_mae: 0.1426\n",
      "Epoch 29/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0374 - mae: 0.1489 - val_loss: 0.0359 - val_mae: 0.1457\n",
      "Epoch 30/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0369 - mae: 0.1473 - val_loss: 0.0353 - val_mae: 0.1435\n",
      "Epoch 31/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0355 - mae: 0.1447 - val_loss: 0.0354 - val_mae: 0.1446\n",
      "Epoch 32/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0367 - mae: 0.1471 - val_loss: 0.0353 - val_mae: 0.1435\n",
      "Epoch 33/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0367 - mae: 0.1470 - val_loss: 0.0351 - val_mae: 0.1426\n",
      "Epoch 34/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0363 - mae: 0.1465 - val_loss: 0.0355 - val_mae: 0.1433\n",
      "Epoch 35/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0358 - mae: 0.1464 - val_loss: 0.0358 - val_mae: 0.1421\n",
      "Epoch 36/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0349 - mae: 0.1426 - val_loss: 0.0351 - val_mae: 0.1437\n",
      "Epoch 37/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0360 - mae: 0.1459 - val_loss: 0.0348 - val_mae: 0.1433\n",
      "Epoch 38/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0360 - mae: 0.1461 - val_loss: 0.0350 - val_mae: 0.1445\n",
      "Epoch 39/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0352 - mae: 0.1458 - val_loss: 0.0350 - val_mae: 0.1427\n",
      "Epoch 40/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0355 - mae: 0.1452 - val_loss: 0.0344 - val_mae: 0.1416\n",
      "Epoch 41/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0357 - mae: 0.1452 - val_loss: 0.0346 - val_mae: 0.1432\n",
      "Epoch 42/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0350 - mae: 0.1443 - val_loss: 0.0347 - val_mae: 0.1423\n",
      "Epoch 43/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0360 - mae: 0.1469 - val_loss: 0.0348 - val_mae: 0.1432\n",
      "Epoch 44/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0351 - mae: 0.1437 - val_loss: 0.0344 - val_mae: 0.1426\n",
      "Epoch 45/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0370 - mae: 0.1495 - val_loss: 0.0346 - val_mae: 0.1435\n",
      "Epoch 46/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0353 - mae: 0.1449 - val_loss: 0.0345 - val_mae: 0.1412\n",
      "Epoch 47/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0353 - mae: 0.1442 - val_loss: 0.0341 - val_mae: 0.1410\n",
      "Epoch 48/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0351 - mae: 0.1443 - val_loss: 0.0343 - val_mae: 0.1414\n",
      "Epoch 49/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0351 - mae: 0.1455 - val_loss: 0.0342 - val_mae: 0.1426\n",
      "Epoch 50/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0354 - mae: 0.1450 - val_loss: 0.0351 - val_mae: 0.1444\n",
      "Epoch 51/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0363 - mae: 0.1483 - val_loss: 0.0343 - val_mae: 0.1424\n",
      "Epoch 52/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0359 - mae: 0.1462 - val_loss: 0.0345 - val_mae: 0.1422\n",
      "Epoch 53/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0356 - mae: 0.1453 - val_loss: 0.0342 - val_mae: 0.1436\n",
      "Epoch 54/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0360 - mae: 0.1465 - val_loss: 0.0352 - val_mae: 0.1441\n",
      "Epoch 55/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0355 - mae: 0.1450 - val_loss: 0.0345 - val_mae: 0.1419\n",
      "Epoch 56/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0361 - mae: 0.1474 - val_loss: 0.0347 - val_mae: 0.1429\n",
      "Epoch 57/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0342 - mae: 0.1423 - val_loss: 0.0342 - val_mae: 0.1410\n",
      "Epoch 58/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0360 - mae: 0.1470 - val_loss: 0.0344 - val_mae: 0.1423\n",
      "Epoch 59/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0344 - mae: 0.1424 - val_loss: 0.0345 - val_mae: 0.1440\n",
      "Epoch 60/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0344 - mae: 0.1427 - val_loss: 0.0341 - val_mae: 0.1423\n",
      "Epoch 61/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0354 - mae: 0.1458 - val_loss: 0.0337 - val_mae: 0.1390\n",
      "Epoch 62/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0351 - mae: 0.1444 - val_loss: 0.0341 - val_mae: 0.1415\n",
      "Epoch 63/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0356 - mae: 0.1460 - val_loss: 0.0346 - val_mae: 0.1429\n",
      "Epoch 64/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0344 - mae: 0.1449 - val_loss: 0.0338 - val_mae: 0.1409\n",
      "Epoch 65/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0350 - mae: 0.1441 - val_loss: 0.0338 - val_mae: 0.1403\n",
      "Epoch 66/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0339 - mae: 0.1418 - val_loss: 0.0337 - val_mae: 0.1409\n",
      "Epoch 67/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0347 - mae: 0.1444 - val_loss: 0.0335 - val_mae: 0.1393\n",
      "Epoch 68/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0359 - mae: 0.1471 - val_loss: 0.0338 - val_mae: 0.1427\n",
      "Epoch 69/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0339 - mae: 0.1426 - val_loss: 0.0338 - val_mae: 0.1428\n",
      "Epoch 70/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0339 - mae: 0.1421 - val_loss: 0.0336 - val_mae: 0.1408\n",
      "Epoch 71/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0351 - mae: 0.1453 - val_loss: 0.0338 - val_mae: 0.1404\n",
      "Epoch 72/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0352 - mae: 0.1441 - val_loss: 0.0346 - val_mae: 0.1414\n",
      "Epoch 73/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0341 - mae: 0.1418 - val_loss: 0.0345 - val_mae: 0.1434\n",
      "Epoch 74/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0345 - mae: 0.1440 - val_loss: 0.0337 - val_mae: 0.1423\n",
      "Epoch 75/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0352 - mae: 0.1458 - val_loss: 0.0339 - val_mae: 0.1411\n",
      "Epoch 76/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0345 - mae: 0.1441 - val_loss: 0.0331 - val_mae: 0.1403\n",
      "Epoch 77/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0342 - mae: 0.1428 - val_loss: 0.0335 - val_mae: 0.1403\n",
      "Epoch 78/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0337 - mae: 0.1416 - val_loss: 0.0338 - val_mae: 0.1403\n",
      "Epoch 79/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0348 - mae: 0.1436 - val_loss: 0.0338 - val_mae: 0.1408\n",
      "Epoch 80/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0351 - mae: 0.1443 - val_loss: 0.0333 - val_mae: 0.1398\n",
      "Epoch 81/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0341 - mae: 0.1426 - val_loss: 0.0334 - val_mae: 0.1410\n",
      "Epoch 82/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0343 - mae: 0.1430 - val_loss: 0.0336 - val_mae: 0.1401\n",
      "Epoch 83/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0347 - mae: 0.1431 - val_loss: 0.0333 - val_mae: 0.1414\n",
      "Epoch 84/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0344 - mae: 0.1446 - val_loss: 0.0336 - val_mae: 0.1400\n",
      "Epoch 85/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0345 - mae: 0.1435 - val_loss: 0.0336 - val_mae: 0.1412\n",
      "Epoch 86/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0330 - mae: 0.1401 - val_loss: 0.0332 - val_mae: 0.1395\n",
      "Epoch 87/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0343 - mae: 0.1431 - val_loss: 0.0335 - val_mae: 0.1423\n",
      "Epoch 88/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0349 - mae: 0.1457 - val_loss: 0.0336 - val_mae: 0.1391\n",
      "Epoch 89/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0358 - mae: 0.1456 - val_loss: 0.0333 - val_mae: 0.1402\n",
      "Epoch 90/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0342 - mae: 0.1436 - val_loss: 0.0339 - val_mae: 0.1411\n",
      "Epoch 91/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0334 - mae: 0.1408 - val_loss: 0.0334 - val_mae: 0.1406\n",
      "Epoch 92/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0344 - mae: 0.1436 - val_loss: 0.0341 - val_mae: 0.1415\n",
      "Epoch 93/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0346 - mae: 0.1423 - val_loss: 0.0330 - val_mae: 0.1405\n",
      "Epoch 94/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0333 - mae: 0.1409 - val_loss: 0.0345 - val_mae: 0.1435\n",
      "Epoch 95/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0352 - mae: 0.1452 - val_loss: 0.0336 - val_mae: 0.1393\n",
      "Epoch 96/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0356 - mae: 0.1466 - val_loss: 0.0332 - val_mae: 0.1402\n",
      "Epoch 97/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0351 - mae: 0.1441 - val_loss: 0.0331 - val_mae: 0.1403\n",
      "Epoch 98/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0344 - mae: 0.1447 - val_loss: 0.0332 - val_mae: 0.1415\n",
      "Epoch 99/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0349 - mae: 0.1447 - val_loss: 0.0342 - val_mae: 0.1428\n",
      "Epoch 100/100\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0347 - mae: 0.1442 - val_loss: 0.0330 - val_mae: 0.1410\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0333 - mae: 0.1415\n",
      "---------------------------------------------------------\n",
      "USER 1\n",
      "---------------------------------------------------------\n",
      "K 0 FOLD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elped\\AppData\\Local\\Temp\\ipykernel_13956\\4226922763.py:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[features] = scaler.fit_transform(x[features])\n",
      "c:\\Users\\elped\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.3980 - mae: 0.2170 - val_loss: 0.2202 - val_mae: 0.1909\n",
      "Epoch 2/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1917 - mae: 0.1992 - val_loss: 0.1111 - val_mae: 0.1759\n",
      "Epoch 3/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1012 - mae: 0.1821 - val_loss: 0.0652 - val_mae: 0.1585\n",
      "Epoch 4/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0621 - mae: 0.1624 - val_loss: 0.0491 - val_mae: 0.1526\n",
      "Epoch 5/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0506 - mae: 0.1608 - val_loss: 0.0435 - val_mae: 0.1476\n",
      "Epoch 6/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0449 - mae: 0.1532 - val_loss: 0.0417 - val_mae: 0.1480\n",
      "Epoch 7/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0438 - mae: 0.1547 - val_loss: 0.0405 - val_mae: 0.1450\n",
      "Epoch 8/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0436 - mae: 0.1537 - val_loss: 0.0400 - val_mae: 0.1456\n",
      "Epoch 9/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0428 - mae: 0.1525 - val_loss: 0.0398 - val_mae: 0.1458\n",
      "Epoch 10/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0432 - mae: 0.1558 - val_loss: 0.0391 - val_mae: 0.1450\n",
      "Epoch 11/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0408 - mae: 0.1478 - val_loss: 0.0385 - val_mae: 0.1434\n",
      "Epoch 12/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0397 - mae: 0.1471 - val_loss: 0.0388 - val_mae: 0.1426\n",
      "Epoch 13/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0414 - mae: 0.1515 - val_loss: 0.0383 - val_mae: 0.1424\n",
      "Epoch 14/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0413 - mae: 0.1508 - val_loss: 0.0376 - val_mae: 0.1417\n",
      "Epoch 15/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0411 - mae: 0.1517 - val_loss: 0.0380 - val_mae: 0.1425\n",
      "Epoch 16/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0415 - mae: 0.1519 - val_loss: 0.0375 - val_mae: 0.1413\n",
      "Epoch 17/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0404 - mae: 0.1485 - val_loss: 0.0374 - val_mae: 0.1423\n",
      "Epoch 18/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0399 - mae: 0.1484 - val_loss: 0.0371 - val_mae: 0.1416\n",
      "Epoch 19/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0400 - mae: 0.1506 - val_loss: 0.0373 - val_mae: 0.1408\n",
      "Epoch 20/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0399 - mae: 0.1489 - val_loss: 0.0376 - val_mae: 0.1416\n",
      "Epoch 21/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0380 - mae: 0.1465 - val_loss: 0.0373 - val_mae: 0.1422\n",
      "Epoch 22/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0385 - mae: 0.1458 - val_loss: 0.0363 - val_mae: 0.1388\n",
      "Epoch 23/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0372 - mae: 0.1420 - val_loss: 0.0364 - val_mae: 0.1387\n",
      "Epoch 24/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0383 - mae: 0.1459 - val_loss: 0.0363 - val_mae: 0.1415\n",
      "Epoch 25/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0385 - mae: 0.1482 - val_loss: 0.0360 - val_mae: 0.1402\n",
      "Epoch 26/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0379 - mae: 0.1445 - val_loss: 0.0361 - val_mae: 0.1392\n",
      "Epoch 27/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0379 - mae: 0.1452 - val_loss: 0.0359 - val_mae: 0.1386\n",
      "Epoch 28/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0387 - mae: 0.1473 - val_loss: 0.0362 - val_mae: 0.1413\n",
      "Epoch 29/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0375 - mae: 0.1452 - val_loss: 0.0361 - val_mae: 0.1378\n",
      "Epoch 30/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0387 - mae: 0.1480 - val_loss: 0.0359 - val_mae: 0.1404\n",
      "Epoch 31/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0368 - mae: 0.1428 - val_loss: 0.0360 - val_mae: 0.1403\n",
      "Epoch 32/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0377 - mae: 0.1454 - val_loss: 0.0358 - val_mae: 0.1403\n",
      "Epoch 33/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0377 - mae: 0.1451 - val_loss: 0.0352 - val_mae: 0.1396\n",
      "Epoch 34/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0357 - mae: 0.1403 - val_loss: 0.0348 - val_mae: 0.1376\n",
      "Epoch 35/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0369 - mae: 0.1447 - val_loss: 0.0358 - val_mae: 0.1399\n",
      "Epoch 36/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0375 - mae: 0.1454 - val_loss: 0.0353 - val_mae: 0.1382\n",
      "Epoch 37/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0367 - mae: 0.1428 - val_loss: 0.0349 - val_mae: 0.1382\n",
      "Epoch 38/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0363 - mae: 0.1421 - val_loss: 0.0356 - val_mae: 0.1395\n",
      "Epoch 39/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0366 - mae: 0.1428 - val_loss: 0.0349 - val_mae: 0.1397\n",
      "Epoch 40/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0377 - mae: 0.1452 - val_loss: 0.0351 - val_mae: 0.1386\n",
      "Epoch 41/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0380 - mae: 0.1466 - val_loss: 0.0345 - val_mae: 0.1358\n",
      "Epoch 42/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0363 - mae: 0.1412 - val_loss: 0.0347 - val_mae: 0.1382\n",
      "Epoch 43/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0371 - mae: 0.1440 - val_loss: 0.0347 - val_mae: 0.1364\n",
      "Epoch 44/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0364 - mae: 0.1416 - val_loss: 0.0344 - val_mae: 0.1369\n",
      "Epoch 45/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0365 - mae: 0.1433 - val_loss: 0.0342 - val_mae: 0.1378\n",
      "Epoch 46/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0378 - mae: 0.1471 - val_loss: 0.0352 - val_mae: 0.1390\n",
      "Epoch 47/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0371 - mae: 0.1466 - val_loss: 0.0349 - val_mae: 0.1398\n",
      "Epoch 48/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0361 - mae: 0.1425 - val_loss: 0.0346 - val_mae: 0.1388\n",
      "Epoch 49/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0365 - mae: 0.1439 - val_loss: 0.0343 - val_mae: 0.1360\n",
      "Epoch 50/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0361 - mae: 0.1428 - val_loss: 0.0346 - val_mae: 0.1369\n",
      "Epoch 51/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0355 - mae: 0.1407 - val_loss: 0.0344 - val_mae: 0.1381\n",
      "Epoch 52/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0357 - mae: 0.1426 - val_loss: 0.0342 - val_mae: 0.1359\n",
      "Epoch 53/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0353 - mae: 0.1405 - val_loss: 0.0342 - val_mae: 0.1358\n",
      "Epoch 54/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0359 - mae: 0.1425 - val_loss: 0.0340 - val_mae: 0.1364\n",
      "Epoch 55/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0359 - mae: 0.1425 - val_loss: 0.0334 - val_mae: 0.1354\n",
      "Epoch 56/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0366 - mae: 0.1439 - val_loss: 0.0337 - val_mae: 0.1341\n",
      "Epoch 57/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0355 - mae: 0.1414 - val_loss: 0.0341 - val_mae: 0.1368\n",
      "Epoch 58/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0347 - mae: 0.1391 - val_loss: 0.0337 - val_mae: 0.1368\n",
      "Epoch 59/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0358 - mae: 0.1431 - val_loss: 0.0340 - val_mae: 0.1380\n",
      "Epoch 60/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0346 - mae: 0.1399 - val_loss: 0.0334 - val_mae: 0.1368\n",
      "Epoch 61/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0355 - mae: 0.1411 - val_loss: 0.0338 - val_mae: 0.1379\n",
      "Epoch 62/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0353 - mae: 0.1424 - val_loss: 0.0333 - val_mae: 0.1353\n",
      "Epoch 63/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0354 - mae: 0.1418 - val_loss: 0.0340 - val_mae: 0.1378\n",
      "Epoch 64/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0365 - mae: 0.1442 - val_loss: 0.0335 - val_mae: 0.1349\n",
      "Epoch 65/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0348 - mae: 0.1399 - val_loss: 0.0332 - val_mae: 0.1364\n",
      "Epoch 66/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0344 - mae: 0.1398 - val_loss: 0.0334 - val_mae: 0.1368\n",
      "Epoch 67/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0358 - mae: 0.1421 - val_loss: 0.0332 - val_mae: 0.1351\n",
      "Epoch 68/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0349 - mae: 0.1411 - val_loss: 0.0339 - val_mae: 0.1375\n",
      "Epoch 69/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0351 - mae: 0.1412 - val_loss: 0.0332 - val_mae: 0.1384\n",
      "Epoch 70/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0354 - mae: 0.1434 - val_loss: 0.0334 - val_mae: 0.1347\n",
      "Epoch 71/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0354 - mae: 0.1414 - val_loss: 0.0336 - val_mae: 0.1343\n",
      "Epoch 72/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0350 - mae: 0.1402 - val_loss: 0.0332 - val_mae: 0.1361\n",
      "Epoch 73/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0358 - mae: 0.1431 - val_loss: 0.0328 - val_mae: 0.1331\n",
      "Epoch 74/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0337 - mae: 0.1389 - val_loss: 0.0339 - val_mae: 0.1382\n",
      "Epoch 75/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0346 - mae: 0.1417 - val_loss: 0.0332 - val_mae: 0.1354\n",
      "Epoch 76/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0342 - mae: 0.1388 - val_loss: 0.0332 - val_mae: 0.1356\n",
      "Epoch 77/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0339 - mae: 0.1390 - val_loss: 0.0332 - val_mae: 0.1365\n",
      "Epoch 78/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0343 - mae: 0.1386 - val_loss: 0.0334 - val_mae: 0.1379\n",
      "Epoch 79/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0356 - mae: 0.1435 - val_loss: 0.0334 - val_mae: 0.1377\n",
      "Epoch 80/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0349 - mae: 0.1402 - val_loss: 0.0331 - val_mae: 0.1355\n",
      "Epoch 81/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0342 - mae: 0.1388 - val_loss: 0.0328 - val_mae: 0.1351\n",
      "Epoch 82/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0335 - mae: 0.1377 - val_loss: 0.0332 - val_mae: 0.1363\n",
      "Epoch 83/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0343 - mae: 0.1400 - val_loss: 0.0331 - val_mae: 0.1345\n",
      "Epoch 84/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0347 - mae: 0.1401 - val_loss: 0.0329 - val_mae: 0.1339\n",
      "Epoch 85/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0346 - mae: 0.1402 - val_loss: 0.0340 - val_mae: 0.1395\n",
      "Epoch 86/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0342 - mae: 0.1395 - val_loss: 0.0329 - val_mae: 0.1365\n",
      "Epoch 87/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0343 - mae: 0.1397 - val_loss: 0.0328 - val_mae: 0.1331\n",
      "Epoch 88/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0343 - mae: 0.1392 - val_loss: 0.0324 - val_mae: 0.1348\n",
      "Epoch 89/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0349 - mae: 0.1419 - val_loss: 0.0327 - val_mae: 0.1343\n",
      "Epoch 90/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0352 - mae: 0.1413 - val_loss: 0.0328 - val_mae: 0.1348\n",
      "Epoch 91/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0339 - mae: 0.1396 - val_loss: 0.0327 - val_mae: 0.1356\n",
      "Epoch 92/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0350 - mae: 0.1426 - val_loss: 0.0332 - val_mae: 0.1346\n",
      "Epoch 93/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0347 - mae: 0.1401 - val_loss: 0.0332 - val_mae: 0.1337\n",
      "Epoch 94/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0347 - mae: 0.1404 - val_loss: 0.0335 - val_mae: 0.1365\n",
      "Epoch 95/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0354 - mae: 0.1428 - val_loss: 0.0331 - val_mae: 0.1376\n",
      "Epoch 96/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0350 - mae: 0.1422 - val_loss: 0.0329 - val_mae: 0.1341\n",
      "Epoch 97/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0347 - mae: 0.1405 - val_loss: 0.0325 - val_mae: 0.1359\n",
      "Epoch 98/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0349 - mae: 0.1413 - val_loss: 0.0329 - val_mae: 0.1353\n",
      "Epoch 99/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0340 - mae: 0.1393 - val_loss: 0.0327 - val_mae: 0.1346\n",
      "Epoch 100/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0345 - mae: 0.1391 - val_loss: 0.0327 - val_mae: 0.1371\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0310 - mae: 0.1320\n",
      "---------------------------------------------------------\n",
      "K 1 FOLD\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elped\\AppData\\Local\\Temp\\ipykernel_13956\\4226922763.py:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[features] = scaler.fit_transform(x[features])\n",
      "c:\\Users\\elped\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.3843 - mae: 0.2354 - val_loss: 0.2098 - val_mae: 0.1933\n",
      "Epoch 2/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1803 - mae: 0.1886 - val_loss: 0.1105 - val_mae: 0.1815\n",
      "Epoch 3/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0981 - mae: 0.1765 - val_loss: 0.0687 - val_mae: 0.1690\n",
      "Epoch 4/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0639 - mae: 0.1648 - val_loss: 0.0519 - val_mae: 0.1590\n",
      "Epoch 5/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0508 - mae: 0.1585 - val_loss: 0.0454 - val_mae: 0.1544\n",
      "Epoch 6/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0458 - mae: 0.1551 - val_loss: 0.0430 - val_mae: 0.1522\n",
      "Epoch 7/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0430 - mae: 0.1516 - val_loss: 0.0418 - val_mae: 0.1508\n",
      "Epoch 8/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0436 - mae: 0.1531 - val_loss: 0.0411 - val_mae: 0.1493\n",
      "Epoch 9/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0421 - mae: 0.1511 - val_loss: 0.0410 - val_mae: 0.1517\n",
      "Epoch 10/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0418 - mae: 0.1514 - val_loss: 0.0402 - val_mae: 0.1483\n",
      "Epoch 11/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0414 - mae: 0.1509 - val_loss: 0.0398 - val_mae: 0.1494\n",
      "Epoch 12/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0411 - mae: 0.1511 - val_loss: 0.0398 - val_mae: 0.1486\n",
      "Epoch 13/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0417 - mae: 0.1513 - val_loss: 0.0392 - val_mae: 0.1463\n",
      "Epoch 14/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0397 - mae: 0.1477 - val_loss: 0.0402 - val_mae: 0.1513\n",
      "Epoch 15/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0417 - mae: 0.1530 - val_loss: 0.0392 - val_mae: 0.1471\n",
      "Epoch 16/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0403 - mae: 0.1496 - val_loss: 0.0387 - val_mae: 0.1456\n",
      "Epoch 17/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0411 - mae: 0.1496 - val_loss: 0.0385 - val_mae: 0.1470\n",
      "Epoch 18/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0404 - mae: 0.1508 - val_loss: 0.0382 - val_mae: 0.1459\n",
      "Epoch 19/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0393 - mae: 0.1470 - val_loss: 0.0384 - val_mae: 0.1481\n",
      "Epoch 20/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0395 - mae: 0.1481 - val_loss: 0.0389 - val_mae: 0.1493\n",
      "Epoch 21/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0390 - mae: 0.1481 - val_loss: 0.0381 - val_mae: 0.1467\n",
      "Epoch 22/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0374 - mae: 0.1439 - val_loss: 0.0378 - val_mae: 0.1466\n",
      "Epoch 23/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0371 - mae: 0.1428 - val_loss: 0.0374 - val_mae: 0.1456\n",
      "Epoch 24/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0390 - mae: 0.1483 - val_loss: 0.0371 - val_mae: 0.1435\n",
      "Epoch 25/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0385 - mae: 0.1463 - val_loss: 0.0370 - val_mae: 0.1425\n",
      "Epoch 26/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0388 - mae: 0.1483 - val_loss: 0.0371 - val_mae: 0.1437\n",
      "Epoch 27/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0388 - mae: 0.1477 - val_loss: 0.0369 - val_mae: 0.1431\n",
      "Epoch 28/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0374 - mae: 0.1443 - val_loss: 0.0369 - val_mae: 0.1442\n",
      "Epoch 29/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0381 - mae: 0.1469 - val_loss: 0.0367 - val_mae: 0.1429\n",
      "Epoch 30/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0377 - mae: 0.1447 - val_loss: 0.0368 - val_mae: 0.1434\n",
      "Epoch 31/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0371 - mae: 0.1443 - val_loss: 0.0367 - val_mae: 0.1441\n",
      "Epoch 32/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0379 - mae: 0.1464 - val_loss: 0.0363 - val_mae: 0.1422\n",
      "Epoch 33/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0385 - mae: 0.1473 - val_loss: 0.0363 - val_mae: 0.1424\n",
      "Epoch 34/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0380 - mae: 0.1471 - val_loss: 0.0364 - val_mae: 0.1419\n",
      "Epoch 35/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0375 - mae: 0.1445 - val_loss: 0.0373 - val_mae: 0.1441\n",
      "Epoch 36/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0380 - mae: 0.1454 - val_loss: 0.0364 - val_mae: 0.1433\n",
      "Epoch 37/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0389 - mae: 0.1486 - val_loss: 0.0358 - val_mae: 0.1409\n",
      "Epoch 38/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0371 - mae: 0.1443 - val_loss: 0.0357 - val_mae: 0.1407\n",
      "Epoch 39/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0375 - mae: 0.1459 - val_loss: 0.0354 - val_mae: 0.1414\n",
      "Epoch 40/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0367 - mae: 0.1433 - val_loss: 0.0365 - val_mae: 0.1440\n",
      "Epoch 41/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0369 - mae: 0.1446 - val_loss: 0.0353 - val_mae: 0.1405\n",
      "Epoch 42/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0365 - mae: 0.1434 - val_loss: 0.0352 - val_mae: 0.1414\n",
      "Epoch 43/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0359 - mae: 0.1425 - val_loss: 0.0351 - val_mae: 0.1388\n",
      "Epoch 44/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0370 - mae: 0.1444 - val_loss: 0.0350 - val_mae: 0.1411\n",
      "Epoch 45/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0371 - mae: 0.1454 - val_loss: 0.0359 - val_mae: 0.1421\n",
      "Epoch 46/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0366 - mae: 0.1430 - val_loss: 0.0371 - val_mae: 0.1464\n",
      "Epoch 47/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0359 - mae: 0.1422 - val_loss: 0.0349 - val_mae: 0.1401\n",
      "Epoch 48/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0368 - mae: 0.1433 - val_loss: 0.0349 - val_mae: 0.1412\n",
      "Epoch 49/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0370 - mae: 0.1454 - val_loss: 0.0351 - val_mae: 0.1411\n",
      "Epoch 50/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0361 - mae: 0.1425 - val_loss: 0.0348 - val_mae: 0.1389\n",
      "Epoch 51/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0367 - mae: 0.1420 - val_loss: 0.0356 - val_mae: 0.1431\n",
      "Epoch 52/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0368 - mae: 0.1450 - val_loss: 0.0346 - val_mae: 0.1405\n",
      "Epoch 53/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0366 - mae: 0.1443 - val_loss: 0.0344 - val_mae: 0.1387\n",
      "Epoch 54/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0353 - mae: 0.1406 - val_loss: 0.0348 - val_mae: 0.1424\n",
      "Epoch 55/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0367 - mae: 0.1443 - val_loss: 0.0344 - val_mae: 0.1402\n",
      "Epoch 56/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0366 - mae: 0.1434 - val_loss: 0.0355 - val_mae: 0.1431\n",
      "Epoch 57/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0367 - mae: 0.1445 - val_loss: 0.0362 - val_mae: 0.1453\n",
      "Epoch 58/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0355 - mae: 0.1408 - val_loss: 0.0344 - val_mae: 0.1398\n",
      "Epoch 59/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0354 - mae: 0.1417 - val_loss: 0.0342 - val_mae: 0.1402\n",
      "Epoch 60/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0356 - mae: 0.1427 - val_loss: 0.0341 - val_mae: 0.1377\n",
      "Epoch 61/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0361 - mae: 0.1423 - val_loss: 0.0337 - val_mae: 0.1375\n",
      "Epoch 62/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0358 - mae: 0.1431 - val_loss: 0.0339 - val_mae: 0.1378\n",
      "Epoch 63/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0346 - mae: 0.1393 - val_loss: 0.0340 - val_mae: 0.1403\n",
      "Epoch 64/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0354 - mae: 0.1417 - val_loss: 0.0338 - val_mae: 0.1378\n",
      "Epoch 65/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0350 - mae: 0.1393 - val_loss: 0.0346 - val_mae: 0.1410\n",
      "Epoch 66/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0352 - mae: 0.1413 - val_loss: 0.0347 - val_mae: 0.1420\n",
      "Epoch 67/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0362 - mae: 0.1441 - val_loss: 0.0346 - val_mae: 0.1386\n",
      "Epoch 68/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0362 - mae: 0.1428 - val_loss: 0.0350 - val_mae: 0.1425\n",
      "Epoch 69/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0351 - mae: 0.1404 - val_loss: 0.0339 - val_mae: 0.1388\n",
      "Epoch 70/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0356 - mae: 0.1417 - val_loss: 0.0338 - val_mae: 0.1396\n",
      "Epoch 71/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0365 - mae: 0.1444 - val_loss: 0.0338 - val_mae: 0.1396\n",
      "Epoch 72/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0346 - mae: 0.1408 - val_loss: 0.0343 - val_mae: 0.1410\n",
      "Epoch 73/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0349 - mae: 0.1420 - val_loss: 0.0336 - val_mae: 0.1387\n",
      "Epoch 74/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0359 - mae: 0.1442 - val_loss: 0.0339 - val_mae: 0.1380\n",
      "Epoch 75/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0349 - mae: 0.1411 - val_loss: 0.0341 - val_mae: 0.1384\n",
      "Epoch 76/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0371 - mae: 0.1465 - val_loss: 0.0333 - val_mae: 0.1375\n",
      "Epoch 77/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0345 - mae: 0.1391 - val_loss: 0.0340 - val_mae: 0.1379\n",
      "Epoch 78/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0347 - mae: 0.1405 - val_loss: 0.0333 - val_mae: 0.1381\n",
      "Epoch 79/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0357 - mae: 0.1432 - val_loss: 0.0330 - val_mae: 0.1378\n",
      "Epoch 80/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0340 - mae: 0.1384 - val_loss: 0.0341 - val_mae: 0.1410\n",
      "Epoch 81/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0348 - mae: 0.1416 - val_loss: 0.0334 - val_mae: 0.1393\n",
      "Epoch 82/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0341 - mae: 0.1382 - val_loss: 0.0338 - val_mae: 0.1410\n",
      "Epoch 83/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0342 - mae: 0.1399 - val_loss: 0.0334 - val_mae: 0.1391\n",
      "Epoch 84/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0344 - mae: 0.1413 - val_loss: 0.0335 - val_mae: 0.1393\n",
      "Epoch 85/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0340 - mae: 0.1400 - val_loss: 0.0337 - val_mae: 0.1409\n",
      "Epoch 86/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0346 - mae: 0.1413 - val_loss: 0.0329 - val_mae: 0.1372\n",
      "Epoch 87/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0342 - mae: 0.1388 - val_loss: 0.0330 - val_mae: 0.1392\n",
      "Epoch 88/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0347 - mae: 0.1421 - val_loss: 0.0326 - val_mae: 0.1358\n",
      "Epoch 89/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0351 - mae: 0.1411 - val_loss: 0.0335 - val_mae: 0.1383\n",
      "Epoch 90/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0339 - mae: 0.1402 - val_loss: 0.0324 - val_mae: 0.1349\n",
      "Epoch 91/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0351 - mae: 0.1424 - val_loss: 0.0335 - val_mae: 0.1398\n",
      "Epoch 92/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0347 - mae: 0.1413 - val_loss: 0.0322 - val_mae: 0.1336\n",
      "Epoch 93/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0349 - mae: 0.1413 - val_loss: 0.0329 - val_mae: 0.1356\n",
      "Epoch 94/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0353 - mae: 0.1415 - val_loss: 0.0335 - val_mae: 0.1403\n",
      "Epoch 95/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0333 - mae: 0.1376 - val_loss: 0.0333 - val_mae: 0.1382\n",
      "Epoch 96/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0343 - mae: 0.1395 - val_loss: 0.0327 - val_mae: 0.1376\n",
      "Epoch 97/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0335 - mae: 0.1390 - val_loss: 0.0330 - val_mae: 0.1393\n",
      "Epoch 98/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0337 - mae: 0.1390 - val_loss: 0.0324 - val_mae: 0.1378\n",
      "Epoch 99/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0336 - mae: 0.1389 - val_loss: 0.0331 - val_mae: 0.1395\n",
      "Epoch 100/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0328 - mae: 0.1386 - val_loss: 0.0325 - val_mae: 0.1376\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0320 - mae: 0.1356 \n",
      "---------------------------------------------------------\n",
      "K 2 FOLD\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elped\\AppData\\Local\\Temp\\ipykernel_13956\\4226922763.py:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[features] = scaler.fit_transform(x[features])\n",
      "c:\\Users\\elped\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.3948 - mae: 0.2319 - val_loss: 0.2212 - val_mae: 0.2002\n",
      "Epoch 2/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1902 - mae: 0.1993 - val_loss: 0.1139 - val_mae: 0.1808\n",
      "Epoch 3/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1021 - mae: 0.1812 - val_loss: 0.0692 - val_mae: 0.1677\n",
      "Epoch 4/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0666 - mae: 0.1703 - val_loss: 0.0516 - val_mae: 0.1599\n",
      "Epoch 5/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0529 - mae: 0.1627 - val_loss: 0.0453 - val_mae: 0.1567\n",
      "Epoch 6/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0470 - mae: 0.1577 - val_loss: 0.0425 - val_mae: 0.1540\n",
      "Epoch 7/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0465 - mae: 0.1599 - val_loss: 0.0412 - val_mae: 0.1509\n",
      "Epoch 8/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0444 - mae: 0.1556 - val_loss: 0.0402 - val_mae: 0.1489\n",
      "Epoch 9/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0436 - mae: 0.1535 - val_loss: 0.0394 - val_mae: 0.1475\n",
      "Epoch 10/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0429 - mae: 0.1535 - val_loss: 0.0393 - val_mae: 0.1471\n",
      "Epoch 11/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0432 - mae: 0.1524 - val_loss: 0.0394 - val_mae: 0.1502\n",
      "Epoch 12/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0436 - mae: 0.1557 - val_loss: 0.0389 - val_mae: 0.1470\n",
      "Epoch 13/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0420 - mae: 0.1513 - val_loss: 0.0384 - val_mae: 0.1463\n",
      "Epoch 14/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0428 - mae: 0.1533 - val_loss: 0.0384 - val_mae: 0.1477\n",
      "Epoch 15/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0404 - mae: 0.1480 - val_loss: 0.0376 - val_mae: 0.1427\n",
      "Epoch 16/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0420 - mae: 0.1518 - val_loss: 0.0380 - val_mae: 0.1451\n",
      "Epoch 17/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0428 - mae: 0.1534 - val_loss: 0.0368 - val_mae: 0.1437\n",
      "Epoch 18/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0410 - mae: 0.1498 - val_loss: 0.0373 - val_mae: 0.1461\n",
      "Epoch 19/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0407 - mae: 0.1508 - val_loss: 0.0368 - val_mae: 0.1445\n",
      "Epoch 20/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0412 - mae: 0.1511 - val_loss: 0.0368 - val_mae: 0.1457\n",
      "Epoch 21/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0404 - mae: 0.1499 - val_loss: 0.0374 - val_mae: 0.1455\n",
      "Epoch 22/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0403 - mae: 0.1486 - val_loss: 0.0380 - val_mae: 0.1460\n",
      "Epoch 23/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0404 - mae: 0.1489 - val_loss: 0.0361 - val_mae: 0.1423\n",
      "Epoch 24/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0400 - mae: 0.1493 - val_loss: 0.0359 - val_mae: 0.1430\n",
      "Epoch 25/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0399 - mae: 0.1490 - val_loss: 0.0358 - val_mae: 0.1410\n",
      "Epoch 26/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0394 - mae: 0.1484 - val_loss: 0.0362 - val_mae: 0.1433\n",
      "Epoch 27/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0378 - mae: 0.1450 - val_loss: 0.0352 - val_mae: 0.1413\n",
      "Epoch 28/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0403 - mae: 0.1501 - val_loss: 0.0357 - val_mae: 0.1410\n",
      "Epoch 29/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0382 - mae: 0.1447 - val_loss: 0.0354 - val_mae: 0.1429\n",
      "Epoch 30/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0380 - mae: 0.1454 - val_loss: 0.0355 - val_mae: 0.1435\n",
      "Epoch 31/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0389 - mae: 0.1479 - val_loss: 0.0345 - val_mae: 0.1409\n",
      "Epoch 32/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0380 - mae: 0.1464 - val_loss: 0.0350 - val_mae: 0.1405\n",
      "Epoch 33/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0366 - mae: 0.1415 - val_loss: 0.0344 - val_mae: 0.1397\n",
      "Epoch 34/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0377 - mae: 0.1456 - val_loss: 0.0342 - val_mae: 0.1400\n",
      "Epoch 35/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0374 - mae: 0.1444 - val_loss: 0.0345 - val_mae: 0.1400\n",
      "Epoch 36/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0391 - mae: 0.1486 - val_loss: 0.0344 - val_mae: 0.1407\n",
      "Epoch 37/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0366 - mae: 0.1422 - val_loss: 0.0345 - val_mae: 0.1422\n",
      "Epoch 38/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0371 - mae: 0.1443 - val_loss: 0.0347 - val_mae: 0.1403\n",
      "Epoch 39/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0393 - mae: 0.1490 - val_loss: 0.0347 - val_mae: 0.1422\n",
      "Epoch 40/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0366 - mae: 0.1425 - val_loss: 0.0345 - val_mae: 0.1403\n",
      "Epoch 41/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0373 - mae: 0.1429 - val_loss: 0.0343 - val_mae: 0.1406\n",
      "Epoch 42/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0367 - mae: 0.1440 - val_loss: 0.0342 - val_mae: 0.1414\n",
      "Epoch 43/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0368 - mae: 0.1420 - val_loss: 0.0340 - val_mae: 0.1400\n",
      "Epoch 44/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0371 - mae: 0.1439 - val_loss: 0.0337 - val_mae: 0.1391\n",
      "Epoch 45/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0368 - mae: 0.1436 - val_loss: 0.0344 - val_mae: 0.1428\n",
      "Epoch 46/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0367 - mae: 0.1433 - val_loss: 0.0338 - val_mae: 0.1400\n",
      "Epoch 47/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0365 - mae: 0.1427 - val_loss: 0.0344 - val_mae: 0.1424\n",
      "Epoch 48/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0370 - mae: 0.1441 - val_loss: 0.0346 - val_mae: 0.1438\n",
      "Epoch 49/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0362 - mae: 0.1420 - val_loss: 0.0336 - val_mae: 0.1380\n",
      "Epoch 50/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0386 - mae: 0.1475 - val_loss: 0.0327 - val_mae: 0.1369\n",
      "Epoch 51/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0360 - mae: 0.1412 - val_loss: 0.0332 - val_mae: 0.1386\n",
      "Epoch 52/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0378 - mae: 0.1474 - val_loss: 0.0335 - val_mae: 0.1390\n",
      "Epoch 53/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0361 - mae: 0.1420 - val_loss: 0.0332 - val_mae: 0.1372\n",
      "Epoch 54/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0362 - mae: 0.1425 - val_loss: 0.0328 - val_mae: 0.1364\n",
      "Epoch 55/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0359 - mae: 0.1418 - val_loss: 0.0329 - val_mae: 0.1376\n",
      "Epoch 56/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0370 - mae: 0.1445 - val_loss: 0.0333 - val_mae: 0.1397\n",
      "Epoch 57/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0346 - mae: 0.1388 - val_loss: 0.0325 - val_mae: 0.1367\n",
      "Epoch 58/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0369 - mae: 0.1448 - val_loss: 0.0327 - val_mae: 0.1385\n",
      "Epoch 59/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0364 - mae: 0.1437 - val_loss: 0.0339 - val_mae: 0.1407\n",
      "Epoch 60/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0363 - mae: 0.1429 - val_loss: 0.0330 - val_mae: 0.1387\n",
      "Epoch 61/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0347 - mae: 0.1394 - val_loss: 0.0325 - val_mae: 0.1373\n",
      "Epoch 62/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0353 - mae: 0.1414 - val_loss: 0.0325 - val_mae: 0.1353\n",
      "Epoch 63/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0370 - mae: 0.1431 - val_loss: 0.0328 - val_mae: 0.1400\n",
      "Epoch 64/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0360 - mae: 0.1430 - val_loss: 0.0325 - val_mae: 0.1368\n",
      "Epoch 65/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0362 - mae: 0.1423 - val_loss: 0.0323 - val_mae: 0.1371\n",
      "Epoch 66/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0363 - mae: 0.1433 - val_loss: 0.0327 - val_mae: 0.1375\n",
      "Epoch 67/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0353 - mae: 0.1417 - val_loss: 0.0329 - val_mae: 0.1378\n",
      "Epoch 68/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0362 - mae: 0.1415 - val_loss: 0.0324 - val_mae: 0.1368\n",
      "Epoch 69/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0362 - mae: 0.1439 - val_loss: 0.0332 - val_mae: 0.1363\n",
      "Epoch 70/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0346 - mae: 0.1385 - val_loss: 0.0326 - val_mae: 0.1377\n",
      "Epoch 71/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0349 - mae: 0.1406 - val_loss: 0.0341 - val_mae: 0.1418\n",
      "Epoch 72/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0358 - mae: 0.1415 - val_loss: 0.0323 - val_mae: 0.1387\n",
      "Epoch 73/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0358 - mae: 0.1435 - val_loss: 0.0326 - val_mae: 0.1388\n",
      "Epoch 74/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0349 - mae: 0.1401 - val_loss: 0.0328 - val_mae: 0.1380\n",
      "Epoch 75/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0360 - mae: 0.1425 - val_loss: 0.0327 - val_mae: 0.1370\n",
      "Epoch 76/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0351 - mae: 0.1402 - val_loss: 0.0323 - val_mae: 0.1348\n",
      "Epoch 77/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0359 - mae: 0.1425 - val_loss: 0.0319 - val_mae: 0.1351\n",
      "Epoch 78/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0365 - mae: 0.1436 - val_loss: 0.0326 - val_mae: 0.1381\n",
      "Epoch 79/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0358 - mae: 0.1424 - val_loss: 0.0322 - val_mae: 0.1367\n",
      "Epoch 80/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0344 - mae: 0.1407 - val_loss: 0.0320 - val_mae: 0.1367\n",
      "Epoch 81/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0354 - mae: 0.1408 - val_loss: 0.0326 - val_mae: 0.1381\n",
      "Epoch 82/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0348 - mae: 0.1402 - val_loss: 0.0321 - val_mae: 0.1382\n",
      "Epoch 83/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0351 - mae: 0.1422 - val_loss: 0.0324 - val_mae: 0.1359\n",
      "Epoch 84/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0342 - mae: 0.1391 - val_loss: 0.0320 - val_mae: 0.1364\n",
      "Epoch 85/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0345 - mae: 0.1401 - val_loss: 0.0319 - val_mae: 0.1373\n",
      "Epoch 86/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0352 - mae: 0.1410 - val_loss: 0.0322 - val_mae: 0.1367\n",
      "Epoch 87/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0356 - mae: 0.1414 - val_loss: 0.0320 - val_mae: 0.1372\n",
      "Epoch 88/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0351 - mae: 0.1417 - val_loss: 0.0325 - val_mae: 0.1362\n",
      "Epoch 89/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0342 - mae: 0.1385 - val_loss: 0.0316 - val_mae: 0.1360\n",
      "Epoch 90/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0341 - mae: 0.1385 - val_loss: 0.0319 - val_mae: 0.1380\n",
      "Epoch 91/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0350 - mae: 0.1397 - val_loss: 0.0325 - val_mae: 0.1374\n",
      "Epoch 92/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0362 - mae: 0.1414 - val_loss: 0.0318 - val_mae: 0.1330\n",
      "Epoch 93/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0350 - mae: 0.1403 - val_loss: 0.0323 - val_mae: 0.1359\n",
      "Epoch 94/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0346 - mae: 0.1391 - val_loss: 0.0318 - val_mae: 0.1378\n",
      "Epoch 95/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0351 - mae: 0.1430 - val_loss: 0.0321 - val_mae: 0.1388\n",
      "Epoch 96/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0357 - mae: 0.1432 - val_loss: 0.0312 - val_mae: 0.1342\n",
      "Epoch 97/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0339 - mae: 0.1379 - val_loss: 0.0316 - val_mae: 0.1377\n",
      "Epoch 98/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0351 - mae: 0.1415 - val_loss: 0.0319 - val_mae: 0.1377\n",
      "Epoch 99/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0337 - mae: 0.1389 - val_loss: 0.0313 - val_mae: 0.1344\n",
      "Epoch 100/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0344 - mae: 0.1383 - val_loss: 0.0316 - val_mae: 0.1356\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - loss: 0.0324 - mae: 0.1381\n",
      "---------------------------------------------------------\n",
      "K 3 FOLD\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elped\\AppData\\Local\\Temp\\ipykernel_13956\\4226922763.py:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[features] = scaler.fit_transform(x[features])\n",
      "c:\\Users\\elped\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.4061 - mae: 0.2246 - val_loss: 0.2256 - val_mae: 0.2049\n",
      "Epoch 2/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1930 - mae: 0.2025 - val_loss: 0.1139 - val_mae: 0.1871\n",
      "Epoch 3/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1003 - mae: 0.1827 - val_loss: 0.0665 - val_mae: 0.1673\n",
      "Epoch 4/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0615 - mae: 0.1621 - val_loss: 0.0493 - val_mae: 0.1555\n",
      "Epoch 5/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0501 - mae: 0.1575 - val_loss: 0.0436 - val_mae: 0.1515\n",
      "Epoch 6/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0451 - mae: 0.1545 - val_loss: 0.0419 - val_mae: 0.1502\n",
      "Epoch 7/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0425 - mae: 0.1495 - val_loss: 0.0408 - val_mae: 0.1500\n",
      "Epoch 8/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0444 - mae: 0.1554 - val_loss: 0.0401 - val_mae: 0.1475\n",
      "Epoch 9/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0427 - mae: 0.1515 - val_loss: 0.0395 - val_mae: 0.1488\n",
      "Epoch 10/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0428 - mae: 0.1530 - val_loss: 0.0393 - val_mae: 0.1476\n",
      "Epoch 11/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0413 - mae: 0.1493 - val_loss: 0.0392 - val_mae: 0.1468\n",
      "Epoch 12/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0409 - mae: 0.1499 - val_loss: 0.0386 - val_mae: 0.1471\n",
      "Epoch 13/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0406 - mae: 0.1502 - val_loss: 0.0384 - val_mae: 0.1436\n",
      "Epoch 14/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0408 - mae: 0.1490 - val_loss: 0.0380 - val_mae: 0.1446\n",
      "Epoch 15/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0403 - mae: 0.1489 - val_loss: 0.0376 - val_mae: 0.1456\n",
      "Epoch 16/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0408 - mae: 0.1500 - val_loss: 0.0371 - val_mae: 0.1436\n",
      "Epoch 17/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0410 - mae: 0.1516 - val_loss: 0.0371 - val_mae: 0.1437\n",
      "Epoch 18/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0391 - mae: 0.1464 - val_loss: 0.0367 - val_mae: 0.1415\n",
      "Epoch 19/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0400 - mae: 0.1489 - val_loss: 0.0371 - val_mae: 0.1416\n",
      "Epoch 20/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0390 - mae: 0.1449 - val_loss: 0.0374 - val_mae: 0.1471\n",
      "Epoch 21/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0387 - mae: 0.1452 - val_loss: 0.0367 - val_mae: 0.1453\n",
      "Epoch 22/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0387 - mae: 0.1459 - val_loss: 0.0361 - val_mae: 0.1428\n",
      "Epoch 23/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0390 - mae: 0.1468 - val_loss: 0.0364 - val_mae: 0.1433\n",
      "Epoch 24/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0390 - mae: 0.1468 - val_loss: 0.0361 - val_mae: 0.1412\n",
      "Epoch 25/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0385 - mae: 0.1457 - val_loss: 0.0361 - val_mae: 0.1406\n",
      "Epoch 26/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0385 - mae: 0.1457 - val_loss: 0.0362 - val_mae: 0.1458\n",
      "Epoch 27/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0387 - mae: 0.1478 - val_loss: 0.0371 - val_mae: 0.1433\n",
      "Epoch 28/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0391 - mae: 0.1486 - val_loss: 0.0365 - val_mae: 0.1419\n",
      "Epoch 29/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0389 - mae: 0.1473 - val_loss: 0.0356 - val_mae: 0.1421\n",
      "Epoch 30/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0374 - mae: 0.1441 - val_loss: 0.0352 - val_mae: 0.1417\n",
      "Epoch 31/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0387 - mae: 0.1476 - val_loss: 0.0349 - val_mae: 0.1378\n",
      "Epoch 32/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0386 - mae: 0.1465 - val_loss: 0.0352 - val_mae: 0.1414\n",
      "Epoch 33/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0394 - mae: 0.1482 - val_loss: 0.0352 - val_mae: 0.1371\n",
      "Epoch 34/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0378 - mae: 0.1442 - val_loss: 0.0352 - val_mae: 0.1397\n",
      "Epoch 35/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0385 - mae: 0.1476 - val_loss: 0.0345 - val_mae: 0.1391\n",
      "Epoch 36/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0356 - mae: 0.1403 - val_loss: 0.0353 - val_mae: 0.1428\n",
      "Epoch 37/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0375 - mae: 0.1444 - val_loss: 0.0357 - val_mae: 0.1408\n",
      "Epoch 38/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0366 - mae: 0.1434 - val_loss: 0.0343 - val_mae: 0.1396\n",
      "Epoch 39/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0383 - mae: 0.1468 - val_loss: 0.0341 - val_mae: 0.1376\n",
      "Epoch 40/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0374 - mae: 0.1449 - val_loss: 0.0345 - val_mae: 0.1416\n",
      "Epoch 41/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0374 - mae: 0.1455 - val_loss: 0.0348 - val_mae: 0.1417\n",
      "Epoch 42/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0369 - mae: 0.1442 - val_loss: 0.0349 - val_mae: 0.1387\n",
      "Epoch 43/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0362 - mae: 0.1426 - val_loss: 0.0339 - val_mae: 0.1387\n",
      "Epoch 44/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0372 - mae: 0.1447 - val_loss: 0.0340 - val_mae: 0.1374\n",
      "Epoch 45/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0375 - mae: 0.1453 - val_loss: 0.0338 - val_mae: 0.1393\n",
      "Epoch 46/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0364 - mae: 0.1436 - val_loss: 0.0337 - val_mae: 0.1395\n",
      "Epoch 47/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0364 - mae: 0.1429 - val_loss: 0.0348 - val_mae: 0.1419\n",
      "Epoch 48/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0368 - mae: 0.1453 - val_loss: 0.0342 - val_mae: 0.1419\n",
      "Epoch 49/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0360 - mae: 0.1423 - val_loss: 0.0337 - val_mae: 0.1389\n",
      "Epoch 50/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0364 - mae: 0.1433 - val_loss: 0.0343 - val_mae: 0.1398\n",
      "Epoch 51/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0363 - mae: 0.1414 - val_loss: 0.0336 - val_mae: 0.1389\n",
      "Epoch 52/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0363 - mae: 0.1448 - val_loss: 0.0339 - val_mae: 0.1380\n",
      "Epoch 53/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0368 - mae: 0.1445 - val_loss: 0.0336 - val_mae: 0.1385\n",
      "Epoch 54/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0362 - mae: 0.1436 - val_loss: 0.0338 - val_mae: 0.1357\n",
      "Epoch 55/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0385 - mae: 0.1477 - val_loss: 0.0333 - val_mae: 0.1386\n",
      "Epoch 56/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0355 - mae: 0.1410 - val_loss: 0.0332 - val_mae: 0.1367\n",
      "Epoch 57/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0352 - mae: 0.1404 - val_loss: 0.0339 - val_mae: 0.1395\n",
      "Epoch 58/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0363 - mae: 0.1440 - val_loss: 0.0328 - val_mae: 0.1341\n",
      "Epoch 59/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0365 - mae: 0.1430 - val_loss: 0.0334 - val_mae: 0.1368\n",
      "Epoch 60/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0352 - mae: 0.1411 - val_loss: 0.0333 - val_mae: 0.1378\n",
      "Epoch 61/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0350 - mae: 0.1399 - val_loss: 0.0338 - val_mae: 0.1399\n",
      "Epoch 62/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0376 - mae: 0.1471 - val_loss: 0.0339 - val_mae: 0.1395\n",
      "Epoch 63/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0353 - mae: 0.1414 - val_loss: 0.0328 - val_mae: 0.1363\n",
      "Epoch 64/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0338 - mae: 0.1378 - val_loss: 0.0352 - val_mae: 0.1380\n",
      "Epoch 65/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0371 - mae: 0.1452 - val_loss: 0.0333 - val_mae: 0.1375\n",
      "Epoch 66/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0376 - mae: 0.1471 - val_loss: 0.0328 - val_mae: 0.1376\n",
      "Epoch 67/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0365 - mae: 0.1450 - val_loss: 0.0329 - val_mae: 0.1371\n",
      "Epoch 68/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0344 - mae: 0.1389 - val_loss: 0.0331 - val_mae: 0.1377\n",
      "Epoch 69/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0369 - mae: 0.1452 - val_loss: 0.0329 - val_mae: 0.1374\n",
      "Epoch 70/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0375 - mae: 0.1457 - val_loss: 0.0320 - val_mae: 0.1341\n",
      "Epoch 71/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0356 - mae: 0.1403 - val_loss: 0.0327 - val_mae: 0.1382\n",
      "Epoch 72/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0345 - mae: 0.1407 - val_loss: 0.0330 - val_mae: 0.1389\n",
      "Epoch 73/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0353 - mae: 0.1423 - val_loss: 0.0338 - val_mae: 0.1367\n",
      "Epoch 74/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0370 - mae: 0.1464 - val_loss: 0.0325 - val_mae: 0.1365\n",
      "Epoch 75/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0358 - mae: 0.1414 - val_loss: 0.0324 - val_mae: 0.1350\n",
      "Epoch 76/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0348 - mae: 0.1410 - val_loss: 0.0323 - val_mae: 0.1360\n",
      "Epoch 77/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0353 - mae: 0.1422 - val_loss: 0.0320 - val_mae: 0.1370\n",
      "Epoch 78/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0358 - mae: 0.1432 - val_loss: 0.0329 - val_mae: 0.1400\n",
      "Epoch 79/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0343 - mae: 0.1397 - val_loss: 0.0330 - val_mae: 0.1392\n",
      "Epoch 80/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0341 - mae: 0.1386 - val_loss: 0.0330 - val_mae: 0.1379\n",
      "Epoch 81/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0344 - mae: 0.1396 - val_loss: 0.0324 - val_mae: 0.1345\n",
      "Epoch 82/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0348 - mae: 0.1409 - val_loss: 0.0317 - val_mae: 0.1331\n",
      "Epoch 83/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0348 - mae: 0.1403 - val_loss: 0.0322 - val_mae: 0.1375\n",
      "Epoch 84/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0348 - mae: 0.1404 - val_loss: 0.0318 - val_mae: 0.1323\n",
      "Epoch 85/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0357 - mae: 0.1423 - val_loss: 0.0317 - val_mae: 0.1342\n",
      "Epoch 86/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0342 - mae: 0.1397 - val_loss: 0.0320 - val_mae: 0.1353\n",
      "Epoch 87/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0344 - mae: 0.1409 - val_loss: 0.0327 - val_mae: 0.1349\n",
      "Epoch 88/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0351 - mae: 0.1415 - val_loss: 0.0329 - val_mae: 0.1385\n",
      "Epoch 89/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0356 - mae: 0.1437 - val_loss: 0.0315 - val_mae: 0.1354\n",
      "Epoch 90/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0347 - mae: 0.1412 - val_loss: 0.0318 - val_mae: 0.1355\n",
      "Epoch 91/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0353 - mae: 0.1429 - val_loss: 0.0322 - val_mae: 0.1371\n",
      "Epoch 92/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0357 - mae: 0.1426 - val_loss: 0.0319 - val_mae: 0.1359\n",
      "Epoch 93/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0337 - mae: 0.1382 - val_loss: 0.0331 - val_mae: 0.1380\n",
      "Epoch 94/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0337 - mae: 0.1382 - val_loss: 0.0321 - val_mae: 0.1347\n",
      "Epoch 95/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0342 - mae: 0.1400 - val_loss: 0.0321 - val_mae: 0.1358\n",
      "Epoch 96/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0334 - mae: 0.1380 - val_loss: 0.0325 - val_mae: 0.1376\n",
      "Epoch 97/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0342 - mae: 0.1400 - val_loss: 0.0321 - val_mae: 0.1358\n",
      "Epoch 98/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0349 - mae: 0.1412 - val_loss: 0.0317 - val_mae: 0.1348\n",
      "Epoch 99/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0351 - mae: 0.1403 - val_loss: 0.0321 - val_mae: 0.1317\n",
      "Epoch 100/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0336 - mae: 0.1366 - val_loss: 0.0323 - val_mae: 0.1370\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0317 - mae: 0.1354 \n",
      "---------------------------------------------------------\n",
      "K 4 FOLD\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elped\\AppData\\Local\\Temp\\ipykernel_13956\\4226922763.py:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[features] = scaler.fit_transform(x[features])\n",
      "c:\\Users\\elped\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.4099 - mae: 0.2391 - val_loss: 0.2268 - val_mae: 0.1994\n",
      "Epoch 2/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1959 - mae: 0.2031 - val_loss: 0.1166 - val_mae: 0.1822\n",
      "Epoch 3/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1040 - mae: 0.1831 - val_loss: 0.0691 - val_mae: 0.1645\n",
      "Epoch 4/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0659 - mae: 0.1666 - val_loss: 0.0516 - val_mae: 0.1562\n",
      "Epoch 5/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0512 - mae: 0.1581 - val_loss: 0.0454 - val_mae: 0.1515\n",
      "Epoch 6/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0470 - mae: 0.1562 - val_loss: 0.0427 - val_mae: 0.1502\n",
      "Epoch 7/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0450 - mae: 0.1563 - val_loss: 0.0420 - val_mae: 0.1484\n",
      "Epoch 8/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0444 - mae: 0.1559 - val_loss: 0.0411 - val_mae: 0.1477\n",
      "Epoch 9/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0439 - mae: 0.1549 - val_loss: 0.0413 - val_mae: 0.1475\n",
      "Epoch 10/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0421 - mae: 0.1506 - val_loss: 0.0407 - val_mae: 0.1471\n",
      "Epoch 11/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0411 - mae: 0.1489 - val_loss: 0.0406 - val_mae: 0.1469\n",
      "Epoch 12/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0408 - mae: 0.1480 - val_loss: 0.0399 - val_mae: 0.1447\n",
      "Epoch 13/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0410 - mae: 0.1487 - val_loss: 0.0410 - val_mae: 0.1466\n",
      "Epoch 14/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0408 - mae: 0.1476 - val_loss: 0.0397 - val_mae: 0.1452\n",
      "Epoch 15/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0415 - mae: 0.1514 - val_loss: 0.0396 - val_mae: 0.1448\n",
      "Epoch 16/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0402 - mae: 0.1479 - val_loss: 0.0388 - val_mae: 0.1456\n",
      "Epoch 17/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0397 - mae: 0.1471 - val_loss: 0.0388 - val_mae: 0.1443\n",
      "Epoch 18/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0399 - mae: 0.1478 - val_loss: 0.0399 - val_mae: 0.1450\n",
      "Epoch 19/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0406 - mae: 0.1490 - val_loss: 0.0389 - val_mae: 0.1434\n",
      "Epoch 20/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0405 - mae: 0.1500 - val_loss: 0.0386 - val_mae: 0.1436\n",
      "Epoch 21/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0382 - mae: 0.1441 - val_loss: 0.0379 - val_mae: 0.1430\n",
      "Epoch 22/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0386 - mae: 0.1461 - val_loss: 0.0387 - val_mae: 0.1431\n",
      "Epoch 23/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0392 - mae: 0.1477 - val_loss: 0.0382 - val_mae: 0.1417\n",
      "Epoch 24/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0400 - mae: 0.1490 - val_loss: 0.0378 - val_mae: 0.1437\n",
      "Epoch 25/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0384 - mae: 0.1446 - val_loss: 0.0378 - val_mae: 0.1439\n",
      "Epoch 26/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0379 - mae: 0.1444 - val_loss: 0.0372 - val_mae: 0.1434\n",
      "Epoch 27/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0375 - mae: 0.1452 - val_loss: 0.0381 - val_mae: 0.1407\n",
      "Epoch 28/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0395 - mae: 0.1479 - val_loss: 0.0376 - val_mae: 0.1435\n",
      "Epoch 29/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0383 - mae: 0.1460 - val_loss: 0.0376 - val_mae: 0.1402\n",
      "Epoch 30/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0385 - mae: 0.1459 - val_loss: 0.0373 - val_mae: 0.1411\n",
      "Epoch 31/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0374 - mae: 0.1426 - val_loss: 0.0374 - val_mae: 0.1420\n",
      "Epoch 32/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0371 - mae: 0.1439 - val_loss: 0.0371 - val_mae: 0.1429\n",
      "Epoch 33/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0380 - mae: 0.1462 - val_loss: 0.0375 - val_mae: 0.1401\n",
      "Epoch 34/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0367 - mae: 0.1422 - val_loss: 0.0369 - val_mae: 0.1431\n",
      "Epoch 35/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0378 - mae: 0.1473 - val_loss: 0.0367 - val_mae: 0.1402\n",
      "Epoch 36/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0367 - mae: 0.1423 - val_loss: 0.0370 - val_mae: 0.1416\n",
      "Epoch 37/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0377 - mae: 0.1442 - val_loss: 0.0380 - val_mae: 0.1425\n",
      "Epoch 38/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0368 - mae: 0.1432 - val_loss: 0.0363 - val_mae: 0.1405\n",
      "Epoch 39/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0371 - mae: 0.1433 - val_loss: 0.0361 - val_mae: 0.1396\n",
      "Epoch 40/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0371 - mae: 0.1438 - val_loss: 0.0367 - val_mae: 0.1401\n",
      "Epoch 41/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0362 - mae: 0.1425 - val_loss: 0.0361 - val_mae: 0.1432\n",
      "Epoch 42/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0369 - mae: 0.1451 - val_loss: 0.0353 - val_mae: 0.1384\n",
      "Epoch 43/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0369 - mae: 0.1445 - val_loss: 0.0357 - val_mae: 0.1396\n",
      "Epoch 44/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0365 - mae: 0.1420 - val_loss: 0.0363 - val_mae: 0.1398\n",
      "Epoch 45/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0360 - mae: 0.1418 - val_loss: 0.0359 - val_mae: 0.1396\n",
      "Epoch 46/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0355 - mae: 0.1392 - val_loss: 0.0363 - val_mae: 0.1401\n",
      "Epoch 47/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0360 - mae: 0.1414 - val_loss: 0.0367 - val_mae: 0.1401\n",
      "Epoch 48/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0372 - mae: 0.1465 - val_loss: 0.0355 - val_mae: 0.1394\n",
      "Epoch 49/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0366 - mae: 0.1437 - val_loss: 0.0354 - val_mae: 0.1400\n",
      "Epoch 50/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0354 - mae: 0.1416 - val_loss: 0.0352 - val_mae: 0.1378\n",
      "Epoch 51/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0360 - mae: 0.1425 - val_loss: 0.0357 - val_mae: 0.1424\n",
      "Epoch 52/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0373 - mae: 0.1464 - val_loss: 0.0355 - val_mae: 0.1401\n",
      "Epoch 53/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0362 - mae: 0.1438 - val_loss: 0.0355 - val_mae: 0.1390\n",
      "Epoch 54/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0348 - mae: 0.1384 - val_loss: 0.0352 - val_mae: 0.1391\n",
      "Epoch 55/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0345 - mae: 0.1380 - val_loss: 0.0348 - val_mae: 0.1379\n",
      "Epoch 56/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0352 - mae: 0.1405 - val_loss: 0.0349 - val_mae: 0.1401\n",
      "Epoch 57/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0359 - mae: 0.1435 - val_loss: 0.0355 - val_mae: 0.1370\n",
      "Epoch 58/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0344 - mae: 0.1384 - val_loss: 0.0362 - val_mae: 0.1395\n",
      "Epoch 59/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0350 - mae: 0.1393 - val_loss: 0.0359 - val_mae: 0.1408\n",
      "Epoch 60/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0346 - mae: 0.1388 - val_loss: 0.0350 - val_mae: 0.1377\n",
      "Epoch 61/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0362 - mae: 0.1443 - val_loss: 0.0354 - val_mae: 0.1368\n",
      "Epoch 62/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0355 - mae: 0.1412 - val_loss: 0.0345 - val_mae: 0.1382\n",
      "Epoch 63/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0360 - mae: 0.1435 - val_loss: 0.0346 - val_mae: 0.1375\n",
      "Epoch 64/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0350 - mae: 0.1398 - val_loss: 0.0343 - val_mae: 0.1372\n",
      "Epoch 65/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0348 - mae: 0.1409 - val_loss: 0.0350 - val_mae: 0.1361\n",
      "Epoch 66/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0359 - mae: 0.1419 - val_loss: 0.0349 - val_mae: 0.1383\n",
      "Epoch 67/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0345 - mae: 0.1409 - val_loss: 0.0343 - val_mae: 0.1381\n",
      "Epoch 68/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0359 - mae: 0.1443 - val_loss: 0.0349 - val_mae: 0.1378\n",
      "Epoch 69/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0359 - mae: 0.1431 - val_loss: 0.0350 - val_mae: 0.1365\n",
      "Epoch 70/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0352 - mae: 0.1411 - val_loss: 0.0353 - val_mae: 0.1367\n",
      "Epoch 71/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0357 - mae: 0.1413 - val_loss: 0.0345 - val_mae: 0.1385\n",
      "Epoch 72/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0356 - mae: 0.1433 - val_loss: 0.0363 - val_mae: 0.1395\n",
      "Epoch 73/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0351 - mae: 0.1412 - val_loss: 0.0349 - val_mae: 0.1362\n",
      "Epoch 74/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0346 - mae: 0.1391 - val_loss: 0.0345 - val_mae: 0.1385\n",
      "Epoch 75/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0353 - mae: 0.1434 - val_loss: 0.0349 - val_mae: 0.1366\n",
      "Epoch 76/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0344 - mae: 0.1407 - val_loss: 0.0346 - val_mae: 0.1368\n",
      "Epoch 77/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0352 - mae: 0.1421 - val_loss: 0.0341 - val_mae: 0.1372\n",
      "Epoch 78/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0343 - mae: 0.1396 - val_loss: 0.0360 - val_mae: 0.1385\n",
      "Epoch 79/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0341 - mae: 0.1384 - val_loss: 0.0340 - val_mae: 0.1354\n",
      "Epoch 80/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0344 - mae: 0.1381 - val_loss: 0.0336 - val_mae: 0.1343\n",
      "Epoch 81/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0352 - mae: 0.1404 - val_loss: 0.0341 - val_mae: 0.1373\n",
      "Epoch 82/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0340 - mae: 0.1392 - val_loss: 0.0345 - val_mae: 0.1386\n",
      "Epoch 83/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0349 - mae: 0.1413 - val_loss: 0.0342 - val_mae: 0.1352\n",
      "Epoch 84/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0340 - mae: 0.1392 - val_loss: 0.0346 - val_mae: 0.1365\n",
      "Epoch 85/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0337 - mae: 0.1387 - val_loss: 0.0355 - val_mae: 0.1371\n",
      "Epoch 86/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0346 - mae: 0.1401 - val_loss: 0.0353 - val_mae: 0.1379\n",
      "Epoch 87/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0344 - mae: 0.1396 - val_loss: 0.0347 - val_mae: 0.1354\n",
      "Epoch 88/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0353 - mae: 0.1414 - val_loss: 0.0344 - val_mae: 0.1351\n",
      "Epoch 89/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0334 - mae: 0.1371 - val_loss: 0.0340 - val_mae: 0.1358\n",
      "Epoch 90/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0351 - mae: 0.1407 - val_loss: 0.0341 - val_mae: 0.1373\n",
      "Epoch 91/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0343 - mae: 0.1392 - val_loss: 0.0348 - val_mae: 0.1362\n",
      "Epoch 92/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0361 - mae: 0.1442 - val_loss: 0.0339 - val_mae: 0.1360\n",
      "Epoch 93/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0338 - mae: 0.1382 - val_loss: 0.0336 - val_mae: 0.1371\n",
      "Epoch 94/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0340 - mae: 0.1396 - val_loss: 0.0344 - val_mae: 0.1363\n",
      "Epoch 95/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0356 - mae: 0.1415 - val_loss: 0.0335 - val_mae: 0.1351\n",
      "Epoch 96/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0332 - mae: 0.1370 - val_loss: 0.0335 - val_mae: 0.1375\n",
      "Epoch 97/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0352 - mae: 0.1418 - val_loss: 0.0341 - val_mae: 0.1349\n",
      "Epoch 98/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0325 - mae: 0.1364 - val_loss: 0.0336 - val_mae: 0.1353\n",
      "Epoch 99/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0333 - mae: 0.1373 - val_loss: 0.0340 - val_mae: 0.1359\n",
      "Epoch 100/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0339 - mae: 0.1388 - val_loss: 0.0340 - val_mae: 0.1357\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0365 - mae: 0.1409 \n",
      "---------------------------------------------------------\n",
      "USER 2\n",
      "---------------------------------------------------------\n",
      "K 0 FOLD\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elped\\AppData\\Local\\Temp\\ipykernel_13956\\4226922763.py:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[features] = scaler.fit_transform(x[features])\n",
      "c:\\Users\\elped\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.3392 - mae: 0.2043 - val_loss: 0.0840 - val_mae: 0.1273\n",
      "Epoch 2/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0661 - mae: 0.1305 - val_loss: 0.0354 - val_mae: 0.1198\n",
      "Epoch 3/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0355 - mae: 0.1228 - val_loss: 0.0301 - val_mae: 0.1132\n",
      "Epoch 4/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0316 - mae: 0.1202 - val_loss: 0.0290 - val_mae: 0.1137\n",
      "Epoch 5/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0312 - mae: 0.1210 - val_loss: 0.0284 - val_mae: 0.1130\n",
      "Epoch 6/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0305 - mae: 0.1190 - val_loss: 0.0278 - val_mae: 0.1087\n",
      "Epoch 7/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0299 - mae: 0.1173 - val_loss: 0.0276 - val_mae: 0.1105\n",
      "Epoch 8/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0296 - mae: 0.1169 - val_loss: 0.0272 - val_mae: 0.1098\n",
      "Epoch 9/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0293 - mae: 0.1162 - val_loss: 0.0267 - val_mae: 0.1083\n",
      "Epoch 10/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0296 - mae: 0.1186 - val_loss: 0.0268 - val_mae: 0.1098\n",
      "Epoch 11/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0293 - mae: 0.1180 - val_loss: 0.0263 - val_mae: 0.1055\n",
      "Epoch 12/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0285 - mae: 0.1143 - val_loss: 0.0260 - val_mae: 0.1057\n",
      "Epoch 13/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0276 - mae: 0.1136 - val_loss: 0.0258 - val_mae: 0.1055\n",
      "Epoch 14/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0276 - mae: 0.1134 - val_loss: 0.0260 - val_mae: 0.1053\n",
      "Epoch 15/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0284 - mae: 0.1148 - val_loss: 0.0263 - val_mae: 0.1089\n",
      "Epoch 16/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0274 - mae: 0.1132 - val_loss: 0.0255 - val_mae: 0.1055\n",
      "Epoch 17/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0268 - mae: 0.1115 - val_loss: 0.0254 - val_mae: 0.1050\n",
      "Epoch 18/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0268 - mae: 0.1110 - val_loss: 0.0252 - val_mae: 0.1053\n",
      "Epoch 19/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0268 - mae: 0.1118 - val_loss: 0.0254 - val_mae: 0.1081\n",
      "Epoch 20/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0264 - mae: 0.1119 - val_loss: 0.0247 - val_mae: 0.1049\n",
      "Epoch 21/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0275 - mae: 0.1136 - val_loss: 0.0250 - val_mae: 0.1051\n",
      "Epoch 22/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0267 - mae: 0.1115 - val_loss: 0.0247 - val_mae: 0.1043\n",
      "Epoch 23/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0262 - mae: 0.1104 - val_loss: 0.0245 - val_mae: 0.1045\n",
      "Epoch 24/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0256 - mae: 0.1088 - val_loss: 0.0246 - val_mae: 0.1046\n",
      "Epoch 25/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0264 - mae: 0.1119 - val_loss: 0.0244 - val_mae: 0.1040\n",
      "Epoch 26/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0263 - mae: 0.1117 - val_loss: 0.0247 - val_mae: 0.1073\n",
      "Epoch 27/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0267 - mae: 0.1130 - val_loss: 0.0245 - val_mae: 0.1044\n",
      "Epoch 28/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0262 - mae: 0.1104 - val_loss: 0.0243 - val_mae: 0.1037\n",
      "Epoch 29/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0266 - mae: 0.1125 - val_loss: 0.0239 - val_mae: 0.1035\n",
      "Epoch 30/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0261 - mae: 0.1102 - val_loss: 0.0239 - val_mae: 0.1037\n",
      "Epoch 31/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0250 - mae: 0.1089 - val_loss: 0.0240 - val_mae: 0.1033\n",
      "Epoch 32/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0261 - mae: 0.1109 - val_loss: 0.0242 - val_mae: 0.1042\n",
      "Epoch 33/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0260 - mae: 0.1109 - val_loss: 0.0240 - val_mae: 0.1042\n",
      "Epoch 34/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0251 - mae: 0.1084 - val_loss: 0.0238 - val_mae: 0.1040\n",
      "Epoch 35/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0249 - mae: 0.1086 - val_loss: 0.0233 - val_mae: 0.1012\n",
      "Epoch 36/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0255 - mae: 0.1099 - val_loss: 0.0239 - val_mae: 0.1044\n",
      "Epoch 37/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0257 - mae: 0.1105 - val_loss: 0.0235 - val_mae: 0.1021\n",
      "Epoch 38/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0253 - mae: 0.1090 - val_loss: 0.0240 - val_mae: 0.1065\n",
      "Epoch 39/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0259 - mae: 0.1108 - val_loss: 0.0234 - val_mae: 0.1022\n",
      "Epoch 40/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0257 - mae: 0.1095 - val_loss: 0.0235 - val_mae: 0.1019\n",
      "Epoch 41/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0255 - mae: 0.1092 - val_loss: 0.0234 - val_mae: 0.1015\n",
      "Epoch 42/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0257 - mae: 0.1094 - val_loss: 0.0239 - val_mae: 0.1045\n",
      "Epoch 43/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0251 - mae: 0.1090 - val_loss: 0.0234 - val_mae: 0.1000\n",
      "Epoch 44/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0246 - mae: 0.1075 - val_loss: 0.0241 - val_mae: 0.1105\n",
      "Epoch 45/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0247 - mae: 0.1079 - val_loss: 0.0232 - val_mae: 0.1015\n",
      "Epoch 46/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0244 - mae: 0.1068 - val_loss: 0.0235 - val_mae: 0.1038\n",
      "Epoch 47/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0253 - mae: 0.1102 - val_loss: 0.0229 - val_mae: 0.0999\n",
      "Epoch 48/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0252 - mae: 0.1092 - val_loss: 0.0230 - val_mae: 0.1007\n",
      "Epoch 49/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0241 - mae: 0.1066 - val_loss: 0.0232 - val_mae: 0.1014\n",
      "Epoch 50/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0260 - mae: 0.1097 - val_loss: 0.0230 - val_mae: 0.1037\n",
      "Epoch 51/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0255 - mae: 0.1096 - val_loss: 0.0228 - val_mae: 0.0998\n",
      "Epoch 52/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0247 - mae: 0.1067 - val_loss: 0.0237 - val_mae: 0.1029\n",
      "Epoch 53/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0246 - mae: 0.1056 - val_loss: 0.0228 - val_mae: 0.1003\n",
      "Epoch 54/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0244 - mae: 0.1070 - val_loss: 0.0231 - val_mae: 0.1003\n",
      "Epoch 55/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0259 - mae: 0.1093 - val_loss: 0.0229 - val_mae: 0.1033\n",
      "Epoch 56/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0238 - mae: 0.1048 - val_loss: 0.0229 - val_mae: 0.1007\n",
      "Epoch 57/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0245 - mae: 0.1071 - val_loss: 0.0249 - val_mae: 0.1110\n",
      "Epoch 58/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0251 - mae: 0.1086 - val_loss: 0.0228 - val_mae: 0.0997\n",
      "Epoch 59/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0248 - mae: 0.1077 - val_loss: 0.0226 - val_mae: 0.1000\n",
      "Epoch 60/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0246 - mae: 0.1056 - val_loss: 0.0225 - val_mae: 0.0998\n",
      "Epoch 61/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0242 - mae: 0.1053 - val_loss: 0.0226 - val_mae: 0.1011\n",
      "Epoch 62/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0242 - mae: 0.1058 - val_loss: 0.0224 - val_mae: 0.0979\n",
      "Epoch 63/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0250 - mae: 0.1066 - val_loss: 0.0225 - val_mae: 0.0989\n",
      "Epoch 64/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0240 - mae: 0.1053 - val_loss: 0.0227 - val_mae: 0.1005\n",
      "Epoch 65/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0241 - mae: 0.1056 - val_loss: 0.0226 - val_mae: 0.1000\n",
      "Epoch 66/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0248 - mae: 0.1070 - val_loss: 0.0224 - val_mae: 0.1021\n",
      "Epoch 67/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0242 - mae: 0.1053 - val_loss: 0.0226 - val_mae: 0.1005\n",
      "Epoch 68/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0236 - mae: 0.1041 - val_loss: 0.0220 - val_mae: 0.0977\n",
      "Epoch 69/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0243 - mae: 0.1057 - val_loss: 0.0224 - val_mae: 0.0981\n",
      "Epoch 70/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0238 - mae: 0.1049 - val_loss: 0.0221 - val_mae: 0.0954\n",
      "Epoch 71/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0247 - mae: 0.1065 - val_loss: 0.0222 - val_mae: 0.0978\n",
      "Epoch 72/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0244 - mae: 0.1056 - val_loss: 0.0225 - val_mae: 0.0984\n",
      "Epoch 73/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0235 - mae: 0.1028 - val_loss: 0.0221 - val_mae: 0.0993\n",
      "Epoch 74/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0240 - mae: 0.1042 - val_loss: 0.0223 - val_mae: 0.0978\n",
      "Epoch 75/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0241 - mae: 0.1045 - val_loss: 0.0228 - val_mae: 0.1011\n",
      "Epoch 76/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0234 - mae: 0.1039 - val_loss: 0.0221 - val_mae: 0.0973\n",
      "Epoch 77/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0239 - mae: 0.1049 - val_loss: 0.0223 - val_mae: 0.1010\n",
      "Epoch 78/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0241 - mae: 0.1054 - val_loss: 0.0224 - val_mae: 0.1006\n",
      "Epoch 79/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0240 - mae: 0.1055 - val_loss: 0.0220 - val_mae: 0.0971\n",
      "Epoch 80/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0238 - mae: 0.1048 - val_loss: 0.0220 - val_mae: 0.0972\n",
      "Epoch 81/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0244 - mae: 0.1056 - val_loss: 0.0219 - val_mae: 0.0980\n",
      "Epoch 82/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0232 - mae: 0.1035 - val_loss: 0.0222 - val_mae: 0.0991\n",
      "Epoch 83/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0235 - mae: 0.1036 - val_loss: 0.0233 - val_mae: 0.1059\n",
      "Epoch 84/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0235 - mae: 0.1039 - val_loss: 0.0224 - val_mae: 0.1011\n",
      "Epoch 85/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0242 - mae: 0.1063 - val_loss: 0.0225 - val_mae: 0.0999\n",
      "Epoch 86/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0243 - mae: 0.1053 - val_loss: 0.0219 - val_mae: 0.0964\n",
      "Epoch 87/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0238 - mae: 0.1037 - val_loss: 0.0221 - val_mae: 0.0995\n",
      "Epoch 88/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0235 - mae: 0.1035 - val_loss: 0.0219 - val_mae: 0.0970\n",
      "Epoch 89/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0236 - mae: 0.1033 - val_loss: 0.0222 - val_mae: 0.0983\n",
      "Epoch 90/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0244 - mae: 0.1052 - val_loss: 0.0222 - val_mae: 0.1000\n",
      "Epoch 91/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0236 - mae: 0.1049 - val_loss: 0.0223 - val_mae: 0.1002\n",
      "Epoch 92/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0239 - mae: 0.1045 - val_loss: 0.0222 - val_mae: 0.0993\n",
      "Epoch 93/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0235 - mae: 0.1036 - val_loss: 0.0217 - val_mae: 0.0973\n",
      "Epoch 94/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0246 - mae: 0.1062 - val_loss: 0.0218 - val_mae: 0.0967\n",
      "Epoch 95/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0241 - mae: 0.1047 - val_loss: 0.0227 - val_mae: 0.1039\n",
      "Epoch 96/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0232 - mae: 0.1036 - val_loss: 0.0221 - val_mae: 0.0980\n",
      "Epoch 97/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0239 - mae: 0.1053 - val_loss: 0.0216 - val_mae: 0.0978\n",
      "Epoch 98/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0233 - mae: 0.1025 - val_loss: 0.0222 - val_mae: 0.1017\n",
      "Epoch 99/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0233 - mae: 0.1039 - val_loss: 0.0227 - val_mae: 0.1005\n",
      "Epoch 100/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0238 - mae: 0.1049 - val_loss: 0.0221 - val_mae: 0.0998\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0219 - mae: 0.0995\n",
      "---------------------------------------------------------\n",
      "K 1 FOLD\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elped\\AppData\\Local\\Temp\\ipykernel_13956\\4226922763.py:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[features] = scaler.fit_transform(x[features])\n",
      "c:\\Users\\elped\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.3151 - mae: 0.1571 - val_loss: 0.0783 - val_mae: 0.1248\n",
      "Epoch 2/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0628 - mae: 0.1311 - val_loss: 0.0334 - val_mae: 0.1168\n",
      "Epoch 3/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0330 - mae: 0.1198 - val_loss: 0.0293 - val_mae: 0.1107\n",
      "Epoch 4/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0312 - mae: 0.1197 - val_loss: 0.0284 - val_mae: 0.1096\n",
      "Epoch 5/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0304 - mae: 0.1195 - val_loss: 0.0278 - val_mae: 0.1073\n",
      "Epoch 6/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0300 - mae: 0.1176 - val_loss: 0.0272 - val_mae: 0.1062\n",
      "Epoch 7/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0292 - mae: 0.1170 - val_loss: 0.0269 - val_mae: 0.1057\n",
      "Epoch 8/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0290 - mae: 0.1162 - val_loss: 0.0266 - val_mae: 0.1054\n",
      "Epoch 9/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0281 - mae: 0.1137 - val_loss: 0.0261 - val_mae: 0.1054\n",
      "Epoch 10/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0286 - mae: 0.1161 - val_loss: 0.0262 - val_mae: 0.1045\n",
      "Epoch 11/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0285 - mae: 0.1153 - val_loss: 0.0259 - val_mae: 0.1017\n",
      "Epoch 12/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0281 - mae: 0.1141 - val_loss: 0.0256 - val_mae: 0.1020\n",
      "Epoch 13/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0284 - mae: 0.1159 - val_loss: 0.0254 - val_mae: 0.1021\n",
      "Epoch 14/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0271 - mae: 0.1126 - val_loss: 0.0253 - val_mae: 0.1027\n",
      "Epoch 15/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0274 - mae: 0.1139 - val_loss: 0.0254 - val_mae: 0.1022\n",
      "Epoch 16/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0274 - mae: 0.1146 - val_loss: 0.0255 - val_mae: 0.1057\n",
      "Epoch 17/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0270 - mae: 0.1128 - val_loss: 0.0249 - val_mae: 0.1021\n",
      "Epoch 18/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0268 - mae: 0.1117 - val_loss: 0.0250 - val_mae: 0.1039\n",
      "Epoch 19/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0271 - mae: 0.1143 - val_loss: 0.0249 - val_mae: 0.1048\n",
      "Epoch 20/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0271 - mae: 0.1145 - val_loss: 0.0245 - val_mae: 0.1007\n",
      "Epoch 21/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0269 - mae: 0.1127 - val_loss: 0.0245 - val_mae: 0.0989\n",
      "Epoch 22/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0258 - mae: 0.1108 - val_loss: 0.0248 - val_mae: 0.1062\n",
      "Epoch 23/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0263 - mae: 0.1107 - val_loss: 0.0242 - val_mae: 0.1014\n",
      "Epoch 24/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0263 - mae: 0.1121 - val_loss: 0.0242 - val_mae: 0.1022\n",
      "Epoch 25/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0265 - mae: 0.1126 - val_loss: 0.0241 - val_mae: 0.1022\n",
      "Epoch 26/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0258 - mae: 0.1107 - val_loss: 0.0243 - val_mae: 0.1019\n",
      "Epoch 27/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0268 - mae: 0.1130 - val_loss: 0.0244 - val_mae: 0.1019\n",
      "Epoch 28/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0253 - mae: 0.1095 - val_loss: 0.0238 - val_mae: 0.0979\n",
      "Epoch 29/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0264 - mae: 0.1123 - val_loss: 0.0238 - val_mae: 0.1007\n",
      "Epoch 30/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0263 - mae: 0.1118 - val_loss: 0.0239 - val_mae: 0.1014\n",
      "Epoch 31/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0258 - mae: 0.1105 - val_loss: 0.0239 - val_mae: 0.1028\n",
      "Epoch 32/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0256 - mae: 0.1099 - val_loss: 0.0234 - val_mae: 0.0990\n",
      "Epoch 33/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0260 - mae: 0.1116 - val_loss: 0.0238 - val_mae: 0.1001\n",
      "Epoch 34/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0255 - mae: 0.1105 - val_loss: 0.0233 - val_mae: 0.1007\n",
      "Epoch 35/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0259 - mae: 0.1118 - val_loss: 0.0235 - val_mae: 0.1000\n",
      "Epoch 36/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0252 - mae: 0.1087 - val_loss: 0.0232 - val_mae: 0.0985\n",
      "Epoch 37/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0254 - mae: 0.1094 - val_loss: 0.0232 - val_mae: 0.0993\n",
      "Epoch 38/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0249 - mae: 0.1077 - val_loss: 0.0234 - val_mae: 0.1005\n",
      "Epoch 39/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0250 - mae: 0.1092 - val_loss: 0.0232 - val_mae: 0.0988\n",
      "Epoch 40/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0243 - mae: 0.1073 - val_loss: 0.0230 - val_mae: 0.0989\n",
      "Epoch 41/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0252 - mae: 0.1093 - val_loss: 0.0231 - val_mae: 0.0990\n",
      "Epoch 42/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0250 - mae: 0.1086 - val_loss: 0.0231 - val_mae: 0.0975\n",
      "Epoch 43/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0253 - mae: 0.1086 - val_loss: 0.0234 - val_mae: 0.1010\n",
      "Epoch 44/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0249 - mae: 0.1084 - val_loss: 0.0228 - val_mae: 0.0987\n",
      "Epoch 45/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0248 - mae: 0.1075 - val_loss: 0.0230 - val_mae: 0.0998\n",
      "Epoch 46/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0250 - mae: 0.1076 - val_loss: 0.0228 - val_mae: 0.0991\n",
      "Epoch 47/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0252 - mae: 0.1089 - val_loss: 0.0230 - val_mae: 0.0968\n",
      "Epoch 48/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0247 - mae: 0.1074 - val_loss: 0.0230 - val_mae: 0.0979\n",
      "Epoch 49/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0246 - mae: 0.1067 - val_loss: 0.0228 - val_mae: 0.0967\n",
      "Epoch 50/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0245 - mae: 0.1065 - val_loss: 0.0228 - val_mae: 0.0982\n",
      "Epoch 51/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0253 - mae: 0.1088 - val_loss: 0.0228 - val_mae: 0.0969\n",
      "Epoch 52/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0255 - mae: 0.1087 - val_loss: 0.0226 - val_mae: 0.0980\n",
      "Epoch 53/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0255 - mae: 0.1092 - val_loss: 0.0227 - val_mae: 0.0979\n",
      "Epoch 54/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0250 - mae: 0.1077 - val_loss: 0.0225 - val_mae: 0.0973\n",
      "Epoch 55/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0243 - mae: 0.1058 - val_loss: 0.0230 - val_mae: 0.1010\n",
      "Epoch 56/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0246 - mae: 0.1074 - val_loss: 0.0231 - val_mae: 0.0991\n",
      "Epoch 57/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0251 - mae: 0.1078 - val_loss: 0.0228 - val_mae: 0.0984\n",
      "Epoch 58/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0248 - mae: 0.1082 - val_loss: 0.0227 - val_mae: 0.0977\n",
      "Epoch 59/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0246 - mae: 0.1067 - val_loss: 0.0227 - val_mae: 0.0993\n",
      "Epoch 60/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0247 - mae: 0.1072 - val_loss: 0.0231 - val_mae: 0.1006\n",
      "Epoch 61/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0248 - mae: 0.1073 - val_loss: 0.0227 - val_mae: 0.0979\n",
      "Epoch 62/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0249 - mae: 0.1083 - val_loss: 0.0224 - val_mae: 0.0963\n",
      "Epoch 63/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0238 - mae: 0.1055 - val_loss: 0.0225 - val_mae: 0.0988\n",
      "Epoch 64/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0247 - mae: 0.1077 - val_loss: 0.0227 - val_mae: 0.0998\n",
      "Epoch 65/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0247 - mae: 0.1075 - val_loss: 0.0222 - val_mae: 0.0963\n",
      "Epoch 66/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0242 - mae: 0.1050 - val_loss: 0.0225 - val_mae: 0.0976\n",
      "Epoch 67/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0243 - mae: 0.1061 - val_loss: 0.0225 - val_mae: 0.0972\n",
      "Epoch 68/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0245 - mae: 0.1060 - val_loss: 0.0224 - val_mae: 0.0969\n",
      "Epoch 69/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0245 - mae: 0.1057 - val_loss: 0.0225 - val_mae: 0.0973\n",
      "Epoch 70/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0234 - mae: 0.1036 - val_loss: 0.0224 - val_mae: 0.0977\n",
      "Epoch 71/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0233 - mae: 0.1026 - val_loss: 0.0226 - val_mae: 0.0983\n",
      "Epoch 72/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0248 - mae: 0.1072 - val_loss: 0.0230 - val_mae: 0.0992\n",
      "Epoch 73/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0240 - mae: 0.1045 - val_loss: 0.0221 - val_mae: 0.0944\n",
      "Epoch 74/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0249 - mae: 0.1076 - val_loss: 0.0222 - val_mae: 0.0954\n",
      "Epoch 75/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0246 - mae: 0.1066 - val_loss: 0.0222 - val_mae: 0.0971\n",
      "Epoch 76/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0241 - mae: 0.1059 - val_loss: 0.0221 - val_mae: 0.0946\n",
      "Epoch 77/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0240 - mae: 0.1054 - val_loss: 0.0222 - val_mae: 0.0983\n",
      "Epoch 78/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0240 - mae: 0.1057 - val_loss: 0.0225 - val_mae: 0.0990\n",
      "Epoch 79/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0237 - mae: 0.1048 - val_loss: 0.0221 - val_mae: 0.0969\n",
      "Epoch 80/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0228 - mae: 0.1028 - val_loss: 0.0225 - val_mae: 0.1011\n",
      "Epoch 81/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0238 - mae: 0.1057 - val_loss: 0.0234 - val_mae: 0.1006\n",
      "Epoch 82/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0250 - mae: 0.1072 - val_loss: 0.0220 - val_mae: 0.0951\n",
      "Epoch 83/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0242 - mae: 0.1052 - val_loss: 0.0218 - val_mae: 0.0947\n",
      "Epoch 84/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0245 - mae: 0.1052 - val_loss: 0.0219 - val_mae: 0.0944\n",
      "Epoch 85/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0240 - mae: 0.1056 - val_loss: 0.0220 - val_mae: 0.0954\n",
      "Epoch 86/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0238 - mae: 0.1044 - val_loss: 0.0222 - val_mae: 0.0971\n",
      "Epoch 87/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0235 - mae: 0.1046 - val_loss: 0.0221 - val_mae: 0.0975\n",
      "Epoch 88/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0238 - mae: 0.1045 - val_loss: 0.0226 - val_mae: 0.0961\n",
      "Epoch 89/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0233 - mae: 0.1034 - val_loss: 0.0225 - val_mae: 0.0998\n",
      "Epoch 90/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0233 - mae: 0.1039 - val_loss: 0.0230 - val_mae: 0.1029\n",
      "Epoch 91/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0238 - mae: 0.1054 - val_loss: 0.0226 - val_mae: 0.0988\n",
      "Epoch 92/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0236 - mae: 0.1036 - val_loss: 0.0221 - val_mae: 0.0957\n",
      "Epoch 93/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0237 - mae: 0.1045 - val_loss: 0.0220 - val_mae: 0.0948\n",
      "Epoch 94/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0238 - mae: 0.1049 - val_loss: 0.0223 - val_mae: 0.0967\n",
      "Epoch 95/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0236 - mae: 0.1045 - val_loss: 0.0221 - val_mae: 0.0944\n",
      "Epoch 96/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0235 - mae: 0.1039 - val_loss: 0.0217 - val_mae: 0.0946\n",
      "Epoch 97/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0227 - mae: 0.1018 - val_loss: 0.0217 - val_mae: 0.0948\n",
      "Epoch 98/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0248 - mae: 0.1065 - val_loss: 0.0222 - val_mae: 0.0969\n",
      "Epoch 99/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0245 - mae: 0.1069 - val_loss: 0.0221 - val_mae: 0.0973\n",
      "Epoch 100/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0239 - mae: 0.1041 - val_loss: 0.0224 - val_mae: 0.0988\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0239 - mae: 0.1013\n",
      "---------------------------------------------------------\n",
      "K 2 FOLD\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elped\\AppData\\Local\\Temp\\ipykernel_13956\\4226922763.py:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[features] = scaler.fit_transform(x[features])\n",
      "c:\\Users\\elped\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.3234 - mae: 0.1720 - val_loss: 0.0837 - val_mae: 0.1268\n",
      "Epoch 2/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0638 - mae: 0.1252 - val_loss: 0.0345 - val_mae: 0.1174\n",
      "Epoch 3/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0330 - mae: 0.1196 - val_loss: 0.0295 - val_mae: 0.1127\n",
      "Epoch 4/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0301 - mae: 0.1174 - val_loss: 0.0285 - val_mae: 0.1116\n",
      "Epoch 5/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0298 - mae: 0.1175 - val_loss: 0.0283 - val_mae: 0.1127\n",
      "Epoch 6/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0293 - mae: 0.1166 - val_loss: 0.0279 - val_mae: 0.1103\n",
      "Epoch 7/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0294 - mae: 0.1164 - val_loss: 0.0275 - val_mae: 0.1098\n",
      "Epoch 8/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0288 - mae: 0.1156 - val_loss: 0.0271 - val_mae: 0.1072\n",
      "Epoch 9/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0281 - mae: 0.1137 - val_loss: 0.0275 - val_mae: 0.1120\n",
      "Epoch 10/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0274 - mae: 0.1128 - val_loss: 0.0265 - val_mae: 0.1075\n",
      "Epoch 11/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0280 - mae: 0.1138 - val_loss: 0.0264 - val_mae: 0.1072\n",
      "Epoch 12/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0274 - mae: 0.1125 - val_loss: 0.0267 - val_mae: 0.1116\n",
      "Epoch 13/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0277 - mae: 0.1141 - val_loss: 0.0260 - val_mae: 0.1075\n",
      "Epoch 14/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0273 - mae: 0.1128 - val_loss: 0.0266 - val_mae: 0.1103\n",
      "Epoch 15/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0271 - mae: 0.1125 - val_loss: 0.0257 - val_mae: 0.1065\n",
      "Epoch 16/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0268 - mae: 0.1120 - val_loss: 0.0260 - val_mae: 0.1069\n",
      "Epoch 17/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0267 - mae: 0.1123 - val_loss: 0.0258 - val_mae: 0.1077\n",
      "Epoch 18/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0272 - mae: 0.1127 - val_loss: 0.0256 - val_mae: 0.1065\n",
      "Epoch 19/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0266 - mae: 0.1119 - val_loss: 0.0254 - val_mae: 0.1055\n",
      "Epoch 20/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0263 - mae: 0.1102 - val_loss: 0.0256 - val_mae: 0.1073\n",
      "Epoch 21/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0252 - mae: 0.1081 - val_loss: 0.0252 - val_mae: 0.1056\n",
      "Epoch 22/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0260 - mae: 0.1102 - val_loss: 0.0255 - val_mae: 0.1077\n",
      "Epoch 23/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0262 - mae: 0.1106 - val_loss: 0.0252 - val_mae: 0.1074\n",
      "Epoch 24/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0262 - mae: 0.1109 - val_loss: 0.0250 - val_mae: 0.1047\n",
      "Epoch 25/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0261 - mae: 0.1103 - val_loss: 0.0250 - val_mae: 0.1044\n",
      "Epoch 26/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0253 - mae: 0.1081 - val_loss: 0.0251 - val_mae: 0.1055\n",
      "Epoch 27/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0250 - mae: 0.1089 - val_loss: 0.0247 - val_mae: 0.1050\n",
      "Epoch 28/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0254 - mae: 0.1091 - val_loss: 0.0244 - val_mae: 0.1049\n",
      "Epoch 29/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0248 - mae: 0.1072 - val_loss: 0.0249 - val_mae: 0.1034\n",
      "Epoch 30/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0245 - mae: 0.1055 - val_loss: 0.0243 - val_mae: 0.1051\n",
      "Epoch 31/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0249 - mae: 0.1079 - val_loss: 0.0248 - val_mae: 0.1051\n",
      "Epoch 32/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0255 - mae: 0.1092 - val_loss: 0.0243 - val_mae: 0.1051\n",
      "Epoch 33/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0257 - mae: 0.1103 - val_loss: 0.0241 - val_mae: 0.1025\n",
      "Epoch 34/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0250 - mae: 0.1076 - val_loss: 0.0240 - val_mae: 0.1022\n",
      "Epoch 35/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0245 - mae: 0.1061 - val_loss: 0.0245 - val_mae: 0.1035\n",
      "Epoch 36/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0258 - mae: 0.1095 - val_loss: 0.0253 - val_mae: 0.1115\n",
      "Epoch 37/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0248 - mae: 0.1063 - val_loss: 0.0242 - val_mae: 0.1055\n",
      "Epoch 38/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0248 - mae: 0.1077 - val_loss: 0.0244 - val_mae: 0.1050\n",
      "Epoch 39/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0249 - mae: 0.1070 - val_loss: 0.0240 - val_mae: 0.1028\n",
      "Epoch 40/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0251 - mae: 0.1077 - val_loss: 0.0242 - val_mae: 0.1050\n",
      "Epoch 41/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0249 - mae: 0.1072 - val_loss: 0.0240 - val_mae: 0.1042\n",
      "Epoch 42/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0241 - mae: 0.1052 - val_loss: 0.0244 - val_mae: 0.1039\n",
      "Epoch 43/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0251 - mae: 0.1062 - val_loss: 0.0240 - val_mae: 0.1040\n",
      "Epoch 44/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0248 - mae: 0.1068 - val_loss: 0.0239 - val_mae: 0.1027\n",
      "Epoch 45/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0240 - mae: 0.1040 - val_loss: 0.0240 - val_mae: 0.1023\n",
      "Epoch 46/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0242 - mae: 0.1054 - val_loss: 0.0240 - val_mae: 0.1033\n",
      "Epoch 47/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0242 - mae: 0.1052 - val_loss: 0.0242 - val_mae: 0.1076\n",
      "Epoch 48/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0242 - mae: 0.1053 - val_loss: 0.0236 - val_mae: 0.1014\n",
      "Epoch 49/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0241 - mae: 0.1040 - val_loss: 0.0238 - val_mae: 0.1041\n",
      "Epoch 50/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0244 - mae: 0.1063 - val_loss: 0.0248 - val_mae: 0.1104\n",
      "Epoch 51/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0237 - mae: 0.1050 - val_loss: 0.0237 - val_mae: 0.1045\n",
      "Epoch 52/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0242 - mae: 0.1055 - val_loss: 0.0246 - val_mae: 0.1102\n",
      "Epoch 53/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0240 - mae: 0.1052 - val_loss: 0.0239 - val_mae: 0.1040\n",
      "Epoch 54/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0236 - mae: 0.1039 - val_loss: 0.0236 - val_mae: 0.1028\n",
      "Epoch 55/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0240 - mae: 0.1047 - val_loss: 0.0236 - val_mae: 0.1034\n",
      "Epoch 56/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0246 - mae: 0.1056 - val_loss: 0.0235 - val_mae: 0.1028\n",
      "Epoch 57/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0243 - mae: 0.1050 - val_loss: 0.0234 - val_mae: 0.1003\n",
      "Epoch 58/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0235 - mae: 0.1031 - val_loss: 0.0237 - val_mae: 0.1003\n",
      "Epoch 59/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0250 - mae: 0.1069 - val_loss: 0.0233 - val_mae: 0.1016\n",
      "Epoch 60/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0240 - mae: 0.1037 - val_loss: 0.0234 - val_mae: 0.1023\n",
      "Epoch 61/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0238 - mae: 0.1050 - val_loss: 0.0242 - val_mae: 0.1039\n",
      "Epoch 62/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0241 - mae: 0.1054 - val_loss: 0.0233 - val_mae: 0.1024\n",
      "Epoch 63/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0247 - mae: 0.1056 - val_loss: 0.0230 - val_mae: 0.1002\n",
      "Epoch 64/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0238 - mae: 0.1040 - val_loss: 0.0233 - val_mae: 0.1035\n",
      "Epoch 65/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0242 - mae: 0.1059 - val_loss: 0.0232 - val_mae: 0.1017\n",
      "Epoch 66/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0234 - mae: 0.1030 - val_loss: 0.0230 - val_mae: 0.1009\n",
      "Epoch 67/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0238 - mae: 0.1030 - val_loss: 0.0228 - val_mae: 0.0999\n",
      "Epoch 68/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0238 - mae: 0.1040 - val_loss: 0.0235 - val_mae: 0.1024\n",
      "Epoch 69/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0242 - mae: 0.1044 - val_loss: 0.0237 - val_mae: 0.1046\n",
      "Epoch 70/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0238 - mae: 0.1047 - val_loss: 0.0236 - val_mae: 0.1035\n",
      "Epoch 71/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0240 - mae: 0.1044 - val_loss: 0.0230 - val_mae: 0.0997\n",
      "Epoch 72/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0239 - mae: 0.1046 - val_loss: 0.0235 - val_mae: 0.1028\n",
      "Epoch 73/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0229 - mae: 0.1017 - val_loss: 0.0237 - val_mae: 0.1026\n",
      "Epoch 74/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0234 - mae: 0.1033 - val_loss: 0.0236 - val_mae: 0.1019\n",
      "Epoch 75/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0231 - mae: 0.1022 - val_loss: 0.0231 - val_mae: 0.1009\n",
      "Epoch 76/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0237 - mae: 0.1030 - val_loss: 0.0233 - val_mae: 0.1002\n",
      "Epoch 77/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0226 - mae: 0.1003 - val_loss: 0.0231 - val_mae: 0.1017\n",
      "Epoch 78/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0240 - mae: 0.1050 - val_loss: 0.0233 - val_mae: 0.0999\n",
      "Epoch 79/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0235 - mae: 0.1023 - val_loss: 0.0232 - val_mae: 0.1024\n",
      "Epoch 80/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0240 - mae: 0.1046 - val_loss: 0.0231 - val_mae: 0.1026\n",
      "Epoch 81/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0240 - mae: 0.1045 - val_loss: 0.0228 - val_mae: 0.0983\n",
      "Epoch 82/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0236 - mae: 0.1027 - val_loss: 0.0230 - val_mae: 0.1021\n",
      "Epoch 83/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0238 - mae: 0.1040 - val_loss: 0.0230 - val_mae: 0.0996\n",
      "Epoch 84/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0241 - mae: 0.1046 - val_loss: 0.0234 - val_mae: 0.1043\n",
      "Epoch 85/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0236 - mae: 0.1029 - val_loss: 0.0234 - val_mae: 0.1028\n",
      "Epoch 86/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0234 - mae: 0.1033 - val_loss: 0.0229 - val_mae: 0.1014\n",
      "Epoch 87/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0233 - mae: 0.1039 - val_loss: 0.0232 - val_mae: 0.1001\n",
      "Epoch 88/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0237 - mae: 0.1042 - val_loss: 0.0232 - val_mae: 0.1022\n",
      "Epoch 89/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0237 - mae: 0.1030 - val_loss: 0.0227 - val_mae: 0.0999\n",
      "Epoch 90/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0227 - mae: 0.1001 - val_loss: 0.0230 - val_mae: 0.1039\n",
      "Epoch 91/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0236 - mae: 0.1032 - val_loss: 0.0231 - val_mae: 0.1042\n",
      "Epoch 92/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0243 - mae: 0.1042 - val_loss: 0.0229 - val_mae: 0.1008\n",
      "Epoch 93/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0235 - mae: 0.1040 - val_loss: 0.0229 - val_mae: 0.1018\n",
      "Epoch 94/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0240 - mae: 0.1052 - val_loss: 0.0229 - val_mae: 0.1018\n",
      "Epoch 95/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0229 - mae: 0.1023 - val_loss: 0.0228 - val_mae: 0.0998\n",
      "Epoch 96/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0238 - mae: 0.1042 - val_loss: 0.0227 - val_mae: 0.1000\n",
      "Epoch 97/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0229 - mae: 0.1016 - val_loss: 0.0238 - val_mae: 0.1051\n",
      "Epoch 98/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0225 - mae: 0.1003 - val_loss: 0.0231 - val_mae: 0.1015\n",
      "Epoch 99/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0231 - mae: 0.1028 - val_loss: 0.0226 - val_mae: 0.1009\n",
      "Epoch 100/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0234 - mae: 0.1035 - val_loss: 0.0225 - val_mae: 0.0997\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0221 - mae: 0.0968\n",
      "---------------------------------------------------------\n",
      "K 3 FOLD\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elped\\AppData\\Local\\Temp\\ipykernel_13956\\4226922763.py:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[features] = scaler.fit_transform(x[features])\n",
      "c:\\Users\\elped\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.3102 - mae: 0.1586 - val_loss: 0.0787 - val_mae: 0.1272\n",
      "Epoch 2/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0604 - mae: 0.1265 - val_loss: 0.0344 - val_mae: 0.1180\n",
      "Epoch 3/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0333 - mae: 0.1207 - val_loss: 0.0305 - val_mae: 0.1144\n",
      "Epoch 4/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0301 - mae: 0.1168 - val_loss: 0.0293 - val_mae: 0.1147\n",
      "Epoch 5/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0289 - mae: 0.1156 - val_loss: 0.0287 - val_mae: 0.1123\n",
      "Epoch 6/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0292 - mae: 0.1162 - val_loss: 0.0287 - val_mae: 0.1117\n",
      "Epoch 7/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0286 - mae: 0.1152 - val_loss: 0.0280 - val_mae: 0.1113\n",
      "Epoch 8/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0284 - mae: 0.1149 - val_loss: 0.0280 - val_mae: 0.1115\n",
      "Epoch 9/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0280 - mae: 0.1128 - val_loss: 0.0275 - val_mae: 0.1084\n",
      "Epoch 10/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0282 - mae: 0.1142 - val_loss: 0.0272 - val_mae: 0.1081\n",
      "Epoch 11/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0281 - mae: 0.1139 - val_loss: 0.0272 - val_mae: 0.1090\n",
      "Epoch 12/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0261 - mae: 0.1085 - val_loss: 0.0270 - val_mae: 0.1109\n",
      "Epoch 13/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0274 - mae: 0.1130 - val_loss: 0.0266 - val_mae: 0.1075\n",
      "Epoch 14/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0270 - mae: 0.1120 - val_loss: 0.0268 - val_mae: 0.1086\n",
      "Epoch 15/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0270 - mae: 0.1116 - val_loss: 0.0263 - val_mae: 0.1087\n",
      "Epoch 16/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0267 - mae: 0.1115 - val_loss: 0.0266 - val_mae: 0.1093\n",
      "Epoch 17/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0263 - mae: 0.1109 - val_loss: 0.0261 - val_mae: 0.1094\n",
      "Epoch 18/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0269 - mae: 0.1131 - val_loss: 0.0260 - val_mae: 0.1072\n",
      "Epoch 19/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0268 - mae: 0.1121 - val_loss: 0.0266 - val_mae: 0.1115\n",
      "Epoch 20/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0263 - mae: 0.1106 - val_loss: 0.0258 - val_mae: 0.1080\n",
      "Epoch 21/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0266 - mae: 0.1114 - val_loss: 0.0259 - val_mae: 0.1082\n",
      "Epoch 22/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0257 - mae: 0.1098 - val_loss: 0.0254 - val_mae: 0.1064\n",
      "Epoch 23/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0265 - mae: 0.1117 - val_loss: 0.0257 - val_mae: 0.1065\n",
      "Epoch 24/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0265 - mae: 0.1116 - val_loss: 0.0255 - val_mae: 0.1063\n",
      "Epoch 25/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0259 - mae: 0.1096 - val_loss: 0.0255 - val_mae: 0.1079\n",
      "Epoch 26/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0258 - mae: 0.1096 - val_loss: 0.0251 - val_mae: 0.1050\n",
      "Epoch 27/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0254 - mae: 0.1086 - val_loss: 0.0255 - val_mae: 0.1068\n",
      "Epoch 28/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0255 - mae: 0.1094 - val_loss: 0.0250 - val_mae: 0.1061\n",
      "Epoch 29/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0254 - mae: 0.1092 - val_loss: 0.0250 - val_mae: 0.1064\n",
      "Epoch 30/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0253 - mae: 0.1091 - val_loss: 0.0252 - val_mae: 0.1066\n",
      "Epoch 31/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0256 - mae: 0.1101 - val_loss: 0.0260 - val_mae: 0.1101\n",
      "Epoch 32/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0256 - mae: 0.1091 - val_loss: 0.0252 - val_mae: 0.1089\n",
      "Epoch 33/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0258 - mae: 0.1106 - val_loss: 0.0249 - val_mae: 0.1063\n",
      "Epoch 34/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0255 - mae: 0.1083 - val_loss: 0.0251 - val_mae: 0.1066\n",
      "Epoch 35/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0251 - mae: 0.1087 - val_loss: 0.0247 - val_mae: 0.1058\n",
      "Epoch 36/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0252 - mae: 0.1082 - val_loss: 0.0249 - val_mae: 0.1052\n",
      "Epoch 37/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0252 - mae: 0.1076 - val_loss: 0.0243 - val_mae: 0.1027\n",
      "Epoch 38/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0245 - mae: 0.1059 - val_loss: 0.0246 - val_mae: 0.1046\n",
      "Epoch 39/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0247 - mae: 0.1056 - val_loss: 0.0246 - val_mae: 0.1049\n",
      "Epoch 40/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0250 - mae: 0.1078 - val_loss: 0.0247 - val_mae: 0.1042\n",
      "Epoch 41/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0255 - mae: 0.1076 - val_loss: 0.0249 - val_mae: 0.1109\n",
      "Epoch 42/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0249 - mae: 0.1078 - val_loss: 0.0253 - val_mae: 0.1059\n",
      "Epoch 43/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0243 - mae: 0.1051 - val_loss: 0.0252 - val_mae: 0.1081\n",
      "Epoch 44/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0254 - mae: 0.1089 - val_loss: 0.0241 - val_mae: 0.1026\n",
      "Epoch 45/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0248 - mae: 0.1068 - val_loss: 0.0242 - val_mae: 0.1058\n",
      "Epoch 46/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0245 - mae: 0.1068 - val_loss: 0.0241 - val_mae: 0.1034\n",
      "Epoch 47/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0246 - mae: 0.1065 - val_loss: 0.0241 - val_mae: 0.1030\n",
      "Epoch 48/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0251 - mae: 0.1080 - val_loss: 0.0239 - val_mae: 0.1041\n",
      "Epoch 49/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0242 - mae: 0.1067 - val_loss: 0.0241 - val_mae: 0.1039\n",
      "Epoch 50/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0249 - mae: 0.1072 - val_loss: 0.0243 - val_mae: 0.1041\n",
      "Epoch 51/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0243 - mae: 0.1062 - val_loss: 0.0243 - val_mae: 0.1058\n",
      "Epoch 52/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0245 - mae: 0.1063 - val_loss: 0.0245 - val_mae: 0.1072\n",
      "Epoch 53/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0242 - mae: 0.1058 - val_loss: 0.0237 - val_mae: 0.1027\n",
      "Epoch 54/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0247 - mae: 0.1069 - val_loss: 0.0238 - val_mae: 0.1032\n",
      "Epoch 55/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0236 - mae: 0.1042 - val_loss: 0.0237 - val_mae: 0.1023\n",
      "Epoch 56/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0240 - mae: 0.1055 - val_loss: 0.0234 - val_mae: 0.1003\n",
      "Epoch 57/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0236 - mae: 0.1038 - val_loss: 0.0239 - val_mae: 0.1033\n",
      "Epoch 58/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0243 - mae: 0.1064 - val_loss: 0.0244 - val_mae: 0.1085\n",
      "Epoch 59/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0240 - mae: 0.1061 - val_loss: 0.0237 - val_mae: 0.1034\n",
      "Epoch 60/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0240 - mae: 0.1046 - val_loss: 0.0241 - val_mae: 0.1036\n",
      "Epoch 61/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0249 - mae: 0.1070 - val_loss: 0.0238 - val_mae: 0.1029\n",
      "Epoch 62/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0231 - mae: 0.1023 - val_loss: 0.0242 - val_mae: 0.1045\n",
      "Epoch 63/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0237 - mae: 0.1035 - val_loss: 0.0237 - val_mae: 0.1042\n",
      "Epoch 64/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0238 - mae: 0.1040 - val_loss: 0.0238 - val_mae: 0.1055\n",
      "Epoch 65/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0232 - mae: 0.1032 - val_loss: 0.0235 - val_mae: 0.1025\n",
      "Epoch 66/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0241 - mae: 0.1045 - val_loss: 0.0235 - val_mae: 0.1022\n",
      "Epoch 67/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0242 - mae: 0.1054 - val_loss: 0.0235 - val_mae: 0.1010\n",
      "Epoch 68/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0238 - mae: 0.1041 - val_loss: 0.0232 - val_mae: 0.1016\n",
      "Epoch 69/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0244 - mae: 0.1055 - val_loss: 0.0233 - val_mae: 0.1004\n",
      "Epoch 70/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0246 - mae: 0.1056 - val_loss: 0.0237 - val_mae: 0.1021\n",
      "Epoch 71/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0246 - mae: 0.1061 - val_loss: 0.0240 - val_mae: 0.1058\n",
      "Epoch 72/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0242 - mae: 0.1058 - val_loss: 0.0232 - val_mae: 0.1008\n",
      "Epoch 73/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0239 - mae: 0.1047 - val_loss: 0.0232 - val_mae: 0.1013\n",
      "Epoch 74/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0240 - mae: 0.1042 - val_loss: 0.0236 - val_mae: 0.1018\n",
      "Epoch 75/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0234 - mae: 0.1025 - val_loss: 0.0241 - val_mae: 0.1070\n",
      "Epoch 76/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0238 - mae: 0.1046 - val_loss: 0.0234 - val_mae: 0.1020\n",
      "Epoch 77/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0238 - mae: 0.1050 - val_loss: 0.0239 - val_mae: 0.1042\n",
      "Epoch 78/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0236 - mae: 0.1037 - val_loss: 0.0230 - val_mae: 0.1007\n",
      "Epoch 79/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0234 - mae: 0.1033 - val_loss: 0.0232 - val_mae: 0.1006\n",
      "Epoch 80/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0238 - mae: 0.1042 - val_loss: 0.0238 - val_mae: 0.1032\n",
      "Epoch 81/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0236 - mae: 0.1045 - val_loss: 0.0230 - val_mae: 0.1003\n",
      "Epoch 82/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0235 - mae: 0.1031 - val_loss: 0.0227 - val_mae: 0.0977\n",
      "Epoch 83/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0233 - mae: 0.1036 - val_loss: 0.0225 - val_mae: 0.0990\n",
      "Epoch 84/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0238 - mae: 0.1043 - val_loss: 0.0241 - val_mae: 0.1014\n",
      "Epoch 85/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0230 - mae: 0.1021 - val_loss: 0.0233 - val_mae: 0.0994\n",
      "Epoch 86/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0232 - mae: 0.1033 - val_loss: 0.0242 - val_mae: 0.1067\n",
      "Epoch 87/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0231 - mae: 0.1029 - val_loss: 0.0234 - val_mae: 0.1010\n",
      "Epoch 88/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0237 - mae: 0.1038 - val_loss: 0.0241 - val_mae: 0.1016\n",
      "Epoch 89/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0235 - mae: 0.1030 - val_loss: 0.0231 - val_mae: 0.0992\n",
      "Epoch 90/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0236 - mae: 0.1031 - val_loss: 0.0229 - val_mae: 0.1022\n",
      "Epoch 91/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0229 - mae: 0.1022 - val_loss: 0.0246 - val_mae: 0.1040\n",
      "Epoch 92/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0237 - mae: 0.1038 - val_loss: 0.0229 - val_mae: 0.0992\n",
      "Epoch 93/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0227 - mae: 0.1011 - val_loss: 0.0234 - val_mae: 0.1023\n",
      "Epoch 94/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0240 - mae: 0.1051 - val_loss: 0.0229 - val_mae: 0.1009\n",
      "Epoch 95/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0231 - mae: 0.1023 - val_loss: 0.0233 - val_mae: 0.1030\n",
      "Epoch 96/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0242 - mae: 0.1052 - val_loss: 0.0231 - val_mae: 0.1013\n",
      "Epoch 97/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0231 - mae: 0.1017 - val_loss: 0.0230 - val_mae: 0.1008\n",
      "Epoch 98/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0232 - mae: 0.1045 - val_loss: 0.0224 - val_mae: 0.0992\n",
      "Epoch 99/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0232 - mae: 0.1032 - val_loss: 0.0230 - val_mae: 0.0986\n",
      "Epoch 100/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0241 - mae: 0.1039 - val_loss: 0.0227 - val_mae: 0.0993\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0224 - mae: 0.0980\n",
      "---------------------------------------------------------\n",
      "K 4 FOLD\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elped\\AppData\\Local\\Temp\\ipykernel_13956\\4226922763.py:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[features] = scaler.fit_transform(x[features])\n",
      "c:\\Users\\elped\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.3142 - mae: 0.1587 - val_loss: 0.0765 - val_mae: 0.1267\n",
      "Epoch 2/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0611 - mae: 0.1317 - val_loss: 0.0323 - val_mae: 0.1132\n",
      "Epoch 3/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0335 - mae: 0.1226 - val_loss: 0.0284 - val_mae: 0.1107\n",
      "Epoch 4/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0307 - mae: 0.1189 - val_loss: 0.0275 - val_mae: 0.1089\n",
      "Epoch 5/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0298 - mae: 0.1168 - val_loss: 0.0272 - val_mae: 0.1081\n",
      "Epoch 6/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0297 - mae: 0.1166 - val_loss: 0.0264 - val_mae: 0.1065\n",
      "Epoch 7/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0290 - mae: 0.1157 - val_loss: 0.0263 - val_mae: 0.1087\n",
      "Epoch 8/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0291 - mae: 0.1160 - val_loss: 0.0259 - val_mae: 0.1038\n",
      "Epoch 9/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0299 - mae: 0.1182 - val_loss: 0.0259 - val_mae: 0.1057\n",
      "Epoch 10/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0279 - mae: 0.1132 - val_loss: 0.0256 - val_mae: 0.1058\n",
      "Epoch 11/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0280 - mae: 0.1147 - val_loss: 0.0249 - val_mae: 0.1043\n",
      "Epoch 12/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0281 - mae: 0.1138 - val_loss: 0.0252 - val_mae: 0.1043\n",
      "Epoch 13/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0277 - mae: 0.1143 - val_loss: 0.0247 - val_mae: 0.1041\n",
      "Epoch 14/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0275 - mae: 0.1137 - val_loss: 0.0245 - val_mae: 0.1046\n",
      "Epoch 15/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0265 - mae: 0.1112 - val_loss: 0.0247 - val_mae: 0.1022\n",
      "Epoch 16/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0279 - mae: 0.1139 - val_loss: 0.0243 - val_mae: 0.1035\n",
      "Epoch 17/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0269 - mae: 0.1116 - val_loss: 0.0245 - val_mae: 0.1029\n",
      "Epoch 18/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0269 - mae: 0.1122 - val_loss: 0.0238 - val_mae: 0.1013\n",
      "Epoch 19/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0270 - mae: 0.1127 - val_loss: 0.0243 - val_mae: 0.1040\n",
      "Epoch 20/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0272 - mae: 0.1137 - val_loss: 0.0237 - val_mae: 0.1008\n",
      "Epoch 21/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0271 - mae: 0.1133 - val_loss: 0.0240 - val_mae: 0.1028\n",
      "Epoch 22/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0263 - mae: 0.1110 - val_loss: 0.0237 - val_mae: 0.1032\n",
      "Epoch 23/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0258 - mae: 0.1110 - val_loss: 0.0232 - val_mae: 0.1007\n",
      "Epoch 24/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0255 - mae: 0.1100 - val_loss: 0.0234 - val_mae: 0.1004\n",
      "Epoch 25/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0254 - mae: 0.1095 - val_loss: 0.0244 - val_mae: 0.1055\n",
      "Epoch 26/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0256 - mae: 0.1091 - val_loss: 0.0236 - val_mae: 0.1031\n",
      "Epoch 27/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0252 - mae: 0.1086 - val_loss: 0.0233 - val_mae: 0.1023\n",
      "Epoch 28/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0253 - mae: 0.1088 - val_loss: 0.0234 - val_mae: 0.1028\n",
      "Epoch 29/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0255 - mae: 0.1092 - val_loss: 0.0233 - val_mae: 0.1038\n",
      "Epoch 30/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0254 - mae: 0.1091 - val_loss: 0.0232 - val_mae: 0.1014\n",
      "Epoch 31/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0256 - mae: 0.1093 - val_loss: 0.0228 - val_mae: 0.0999\n",
      "Epoch 32/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0253 - mae: 0.1088 - val_loss: 0.0233 - val_mae: 0.1056\n",
      "Epoch 33/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0247 - mae: 0.1086 - val_loss: 0.0231 - val_mae: 0.1004\n",
      "Epoch 34/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0251 - mae: 0.1086 - val_loss: 0.0225 - val_mae: 0.1007\n",
      "Epoch 35/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0250 - mae: 0.1091 - val_loss: 0.0225 - val_mae: 0.0987\n",
      "Epoch 36/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0250 - mae: 0.1092 - val_loss: 0.0230 - val_mae: 0.1011\n",
      "Epoch 37/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0249 - mae: 0.1075 - val_loss: 0.0222 - val_mae: 0.0992\n",
      "Epoch 38/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0248 - mae: 0.1074 - val_loss: 0.0224 - val_mae: 0.0985\n",
      "Epoch 39/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0254 - mae: 0.1080 - val_loss: 0.0224 - val_mae: 0.1011\n",
      "Epoch 40/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0251 - mae: 0.1083 - val_loss: 0.0226 - val_mae: 0.0967\n",
      "Epoch 41/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0252 - mae: 0.1087 - val_loss: 0.0226 - val_mae: 0.1007\n",
      "Epoch 42/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0254 - mae: 0.1077 - val_loss: 0.0220 - val_mae: 0.0964\n",
      "Epoch 43/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0253 - mae: 0.1079 - val_loss: 0.0224 - val_mae: 0.0999\n",
      "Epoch 44/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0247 - mae: 0.1061 - val_loss: 0.0221 - val_mae: 0.0967\n",
      "Epoch 45/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0248 - mae: 0.1062 - val_loss: 0.0221 - val_mae: 0.1006\n",
      "Epoch 46/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0248 - mae: 0.1076 - val_loss: 0.0222 - val_mae: 0.0980\n",
      "Epoch 47/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0242 - mae: 0.1054 - val_loss: 0.0222 - val_mae: 0.0987\n",
      "Epoch 48/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0238 - mae: 0.1051 - val_loss: 0.0223 - val_mae: 0.1004\n",
      "Epoch 49/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0247 - mae: 0.1064 - val_loss: 0.0226 - val_mae: 0.0998\n",
      "Epoch 50/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0245 - mae: 0.1063 - val_loss: 0.0216 - val_mae: 0.0969\n",
      "Epoch 51/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0245 - mae: 0.1062 - val_loss: 0.0226 - val_mae: 0.1030\n",
      "Epoch 52/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0254 - mae: 0.1096 - val_loss: 0.0219 - val_mae: 0.0955\n",
      "Epoch 53/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0255 - mae: 0.1090 - val_loss: 0.0216 - val_mae: 0.0972\n",
      "Epoch 54/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0246 - mae: 0.1065 - val_loss: 0.0219 - val_mae: 0.0992\n",
      "Epoch 55/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0243 - mae: 0.1054 - val_loss: 0.0223 - val_mae: 0.0979\n",
      "Epoch 56/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0245 - mae: 0.1054 - val_loss: 0.0218 - val_mae: 0.0981\n",
      "Epoch 57/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0245 - mae: 0.1059 - val_loss: 0.0226 - val_mae: 0.1048\n",
      "Epoch 58/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0251 - mae: 0.1083 - val_loss: 0.0220 - val_mae: 0.0982\n",
      "Epoch 59/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0234 - mae: 0.1029 - val_loss: 0.0216 - val_mae: 0.0962\n",
      "Epoch 60/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0251 - mae: 0.1071 - val_loss: 0.0218 - val_mae: 0.0959\n",
      "Epoch 61/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0243 - mae: 0.1053 - val_loss: 0.0227 - val_mae: 0.1040\n",
      "Epoch 62/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0239 - mae: 0.1039 - val_loss: 0.0216 - val_mae: 0.0981\n",
      "Epoch 63/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0243 - mae: 0.1063 - val_loss: 0.0216 - val_mae: 0.0945\n",
      "Epoch 64/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0245 - mae: 0.1062 - val_loss: 0.0214 - val_mae: 0.0957\n",
      "Epoch 65/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0242 - mae: 0.1041 - val_loss: 0.0218 - val_mae: 0.0995\n",
      "Epoch 66/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0235 - mae: 0.1035 - val_loss: 0.0221 - val_mae: 0.0994\n",
      "Epoch 67/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0240 - mae: 0.1041 - val_loss: 0.0224 - val_mae: 0.0989\n",
      "Epoch 68/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0237 - mae: 0.1032 - val_loss: 0.0213 - val_mae: 0.0965\n",
      "Epoch 69/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0234 - mae: 0.1035 - val_loss: 0.0217 - val_mae: 0.0960\n",
      "Epoch 70/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0241 - mae: 0.1032 - val_loss: 0.0212 - val_mae: 0.0962\n",
      "Epoch 71/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0229 - mae: 0.1021 - val_loss: 0.0218 - val_mae: 0.0952\n",
      "Epoch 72/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0235 - mae: 0.1030 - val_loss: 0.0213 - val_mae: 0.0968\n",
      "Epoch 73/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0240 - mae: 0.1039 - val_loss: 0.0215 - val_mae: 0.0949\n",
      "Epoch 74/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0228 - mae: 0.1015 - val_loss: 0.0216 - val_mae: 0.0959\n",
      "Epoch 75/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0242 - mae: 0.1045 - val_loss: 0.0213 - val_mae: 0.0962\n",
      "Epoch 76/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0240 - mae: 0.1046 - val_loss: 0.0217 - val_mae: 0.0969\n",
      "Epoch 77/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0240 - mae: 0.1040 - val_loss: 0.0213 - val_mae: 0.0979\n",
      "Epoch 78/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0241 - mae: 0.1049 - val_loss: 0.0214 - val_mae: 0.0959\n",
      "Epoch 79/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0239 - mae: 0.1041 - val_loss: 0.0213 - val_mae: 0.0960\n",
      "Epoch 80/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0233 - mae: 0.1018 - val_loss: 0.0219 - val_mae: 0.1003\n",
      "Epoch 81/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0244 - mae: 0.1056 - val_loss: 0.0214 - val_mae: 0.0958\n",
      "Epoch 82/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0247 - mae: 0.1058 - val_loss: 0.0212 - val_mae: 0.0965\n",
      "Epoch 83/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0240 - mae: 0.1042 - val_loss: 0.0212 - val_mae: 0.0954\n",
      "Epoch 84/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0244 - mae: 0.1049 - val_loss: 0.0212 - val_mae: 0.0965\n",
      "Epoch 85/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0243 - mae: 0.1044 - val_loss: 0.0211 - val_mae: 0.0956\n",
      "Epoch 86/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0240 - mae: 0.1044 - val_loss: 0.0211 - val_mae: 0.0968\n",
      "Epoch 87/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0236 - mae: 0.1023 - val_loss: 0.0215 - val_mae: 0.0972\n",
      "Epoch 88/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0235 - mae: 0.1025 - val_loss: 0.0218 - val_mae: 0.0984\n",
      "Epoch 89/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0239 - mae: 0.1036 - val_loss: 0.0217 - val_mae: 0.0987\n",
      "Epoch 90/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0240 - mae: 0.1039 - val_loss: 0.0214 - val_mae: 0.0961\n",
      "Epoch 91/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0236 - mae: 0.1032 - val_loss: 0.0210 - val_mae: 0.0949\n",
      "Epoch 92/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0235 - mae: 0.1028 - val_loss: 0.0209 - val_mae: 0.0942\n",
      "Epoch 93/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0242 - mae: 0.1045 - val_loss: 0.0216 - val_mae: 0.0982\n",
      "Epoch 94/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0238 - mae: 0.1034 - val_loss: 0.0208 - val_mae: 0.0969\n",
      "Epoch 95/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0239 - mae: 0.1036 - val_loss: 0.0212 - val_mae: 0.0950\n",
      "Epoch 96/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0237 - mae: 0.1034 - val_loss: 0.0218 - val_mae: 0.0995\n",
      "Epoch 97/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0241 - mae: 0.1042 - val_loss: 0.0208 - val_mae: 0.0953\n",
      "Epoch 98/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0245 - mae: 0.1053 - val_loss: 0.0227 - val_mae: 0.1050\n",
      "Epoch 99/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0234 - mae: 0.1030 - val_loss: 0.0217 - val_mae: 0.0988\n",
      "Epoch 100/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0241 - mae: 0.1051 - val_loss: 0.0230 - val_mae: 0.1028\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - loss: 0.0223 - mae: 0.1009\n",
      "---------------------------------------------------------\n",
      "USER 3\n",
      "---------------------------------------------------------\n",
      "K 0 FOLD\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elped\\AppData\\Local\\Temp\\ipykernel_13956\\4226922763.py:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[features] = scaler.fit_transform(x[features])\n",
      "c:\\Users\\elped\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.3894 - mae: 0.1970 - val_loss: 0.2419 - val_mae: 0.1888\n",
      "Epoch 2/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2103 - mae: 0.1870 - val_loss: 0.1354 - val_mae: 0.1820\n",
      "Epoch 3/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1202 - mae: 0.1810 - val_loss: 0.0831 - val_mae: 0.1733\n",
      "Epoch 4/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0756 - mae: 0.1704 - val_loss: 0.0584 - val_mae: 0.1627\n",
      "Epoch 5/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0553 - mae: 0.1606 - val_loss: 0.0477 - val_mae: 0.1564\n",
      "Epoch 6/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0480 - mae: 0.1593 - val_loss: 0.0431 - val_mae: 0.1522\n",
      "Epoch 7/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0433 - mae: 0.1528 - val_loss: 0.0412 - val_mae: 0.1512\n",
      "Epoch 8/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0427 - mae: 0.1546 - val_loss: 0.0401 - val_mae: 0.1511\n",
      "Epoch 9/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0416 - mae: 0.1542 - val_loss: 0.0398 - val_mae: 0.1468\n",
      "Epoch 10/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0429 - mae: 0.1547 - val_loss: 0.0390 - val_mae: 0.1471\n",
      "Epoch 11/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0400 - mae: 0.1484 - val_loss: 0.0391 - val_mae: 0.1509\n",
      "Epoch 12/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0409 - mae: 0.1516 - val_loss: 0.0386 - val_mae: 0.1484\n",
      "Epoch 13/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0408 - mae: 0.1508 - val_loss: 0.0381 - val_mae: 0.1448\n",
      "Epoch 14/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0396 - mae: 0.1482 - val_loss: 0.0382 - val_mae: 0.1461\n",
      "Epoch 15/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0384 - mae: 0.1457 - val_loss: 0.0377 - val_mae: 0.1464\n",
      "Epoch 16/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0395 - mae: 0.1492 - val_loss: 0.0376 - val_mae: 0.1464\n",
      "Epoch 17/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0400 - mae: 0.1501 - val_loss: 0.0377 - val_mae: 0.1472\n",
      "Epoch 18/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0404 - mae: 0.1525 - val_loss: 0.0372 - val_mae: 0.1464\n",
      "Epoch 19/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0392 - mae: 0.1500 - val_loss: 0.0371 - val_mae: 0.1442\n",
      "Epoch 20/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0388 - mae: 0.1478 - val_loss: 0.0364 - val_mae: 0.1408\n",
      "Epoch 21/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0394 - mae: 0.1482 - val_loss: 0.0369 - val_mae: 0.1428\n",
      "Epoch 22/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0398 - mae: 0.1497 - val_loss: 0.0364 - val_mae: 0.1415\n",
      "Epoch 23/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0376 - mae: 0.1445 - val_loss: 0.0365 - val_mae: 0.1427\n",
      "Epoch 24/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0381 - mae: 0.1467 - val_loss: 0.0361 - val_mae: 0.1420\n",
      "Epoch 25/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0365 - mae: 0.1412 - val_loss: 0.0364 - val_mae: 0.1445\n",
      "Epoch 26/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0370 - mae: 0.1441 - val_loss: 0.0364 - val_mae: 0.1461\n",
      "Epoch 27/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0377 - mae: 0.1477 - val_loss: 0.0358 - val_mae: 0.1431\n",
      "Epoch 28/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0369 - mae: 0.1449 - val_loss: 0.0357 - val_mae: 0.1418\n",
      "Epoch 29/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0380 - mae: 0.1471 - val_loss: 0.0358 - val_mae: 0.1431\n",
      "Epoch 30/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0394 - mae: 0.1509 - val_loss: 0.0354 - val_mae: 0.1406\n",
      "Epoch 31/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0396 - mae: 0.1507 - val_loss: 0.0356 - val_mae: 0.1415\n",
      "Epoch 32/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0367 - mae: 0.1426 - val_loss: 0.0355 - val_mae: 0.1410\n",
      "Epoch 33/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0369 - mae: 0.1430 - val_loss: 0.0350 - val_mae: 0.1399\n",
      "Epoch 34/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0375 - mae: 0.1460 - val_loss: 0.0352 - val_mae: 0.1413\n",
      "Epoch 35/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0365 - mae: 0.1431 - val_loss: 0.0353 - val_mae: 0.1419\n",
      "Epoch 36/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0373 - mae: 0.1459 - val_loss: 0.0351 - val_mae: 0.1402\n",
      "Epoch 37/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0360 - mae: 0.1416 - val_loss: 0.0349 - val_mae: 0.1384\n",
      "Epoch 38/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0355 - mae: 0.1403 - val_loss: 0.0346 - val_mae: 0.1398\n",
      "Epoch 39/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0363 - mae: 0.1437 - val_loss: 0.0346 - val_mae: 0.1382\n",
      "Epoch 40/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0359 - mae: 0.1415 - val_loss: 0.0345 - val_mae: 0.1391\n",
      "Epoch 41/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0361 - mae: 0.1410 - val_loss: 0.0345 - val_mae: 0.1382\n",
      "Epoch 42/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0350 - mae: 0.1397 - val_loss: 0.0351 - val_mae: 0.1405\n",
      "Epoch 43/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0366 - mae: 0.1430 - val_loss: 0.0344 - val_mae: 0.1394\n",
      "Epoch 44/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0358 - mae: 0.1422 - val_loss: 0.0346 - val_mae: 0.1393\n",
      "Epoch 45/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0351 - mae: 0.1418 - val_loss: 0.0343 - val_mae: 0.1420\n",
      "Epoch 46/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0359 - mae: 0.1428 - val_loss: 0.0342 - val_mae: 0.1381\n",
      "Epoch 47/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0352 - mae: 0.1400 - val_loss: 0.0346 - val_mae: 0.1408\n",
      "Epoch 48/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0353 - mae: 0.1412 - val_loss: 0.0353 - val_mae: 0.1430\n",
      "Epoch 49/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0360 - mae: 0.1440 - val_loss: 0.0341 - val_mae: 0.1390\n",
      "Epoch 50/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0339 - mae: 0.1382 - val_loss: 0.0343 - val_mae: 0.1416\n",
      "Epoch 51/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0349 - mae: 0.1400 - val_loss: 0.0340 - val_mae: 0.1387\n",
      "Epoch 52/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0345 - mae: 0.1386 - val_loss: 0.0340 - val_mae: 0.1405\n",
      "Epoch 53/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0348 - mae: 0.1419 - val_loss: 0.0338 - val_mae: 0.1403\n",
      "Epoch 54/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0347 - mae: 0.1405 - val_loss: 0.0339 - val_mae: 0.1414\n",
      "Epoch 55/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0360 - mae: 0.1442 - val_loss: 0.0338 - val_mae: 0.1399\n",
      "Epoch 56/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0345 - mae: 0.1406 - val_loss: 0.0338 - val_mae: 0.1396\n",
      "Epoch 57/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0337 - mae: 0.1377 - val_loss: 0.0341 - val_mae: 0.1389\n",
      "Epoch 58/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0338 - mae: 0.1375 - val_loss: 0.0333 - val_mae: 0.1355\n",
      "Epoch 59/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0339 - mae: 0.1377 - val_loss: 0.0335 - val_mae: 0.1370\n",
      "Epoch 60/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0349 - mae: 0.1404 - val_loss: 0.0335 - val_mae: 0.1388\n",
      "Epoch 61/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0348 - mae: 0.1429 - val_loss: 0.0332 - val_mae: 0.1382\n",
      "Epoch 62/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0349 - mae: 0.1406 - val_loss: 0.0343 - val_mae: 0.1405\n",
      "Epoch 63/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0342 - mae: 0.1404 - val_loss: 0.0336 - val_mae: 0.1406\n",
      "Epoch 64/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0337 - mae: 0.1387 - val_loss: 0.0333 - val_mae: 0.1385\n",
      "Epoch 65/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0351 - mae: 0.1407 - val_loss: 0.0331 - val_mae: 0.1378\n",
      "Epoch 66/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0342 - mae: 0.1394 - val_loss: 0.0336 - val_mae: 0.1365\n",
      "Epoch 67/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0350 - mae: 0.1416 - val_loss: 0.0336 - val_mae: 0.1398\n",
      "Epoch 68/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0343 - mae: 0.1388 - val_loss: 0.0336 - val_mae: 0.1394\n",
      "Epoch 69/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0343 - mae: 0.1394 - val_loss: 0.0345 - val_mae: 0.1414\n",
      "Epoch 70/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0351 - mae: 0.1433 - val_loss: 0.0328 - val_mae: 0.1349\n",
      "Epoch 71/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0350 - mae: 0.1412 - val_loss: 0.0330 - val_mae: 0.1386\n",
      "Epoch 72/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0332 - mae: 0.1374 - val_loss: 0.0331 - val_mae: 0.1376\n",
      "Epoch 73/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0348 - mae: 0.1418 - val_loss: 0.0327 - val_mae: 0.1359\n",
      "Epoch 74/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0328 - mae: 0.1360 - val_loss: 0.0342 - val_mae: 0.1434\n",
      "Epoch 75/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0333 - mae: 0.1384 - val_loss: 0.0330 - val_mae: 0.1386\n",
      "Epoch 76/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0332 - mae: 0.1371 - val_loss: 0.0328 - val_mae: 0.1365\n",
      "Epoch 77/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0345 - mae: 0.1407 - val_loss: 0.0326 - val_mae: 0.1353\n",
      "Epoch 78/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0335 - mae: 0.1385 - val_loss: 0.0335 - val_mae: 0.1393\n",
      "Epoch 79/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0346 - mae: 0.1416 - val_loss: 0.0325 - val_mae: 0.1357\n",
      "Epoch 80/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0341 - mae: 0.1393 - val_loss: 0.0329 - val_mae: 0.1370\n",
      "Epoch 81/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0328 - mae: 0.1373 - val_loss: 0.0324 - val_mae: 0.1365\n",
      "Epoch 82/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0342 - mae: 0.1411 - val_loss: 0.0331 - val_mae: 0.1389\n",
      "Epoch 83/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0331 - mae: 0.1366 - val_loss: 0.0333 - val_mae: 0.1391\n",
      "Epoch 84/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0331 - mae: 0.1379 - val_loss: 0.0328 - val_mae: 0.1376\n",
      "Epoch 85/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0341 - mae: 0.1397 - val_loss: 0.0331 - val_mae: 0.1352\n",
      "Epoch 86/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0358 - mae: 0.1443 - val_loss: 0.0326 - val_mae: 0.1383\n",
      "Epoch 87/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0330 - mae: 0.1375 - val_loss: 0.0324 - val_mae: 0.1362\n",
      "Epoch 88/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0340 - mae: 0.1394 - val_loss: 0.0321 - val_mae: 0.1354\n",
      "Epoch 89/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0343 - mae: 0.1414 - val_loss: 0.0321 - val_mae: 0.1353\n",
      "Epoch 90/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0350 - mae: 0.1409 - val_loss: 0.0324 - val_mae: 0.1370\n",
      "Epoch 91/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0335 - mae: 0.1386 - val_loss: 0.0326 - val_mae: 0.1387\n",
      "Epoch 92/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0334 - mae: 0.1384 - val_loss: 0.0321 - val_mae: 0.1342\n",
      "Epoch 93/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0328 - mae: 0.1373 - val_loss: 0.0331 - val_mae: 0.1409\n",
      "Epoch 94/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0339 - mae: 0.1395 - val_loss: 0.0323 - val_mae: 0.1355\n",
      "Epoch 95/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0344 - mae: 0.1417 - val_loss: 0.0323 - val_mae: 0.1368\n",
      "Epoch 96/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0328 - mae: 0.1362 - val_loss: 0.0326 - val_mae: 0.1378\n",
      "Epoch 97/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0338 - mae: 0.1396 - val_loss: 0.0323 - val_mae: 0.1380\n",
      "Epoch 98/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0327 - mae: 0.1368 - val_loss: 0.0322 - val_mae: 0.1361\n",
      "Epoch 99/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0344 - mae: 0.1412 - val_loss: 0.0323 - val_mae: 0.1366\n",
      "Epoch 100/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0337 - mae: 0.1401 - val_loss: 0.0319 - val_mae: 0.1348\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0318 - mae: 0.1363 \n",
      "---------------------------------------------------------\n",
      "K 1 FOLD\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elped\\AppData\\Local\\Temp\\ipykernel_13956\\4226922763.py:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[features] = scaler.fit_transform(x[features])\n",
      "c:\\Users\\elped\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.4082 - mae: 0.2081 - val_loss: 0.2559 - val_mae: 0.1858\n",
      "Epoch 2/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2223 - mae: 0.1797 - val_loss: 0.1460 - val_mae: 0.1795\n",
      "Epoch 3/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1297 - mae: 0.1760 - val_loss: 0.0893 - val_mae: 0.1704\n",
      "Epoch 4/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0808 - mae: 0.1650 - val_loss: 0.0616 - val_mae: 0.1603\n",
      "Epoch 5/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0578 - mae: 0.1576 - val_loss: 0.0495 - val_mae: 0.1565\n",
      "Epoch 6/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0484 - mae: 0.1544 - val_loss: 0.0442 - val_mae: 0.1540\n",
      "Epoch 7/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0435 - mae: 0.1507 - val_loss: 0.0417 - val_mae: 0.1526\n",
      "Epoch 8/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0427 - mae: 0.1517 - val_loss: 0.0404 - val_mae: 0.1515\n",
      "Epoch 9/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0410 - mae: 0.1507 - val_loss: 0.0400 - val_mae: 0.1505\n",
      "Epoch 10/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0418 - mae: 0.1514 - val_loss: 0.0391 - val_mae: 0.1501\n",
      "Epoch 11/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0414 - mae: 0.1530 - val_loss: 0.0387 - val_mae: 0.1503\n",
      "Epoch 12/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0412 - mae: 0.1523 - val_loss: 0.0381 - val_mae: 0.1476\n",
      "Epoch 13/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0401 - mae: 0.1490 - val_loss: 0.0382 - val_mae: 0.1490\n",
      "Epoch 14/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0398 - mae: 0.1488 - val_loss: 0.0382 - val_mae: 0.1482\n",
      "Epoch 15/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0393 - mae: 0.1471 - val_loss: 0.0376 - val_mae: 0.1471\n",
      "Epoch 16/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0394 - mae: 0.1488 - val_loss: 0.0375 - val_mae: 0.1477\n",
      "Epoch 17/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0392 - mae: 0.1487 - val_loss: 0.0375 - val_mae: 0.1474\n",
      "Epoch 18/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0397 - mae: 0.1505 - val_loss: 0.0368 - val_mae: 0.1441\n",
      "Epoch 19/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0389 - mae: 0.1479 - val_loss: 0.0363 - val_mae: 0.1436\n",
      "Epoch 20/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0379 - mae: 0.1450 - val_loss: 0.0365 - val_mae: 0.1439\n",
      "Epoch 21/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0385 - mae: 0.1475 - val_loss: 0.0363 - val_mae: 0.1456\n",
      "Epoch 22/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0382 - mae: 0.1459 - val_loss: 0.0373 - val_mae: 0.1470\n",
      "Epoch 23/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0386 - mae: 0.1479 - val_loss: 0.0363 - val_mae: 0.1457\n",
      "Epoch 24/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0386 - mae: 0.1470 - val_loss: 0.0361 - val_mae: 0.1443\n",
      "Epoch 25/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0381 - mae: 0.1475 - val_loss: 0.0357 - val_mae: 0.1437\n",
      "Epoch 26/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0379 - mae: 0.1454 - val_loss: 0.0357 - val_mae: 0.1449\n",
      "Epoch 27/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0378 - mae: 0.1456 - val_loss: 0.0355 - val_mae: 0.1432\n",
      "Epoch 28/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0385 - mae: 0.1470 - val_loss: 0.0364 - val_mae: 0.1447\n",
      "Epoch 29/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0382 - mae: 0.1475 - val_loss: 0.0361 - val_mae: 0.1438\n",
      "Epoch 30/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0377 - mae: 0.1435 - val_loss: 0.0354 - val_mae: 0.1436\n",
      "Epoch 31/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0368 - mae: 0.1419 - val_loss: 0.0356 - val_mae: 0.1444\n",
      "Epoch 32/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0360 - mae: 0.1422 - val_loss: 0.0349 - val_mae: 0.1428\n",
      "Epoch 33/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0363 - mae: 0.1440 - val_loss: 0.0353 - val_mae: 0.1423\n",
      "Epoch 34/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0373 - mae: 0.1437 - val_loss: 0.0349 - val_mae: 0.1438\n",
      "Epoch 35/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0361 - mae: 0.1426 - val_loss: 0.0357 - val_mae: 0.1446\n",
      "Epoch 36/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0359 - mae: 0.1434 - val_loss: 0.0351 - val_mae: 0.1446\n",
      "Epoch 37/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0369 - mae: 0.1455 - val_loss: 0.0347 - val_mae: 0.1419\n",
      "Epoch 38/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0364 - mae: 0.1443 - val_loss: 0.0369 - val_mae: 0.1446\n",
      "Epoch 39/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0365 - mae: 0.1430 - val_loss: 0.0343 - val_mae: 0.1402\n",
      "Epoch 40/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0359 - mae: 0.1426 - val_loss: 0.0349 - val_mae: 0.1424\n",
      "Epoch 41/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0359 - mae: 0.1409 - val_loss: 0.0346 - val_mae: 0.1423\n",
      "Epoch 42/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0363 - mae: 0.1443 - val_loss: 0.0341 - val_mae: 0.1407\n",
      "Epoch 43/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0356 - mae: 0.1413 - val_loss: 0.0350 - val_mae: 0.1402\n",
      "Epoch 44/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0357 - mae: 0.1406 - val_loss: 0.0339 - val_mae: 0.1408\n",
      "Epoch 45/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0373 - mae: 0.1476 - val_loss: 0.0338 - val_mae: 0.1403\n",
      "Epoch 46/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0366 - mae: 0.1436 - val_loss: 0.0340 - val_mae: 0.1414\n",
      "Epoch 47/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0354 - mae: 0.1426 - val_loss: 0.0337 - val_mae: 0.1414\n",
      "Epoch 48/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0352 - mae: 0.1423 - val_loss: 0.0343 - val_mae: 0.1424\n",
      "Epoch 49/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0352 - mae: 0.1413 - val_loss: 0.0340 - val_mae: 0.1394\n",
      "Epoch 50/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0348 - mae: 0.1412 - val_loss: 0.0352 - val_mae: 0.1466\n",
      "Epoch 51/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0360 - mae: 0.1438 - val_loss: 0.0343 - val_mae: 0.1427\n",
      "Epoch 52/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0351 - mae: 0.1421 - val_loss: 0.0342 - val_mae: 0.1407\n",
      "Epoch 53/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0356 - mae: 0.1422 - val_loss: 0.0342 - val_mae: 0.1412\n",
      "Epoch 54/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0370 - mae: 0.1464 - val_loss: 0.0336 - val_mae: 0.1390\n",
      "Epoch 55/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0357 - mae: 0.1426 - val_loss: 0.0332 - val_mae: 0.1394\n",
      "Epoch 56/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0361 - mae: 0.1441 - val_loss: 0.0339 - val_mae: 0.1398\n",
      "Epoch 57/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0357 - mae: 0.1436 - val_loss: 0.0332 - val_mae: 0.1406\n",
      "Epoch 58/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0358 - mae: 0.1438 - val_loss: 0.0334 - val_mae: 0.1403\n",
      "Epoch 59/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0352 - mae: 0.1417 - val_loss: 0.0330 - val_mae: 0.1392\n",
      "Epoch 60/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0356 - mae: 0.1417 - val_loss: 0.0336 - val_mae: 0.1390\n",
      "Epoch 61/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0353 - mae: 0.1408 - val_loss: 0.0338 - val_mae: 0.1413\n",
      "Epoch 62/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0357 - mae: 0.1424 - val_loss: 0.0332 - val_mae: 0.1411\n",
      "Epoch 63/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0358 - mae: 0.1453 - val_loss: 0.0332 - val_mae: 0.1399\n",
      "Epoch 64/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0356 - mae: 0.1430 - val_loss: 0.0330 - val_mae: 0.1411\n",
      "Epoch 65/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0359 - mae: 0.1436 - val_loss: 0.0335 - val_mae: 0.1422\n",
      "Epoch 66/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0360 - mae: 0.1448 - val_loss: 0.0327 - val_mae: 0.1382\n",
      "Epoch 67/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0339 - mae: 0.1372 - val_loss: 0.0330 - val_mae: 0.1414\n",
      "Epoch 68/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0354 - mae: 0.1422 - val_loss: 0.0335 - val_mae: 0.1399\n",
      "Epoch 69/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0344 - mae: 0.1413 - val_loss: 0.0334 - val_mae: 0.1397\n",
      "Epoch 70/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0342 - mae: 0.1396 - val_loss: 0.0329 - val_mae: 0.1399\n",
      "Epoch 71/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0332 - mae: 0.1372 - val_loss: 0.0330 - val_mae: 0.1392\n",
      "Epoch 72/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0335 - mae: 0.1388 - val_loss: 0.0328 - val_mae: 0.1400\n",
      "Epoch 73/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0327 - mae: 0.1363 - val_loss: 0.0324 - val_mae: 0.1380\n",
      "Epoch 74/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0336 - mae: 0.1383 - val_loss: 0.0321 - val_mae: 0.1376\n",
      "Epoch 75/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0348 - mae: 0.1419 - val_loss: 0.0325 - val_mae: 0.1391\n",
      "Epoch 76/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0355 - mae: 0.1425 - val_loss: 0.0323 - val_mae: 0.1377\n",
      "Epoch 77/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0342 - mae: 0.1405 - val_loss: 0.0324 - val_mae: 0.1389\n",
      "Epoch 78/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0340 - mae: 0.1387 - val_loss: 0.0331 - val_mae: 0.1411\n",
      "Epoch 79/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0345 - mae: 0.1404 - val_loss: 0.0324 - val_mae: 0.1386\n",
      "Epoch 80/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0336 - mae: 0.1385 - val_loss: 0.0326 - val_mae: 0.1400\n",
      "Epoch 81/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0324 - mae: 0.1346 - val_loss: 0.0329 - val_mae: 0.1379\n",
      "Epoch 82/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0334 - mae: 0.1388 - val_loss: 0.0327 - val_mae: 0.1393\n",
      "Epoch 83/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0345 - mae: 0.1394 - val_loss: 0.0336 - val_mae: 0.1422\n",
      "Epoch 84/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0348 - mae: 0.1421 - val_loss: 0.0319 - val_mae: 0.1363\n",
      "Epoch 85/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0338 - mae: 0.1388 - val_loss: 0.0319 - val_mae: 0.1370\n",
      "Epoch 86/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0340 - mae: 0.1396 - val_loss: 0.0324 - val_mae: 0.1397\n",
      "Epoch 87/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0347 - mae: 0.1415 - val_loss: 0.0327 - val_mae: 0.1395\n",
      "Epoch 88/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0337 - mae: 0.1392 - val_loss: 0.0321 - val_mae: 0.1379\n",
      "Epoch 89/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0320 - mae: 0.1334 - val_loss: 0.0332 - val_mae: 0.1421\n",
      "Epoch 90/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0341 - mae: 0.1411 - val_loss: 0.0318 - val_mae: 0.1372\n",
      "Epoch 91/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0334 - mae: 0.1381 - val_loss: 0.0317 - val_mae: 0.1370\n",
      "Epoch 92/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0330 - mae: 0.1365 - val_loss: 0.0316 - val_mae: 0.1366\n",
      "Epoch 93/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0341 - mae: 0.1400 - val_loss: 0.0324 - val_mae: 0.1373\n",
      "Epoch 94/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0334 - mae: 0.1383 - val_loss: 0.0316 - val_mae: 0.1356\n",
      "Epoch 95/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0346 - mae: 0.1402 - val_loss: 0.0320 - val_mae: 0.1386\n",
      "Epoch 96/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0329 - mae: 0.1381 - val_loss: 0.0318 - val_mae: 0.1372\n",
      "Epoch 97/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0330 - mae: 0.1379 - val_loss: 0.0321 - val_mae: 0.1397\n",
      "Epoch 98/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0336 - mae: 0.1401 - val_loss: 0.0322 - val_mae: 0.1395\n",
      "Epoch 99/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0324 - mae: 0.1372 - val_loss: 0.0319 - val_mae: 0.1382\n",
      "Epoch 100/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0332 - mae: 0.1386 - val_loss: 0.0319 - val_mae: 0.1357\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0296 - mae: 0.1308 \n",
      "---------------------------------------------------------\n",
      "K 2 FOLD\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elped\\AppData\\Local\\Temp\\ipykernel_13956\\4226922763.py:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[features] = scaler.fit_transform(x[features])\n",
      "c:\\Users\\elped\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.4060 - mae: 0.2197 - val_loss: 0.2526 - val_mae: 0.1670\n",
      "Epoch 2/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2301 - mae: 0.1791 - val_loss: 0.1508 - val_mae: 0.1609\n",
      "Epoch 3/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1392 - mae: 0.1697 - val_loss: 0.0954 - val_mae: 0.1575\n",
      "Epoch 4/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0894 - mae: 0.1613 - val_loss: 0.0666 - val_mae: 0.1524\n",
      "Epoch 5/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0657 - mae: 0.1605 - val_loss: 0.0519 - val_mae: 0.1477\n",
      "Epoch 6/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0517 - mae: 0.1522 - val_loss: 0.0444 - val_mae: 0.1441\n",
      "Epoch 7/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0456 - mae: 0.1517 - val_loss: 0.0407 - val_mae: 0.1427\n",
      "Epoch 8/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0415 - mae: 0.1470 - val_loss: 0.0391 - val_mae: 0.1421\n",
      "Epoch 9/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0415 - mae: 0.1505 - val_loss: 0.0381 - val_mae: 0.1416\n",
      "Epoch 10/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0400 - mae: 0.1481 - val_loss: 0.0377 - val_mae: 0.1418\n",
      "Epoch 11/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0389 - mae: 0.1461 - val_loss: 0.0374 - val_mae: 0.1408\n",
      "Epoch 12/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0390 - mae: 0.1467 - val_loss: 0.0368 - val_mae: 0.1398\n",
      "Epoch 13/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0385 - mae: 0.1465 - val_loss: 0.0367 - val_mae: 0.1408\n",
      "Epoch 14/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0391 - mae: 0.1503 - val_loss: 0.0363 - val_mae: 0.1382\n",
      "Epoch 15/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0382 - mae: 0.1460 - val_loss: 0.0365 - val_mae: 0.1393\n",
      "Epoch 16/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0390 - mae: 0.1487 - val_loss: 0.0363 - val_mae: 0.1386\n",
      "Epoch 17/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0379 - mae: 0.1465 - val_loss: 0.0360 - val_mae: 0.1373\n",
      "Epoch 18/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0370 - mae: 0.1435 - val_loss: 0.0358 - val_mae: 0.1370\n",
      "Epoch 19/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0370 - mae: 0.1434 - val_loss: 0.0358 - val_mae: 0.1383\n",
      "Epoch 20/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0377 - mae: 0.1460 - val_loss: 0.0360 - val_mae: 0.1370\n",
      "Epoch 21/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0365 - mae: 0.1445 - val_loss: 0.0353 - val_mae: 0.1368\n",
      "Epoch 22/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0374 - mae: 0.1462 - val_loss: 0.0356 - val_mae: 0.1387\n",
      "Epoch 23/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0378 - mae: 0.1482 - val_loss: 0.0353 - val_mae: 0.1365\n",
      "Epoch 24/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0379 - mae: 0.1471 - val_loss: 0.0353 - val_mae: 0.1380\n",
      "Epoch 25/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0371 - mae: 0.1448 - val_loss: 0.0357 - val_mae: 0.1381\n",
      "Epoch 26/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0377 - mae: 0.1471 - val_loss: 0.0351 - val_mae: 0.1367\n",
      "Epoch 27/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0361 - mae: 0.1416 - val_loss: 0.0350 - val_mae: 0.1367\n",
      "Epoch 28/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0361 - mae: 0.1432 - val_loss: 0.0349 - val_mae: 0.1383\n",
      "Epoch 29/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0374 - mae: 0.1471 - val_loss: 0.0347 - val_mae: 0.1360\n",
      "Epoch 30/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0362 - mae: 0.1423 - val_loss: 0.0352 - val_mae: 0.1374\n",
      "Epoch 31/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0363 - mae: 0.1439 - val_loss: 0.0349 - val_mae: 0.1369\n",
      "Epoch 32/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0350 - mae: 0.1405 - val_loss: 0.0349 - val_mae: 0.1383\n",
      "Epoch 33/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0356 - mae: 0.1428 - val_loss: 0.0351 - val_mae: 0.1369\n",
      "Epoch 34/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0368 - mae: 0.1462 - val_loss: 0.0347 - val_mae: 0.1371\n",
      "Epoch 35/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0357 - mae: 0.1432 - val_loss: 0.0344 - val_mae: 0.1358\n",
      "Epoch 36/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0351 - mae: 0.1415 - val_loss: 0.0353 - val_mae: 0.1399\n",
      "Epoch 37/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0366 - mae: 0.1456 - val_loss: 0.0353 - val_mae: 0.1361\n",
      "Epoch 38/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0365 - mae: 0.1447 - val_loss: 0.0343 - val_mae: 0.1368\n",
      "Epoch 39/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0358 - mae: 0.1434 - val_loss: 0.0343 - val_mae: 0.1357\n",
      "Epoch 40/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0347 - mae: 0.1415 - val_loss: 0.0341 - val_mae: 0.1371\n",
      "Epoch 41/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0358 - mae: 0.1432 - val_loss: 0.0349 - val_mae: 0.1370\n",
      "Epoch 42/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0356 - mae: 0.1429 - val_loss: 0.0339 - val_mae: 0.1360\n",
      "Epoch 43/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0350 - mae: 0.1424 - val_loss: 0.0337 - val_mae: 0.1359\n",
      "Epoch 44/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0352 - mae: 0.1421 - val_loss: 0.0339 - val_mae: 0.1364\n",
      "Epoch 45/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0349 - mae: 0.1421 - val_loss: 0.0341 - val_mae: 0.1359\n",
      "Epoch 46/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0349 - mae: 0.1392 - val_loss: 0.0335 - val_mae: 0.1349\n",
      "Epoch 47/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0341 - mae: 0.1393 - val_loss: 0.0338 - val_mae: 0.1358\n",
      "Epoch 48/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0344 - mae: 0.1405 - val_loss: 0.0332 - val_mae: 0.1343\n",
      "Epoch 49/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0349 - mae: 0.1434 - val_loss: 0.0336 - val_mae: 0.1340\n",
      "Epoch 50/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0344 - mae: 0.1400 - val_loss: 0.0337 - val_mae: 0.1334\n",
      "Epoch 51/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0354 - mae: 0.1415 - val_loss: 0.0333 - val_mae: 0.1358\n",
      "Epoch 52/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0342 - mae: 0.1407 - val_loss: 0.0344 - val_mae: 0.1376\n",
      "Epoch 53/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0350 - mae: 0.1420 - val_loss: 0.0338 - val_mae: 0.1364\n",
      "Epoch 54/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0347 - mae: 0.1417 - val_loss: 0.0330 - val_mae: 0.1344\n",
      "Epoch 55/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0350 - mae: 0.1430 - val_loss: 0.0336 - val_mae: 0.1348\n",
      "Epoch 56/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0355 - mae: 0.1415 - val_loss: 0.0336 - val_mae: 0.1347\n",
      "Epoch 57/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0342 - mae: 0.1408 - val_loss: 0.0337 - val_mae: 0.1377\n",
      "Epoch 58/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0336 - mae: 0.1394 - val_loss: 0.0331 - val_mae: 0.1345\n",
      "Epoch 59/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0355 - mae: 0.1441 - val_loss: 0.0330 - val_mae: 0.1343\n",
      "Epoch 60/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0342 - mae: 0.1390 - val_loss: 0.0330 - val_mae: 0.1347\n",
      "Epoch 61/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0336 - mae: 0.1387 - val_loss: 0.0332 - val_mae: 0.1337\n",
      "Epoch 62/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0336 - mae: 0.1396 - val_loss: 0.0330 - val_mae: 0.1339\n",
      "Epoch 63/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0349 - mae: 0.1421 - val_loss: 0.0330 - val_mae: 0.1369\n",
      "Epoch 64/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0334 - mae: 0.1394 - val_loss: 0.0329 - val_mae: 0.1358\n",
      "Epoch 65/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0328 - mae: 0.1370 - val_loss: 0.0329 - val_mae: 0.1341\n",
      "Epoch 66/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0343 - mae: 0.1418 - val_loss: 0.0335 - val_mae: 0.1342\n",
      "Epoch 67/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0343 - mae: 0.1405 - val_loss: 0.0337 - val_mae: 0.1341\n",
      "Epoch 68/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0349 - mae: 0.1426 - val_loss: 0.0327 - val_mae: 0.1333\n",
      "Epoch 69/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0347 - mae: 0.1427 - val_loss: 0.0323 - val_mae: 0.1329\n",
      "Epoch 70/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0348 - mae: 0.1427 - val_loss: 0.0331 - val_mae: 0.1361\n",
      "Epoch 71/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0328 - mae: 0.1372 - val_loss: 0.0328 - val_mae: 0.1328\n",
      "Epoch 72/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0330 - mae: 0.1375 - val_loss: 0.0326 - val_mae: 0.1333\n",
      "Epoch 73/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0334 - mae: 0.1392 - val_loss: 0.0324 - val_mae: 0.1329\n",
      "Epoch 74/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0341 - mae: 0.1408 - val_loss: 0.0327 - val_mae: 0.1333\n",
      "Epoch 75/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0352 - mae: 0.1416 - val_loss: 0.0330 - val_mae: 0.1340\n",
      "Epoch 76/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0343 - mae: 0.1402 - val_loss: 0.0324 - val_mae: 0.1329\n",
      "Epoch 77/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0332 - mae: 0.1381 - val_loss: 0.0324 - val_mae: 0.1336\n",
      "Epoch 78/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0342 - mae: 0.1405 - val_loss: 0.0332 - val_mae: 0.1347\n",
      "Epoch 79/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0346 - mae: 0.1422 - val_loss: 0.0327 - val_mae: 0.1341\n",
      "Epoch 80/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0326 - mae: 0.1378 - val_loss: 0.0323 - val_mae: 0.1329\n",
      "Epoch 81/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0332 - mae: 0.1394 - val_loss: 0.0322 - val_mae: 0.1334\n",
      "Epoch 82/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0317 - mae: 0.1355 - val_loss: 0.0322 - val_mae: 0.1349\n",
      "Epoch 83/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0333 - mae: 0.1400 - val_loss: 0.0324 - val_mae: 0.1346\n",
      "Epoch 84/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0325 - mae: 0.1375 - val_loss: 0.0325 - val_mae: 0.1331\n",
      "Epoch 85/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0350 - mae: 0.1431 - val_loss: 0.0323 - val_mae: 0.1339\n",
      "Epoch 86/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0339 - mae: 0.1414 - val_loss: 0.0322 - val_mae: 0.1321\n",
      "Epoch 87/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0337 - mae: 0.1412 - val_loss: 0.0325 - val_mae: 0.1335\n",
      "Epoch 88/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0329 - mae: 0.1397 - val_loss: 0.0324 - val_mae: 0.1339\n",
      "Epoch 89/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0323 - mae: 0.1382 - val_loss: 0.0325 - val_mae: 0.1333\n",
      "Epoch 90/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0332 - mae: 0.1383 - val_loss: 0.0332 - val_mae: 0.1381\n",
      "Epoch 91/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0330 - mae: 0.1394 - val_loss: 0.0320 - val_mae: 0.1330\n",
      "Epoch 92/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0341 - mae: 0.1418 - val_loss: 0.0325 - val_mae: 0.1341\n",
      "Epoch 93/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0332 - mae: 0.1394 - val_loss: 0.0322 - val_mae: 0.1327\n",
      "Epoch 94/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0323 - mae: 0.1383 - val_loss: 0.0330 - val_mae: 0.1338\n",
      "Epoch 95/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0332 - mae: 0.1381 - val_loss: 0.0324 - val_mae: 0.1333\n",
      "Epoch 96/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0333 - mae: 0.1391 - val_loss: 0.0320 - val_mae: 0.1330\n",
      "Epoch 97/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0332 - mae: 0.1409 - val_loss: 0.0322 - val_mae: 0.1338\n",
      "Epoch 98/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0328 - mae: 0.1374 - val_loss: 0.0318 - val_mae: 0.1335\n",
      "Epoch 99/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0329 - mae: 0.1395 - val_loss: 0.0323 - val_mae: 0.1316\n",
      "Epoch 100/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0334 - mae: 0.1392 - val_loss: 0.0324 - val_mae: 0.1358\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0321 - mae: 0.1355 \n",
      "---------------------------------------------------------\n",
      "K 3 FOLD\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elped\\AppData\\Local\\Temp\\ipykernel_13956\\4226922763.py:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[features] = scaler.fit_transform(x[features])\n",
      "c:\\Users\\elped\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.3939 - mae: 0.2047 - val_loss: 0.2471 - val_mae: 0.1725\n",
      "Epoch 2/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2212 - mae: 0.1822 - val_loss: 0.1419 - val_mae: 0.1645\n",
      "Epoch 3/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1274 - mae: 0.1685 - val_loss: 0.0862 - val_mae: 0.1552\n",
      "Epoch 4/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0808 - mae: 0.1617 - val_loss: 0.0592 - val_mae: 0.1490\n",
      "Epoch 5/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0578 - mae: 0.1547 - val_loss: 0.0472 - val_mae: 0.1468\n",
      "Epoch 6/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0478 - mae: 0.1518 - val_loss: 0.0417 - val_mae: 0.1461\n",
      "Epoch 7/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0435 - mae: 0.1526 - val_loss: 0.0390 - val_mae: 0.1441\n",
      "Epoch 8/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0407 - mae: 0.1483 - val_loss: 0.0381 - val_mae: 0.1435\n",
      "Epoch 9/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0400 - mae: 0.1486 - val_loss: 0.0373 - val_mae: 0.1420\n",
      "Epoch 10/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0412 - mae: 0.1519 - val_loss: 0.0367 - val_mae: 0.1411\n",
      "Epoch 11/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0407 - mae: 0.1502 - val_loss: 0.0365 - val_mae: 0.1411\n",
      "Epoch 12/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0391 - mae: 0.1485 - val_loss: 0.0363 - val_mae: 0.1420\n",
      "Epoch 13/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0392 - mae: 0.1472 - val_loss: 0.0356 - val_mae: 0.1394\n",
      "Epoch 14/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0384 - mae: 0.1468 - val_loss: 0.0360 - val_mae: 0.1415\n",
      "Epoch 15/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0387 - mae: 0.1475 - val_loss: 0.0351 - val_mae: 0.1399\n",
      "Epoch 16/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0386 - mae: 0.1465 - val_loss: 0.0347 - val_mae: 0.1371\n",
      "Epoch 17/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0382 - mae: 0.1463 - val_loss: 0.0351 - val_mae: 0.1399\n",
      "Epoch 18/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0377 - mae: 0.1467 - val_loss: 0.0348 - val_mae: 0.1381\n",
      "Epoch 19/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0371 - mae: 0.1453 - val_loss: 0.0350 - val_mae: 0.1381\n",
      "Epoch 20/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0384 - mae: 0.1476 - val_loss: 0.0342 - val_mae: 0.1383\n",
      "Epoch 21/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0384 - mae: 0.1481 - val_loss: 0.0339 - val_mae: 0.1362\n",
      "Epoch 22/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0375 - mae: 0.1449 - val_loss: 0.0343 - val_mae: 0.1376\n",
      "Epoch 23/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0368 - mae: 0.1443 - val_loss: 0.0341 - val_mae: 0.1368\n",
      "Epoch 24/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0383 - mae: 0.1475 - val_loss: 0.0340 - val_mae: 0.1362\n",
      "Epoch 25/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0364 - mae: 0.1407 - val_loss: 0.0343 - val_mae: 0.1364\n",
      "Epoch 26/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0365 - mae: 0.1441 - val_loss: 0.0338 - val_mae: 0.1369\n",
      "Epoch 27/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0369 - mae: 0.1458 - val_loss: 0.0337 - val_mae: 0.1367\n",
      "Epoch 28/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0351 - mae: 0.1398 - val_loss: 0.0334 - val_mae: 0.1362\n",
      "Epoch 29/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0368 - mae: 0.1455 - val_loss: 0.0336 - val_mae: 0.1371\n",
      "Epoch 30/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0365 - mae: 0.1432 - val_loss: 0.0332 - val_mae: 0.1354\n",
      "Epoch 31/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0375 - mae: 0.1462 - val_loss: 0.0333 - val_mae: 0.1349\n",
      "Epoch 32/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0366 - mae: 0.1418 - val_loss: 0.0337 - val_mae: 0.1360\n",
      "Epoch 33/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0364 - mae: 0.1444 - val_loss: 0.0330 - val_mae: 0.1362\n",
      "Epoch 34/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0371 - mae: 0.1457 - val_loss: 0.0332 - val_mae: 0.1362\n",
      "Epoch 35/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0363 - mae: 0.1436 - val_loss: 0.0339 - val_mae: 0.1377\n",
      "Epoch 36/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0373 - mae: 0.1463 - val_loss: 0.0331 - val_mae: 0.1363\n",
      "Epoch 37/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0372 - mae: 0.1472 - val_loss: 0.0333 - val_mae: 0.1373\n",
      "Epoch 38/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0356 - mae: 0.1433 - val_loss: 0.0326 - val_mae: 0.1348\n",
      "Epoch 39/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0364 - mae: 0.1438 - val_loss: 0.0332 - val_mae: 0.1378\n",
      "Epoch 40/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0363 - mae: 0.1451 - val_loss: 0.0328 - val_mae: 0.1358\n",
      "Epoch 41/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0345 - mae: 0.1406 - val_loss: 0.0334 - val_mae: 0.1344\n",
      "Epoch 42/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0357 - mae: 0.1429 - val_loss: 0.0326 - val_mae: 0.1342\n",
      "Epoch 43/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0354 - mae: 0.1428 - val_loss: 0.0324 - val_mae: 0.1351\n",
      "Epoch 44/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0369 - mae: 0.1443 - val_loss: 0.0323 - val_mae: 0.1339\n",
      "Epoch 45/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0353 - mae: 0.1426 - val_loss: 0.0329 - val_mae: 0.1371\n",
      "Epoch 46/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0359 - mae: 0.1441 - val_loss: 0.0322 - val_mae: 0.1343\n",
      "Epoch 47/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0353 - mae: 0.1417 - val_loss: 0.0319 - val_mae: 0.1342\n",
      "Epoch 48/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0357 - mae: 0.1442 - val_loss: 0.0323 - val_mae: 0.1351\n",
      "Epoch 49/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0357 - mae: 0.1451 - val_loss: 0.0324 - val_mae: 0.1351\n",
      "Epoch 50/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0358 - mae: 0.1430 - val_loss: 0.0321 - val_mae: 0.1342\n",
      "Epoch 51/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0341 - mae: 0.1381 - val_loss: 0.0319 - val_mae: 0.1327\n",
      "Epoch 52/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0350 - mae: 0.1421 - val_loss: 0.0321 - val_mae: 0.1349\n",
      "Epoch 53/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0356 - mae: 0.1435 - val_loss: 0.0330 - val_mae: 0.1349\n",
      "Epoch 54/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0355 - mae: 0.1425 - val_loss: 0.0322 - val_mae: 0.1356\n",
      "Epoch 55/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0361 - mae: 0.1452 - val_loss: 0.0325 - val_mae: 0.1350\n",
      "Epoch 56/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0351 - mae: 0.1427 - val_loss: 0.0322 - val_mae: 0.1349\n",
      "Epoch 57/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0351 - mae: 0.1430 - val_loss: 0.0319 - val_mae: 0.1343\n",
      "Epoch 58/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0347 - mae: 0.1415 - val_loss: 0.0323 - val_mae: 0.1365\n",
      "Epoch 59/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0346 - mae: 0.1402 - val_loss: 0.0319 - val_mae: 0.1339\n",
      "Epoch 60/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0351 - mae: 0.1425 - val_loss: 0.0316 - val_mae: 0.1345\n",
      "Epoch 61/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0350 - mae: 0.1431 - val_loss: 0.0318 - val_mae: 0.1344\n",
      "Epoch 62/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0335 - mae: 0.1373 - val_loss: 0.0322 - val_mae: 0.1362\n",
      "Epoch 63/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0332 - mae: 0.1380 - val_loss: 0.0319 - val_mae: 0.1340\n",
      "Epoch 64/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0335 - mae: 0.1375 - val_loss: 0.0314 - val_mae: 0.1315\n",
      "Epoch 65/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0337 - mae: 0.1400 - val_loss: 0.0312 - val_mae: 0.1324\n",
      "Epoch 66/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0336 - mae: 0.1394 - val_loss: 0.0318 - val_mae: 0.1349\n",
      "Epoch 67/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0334 - mae: 0.1391 - val_loss: 0.0313 - val_mae: 0.1333\n",
      "Epoch 68/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0334 - mae: 0.1401 - val_loss: 0.0314 - val_mae: 0.1331\n",
      "Epoch 69/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0341 - mae: 0.1399 - val_loss: 0.0315 - val_mae: 0.1322\n",
      "Epoch 70/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0352 - mae: 0.1426 - val_loss: 0.0318 - val_mae: 0.1334\n",
      "Epoch 71/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0361 - mae: 0.1444 - val_loss: 0.0311 - val_mae: 0.1325\n",
      "Epoch 72/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0352 - mae: 0.1431 - val_loss: 0.0312 - val_mae: 0.1333\n",
      "Epoch 73/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0355 - mae: 0.1425 - val_loss: 0.0315 - val_mae: 0.1343\n",
      "Epoch 74/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0349 - mae: 0.1437 - val_loss: 0.0313 - val_mae: 0.1344\n",
      "Epoch 75/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0344 - mae: 0.1419 - val_loss: 0.0315 - val_mae: 0.1329\n",
      "Epoch 76/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0335 - mae: 0.1388 - val_loss: 0.0309 - val_mae: 0.1306\n",
      "Epoch 77/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0334 - mae: 0.1382 - val_loss: 0.0308 - val_mae: 0.1317\n",
      "Epoch 78/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0343 - mae: 0.1397 - val_loss: 0.0309 - val_mae: 0.1320\n",
      "Epoch 79/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0340 - mae: 0.1398 - val_loss: 0.0307 - val_mae: 0.1323\n",
      "Epoch 80/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0351 - mae: 0.1429 - val_loss: 0.0307 - val_mae: 0.1313\n",
      "Epoch 81/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0336 - mae: 0.1394 - val_loss: 0.0311 - val_mae: 0.1331\n",
      "Epoch 82/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0335 - mae: 0.1401 - val_loss: 0.0310 - val_mae: 0.1328\n",
      "Epoch 83/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0330 - mae: 0.1385 - val_loss: 0.0312 - val_mae: 0.1334\n",
      "Epoch 84/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0336 - mae: 0.1399 - val_loss: 0.0307 - val_mae: 0.1317\n",
      "Epoch 85/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0339 - mae: 0.1420 - val_loss: 0.0303 - val_mae: 0.1304\n",
      "Epoch 86/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0333 - mae: 0.1360 - val_loss: 0.0312 - val_mae: 0.1339\n",
      "Epoch 87/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0344 - mae: 0.1419 - val_loss: 0.0307 - val_mae: 0.1330\n",
      "Epoch 88/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0344 - mae: 0.1423 - val_loss: 0.0308 - val_mae: 0.1334\n",
      "Epoch 89/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0332 - mae: 0.1401 - val_loss: 0.0305 - val_mae: 0.1308\n",
      "Epoch 90/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0333 - mae: 0.1393 - val_loss: 0.0304 - val_mae: 0.1316\n",
      "Epoch 91/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0325 - mae: 0.1373 - val_loss: 0.0307 - val_mae: 0.1312\n",
      "Epoch 92/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0336 - mae: 0.1396 - val_loss: 0.0305 - val_mae: 0.1308\n",
      "Epoch 93/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0345 - mae: 0.1407 - val_loss: 0.0309 - val_mae: 0.1322\n",
      "Epoch 94/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0326 - mae: 0.1367 - val_loss: 0.0311 - val_mae: 0.1328\n",
      "Epoch 95/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0346 - mae: 0.1426 - val_loss: 0.0305 - val_mae: 0.1308\n",
      "Epoch 96/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0334 - mae: 0.1384 - val_loss: 0.0305 - val_mae: 0.1316\n",
      "Epoch 97/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0334 - mae: 0.1393 - val_loss: 0.0305 - val_mae: 0.1317\n",
      "Epoch 98/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0324 - mae: 0.1373 - val_loss: 0.0302 - val_mae: 0.1297\n",
      "Epoch 99/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0332 - mae: 0.1385 - val_loss: 0.0310 - val_mae: 0.1342\n",
      "Epoch 100/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0331 - mae: 0.1397 - val_loss: 0.0302 - val_mae: 0.1305\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - loss: 0.0293 - mae: 0.1274\n",
      "---------------------------------------------------------\n",
      "K 4 FOLD\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elped\\AppData\\Local\\Temp\\ipykernel_13956\\4226922763.py:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[features] = scaler.fit_transform(x[features])\n",
      "c:\\Users\\elped\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.4304 - mae: 0.1993 - val_loss: 0.2679 - val_mae: 0.1765\n",
      "Epoch 2/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2359 - mae: 0.1793 - val_loss: 0.1520 - val_mae: 0.1726\n",
      "Epoch 3/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1365 - mae: 0.1748 - val_loss: 0.0926 - val_mae: 0.1683\n",
      "Epoch 4/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0857 - mae: 0.1685 - val_loss: 0.0635 - val_mae: 0.1616\n",
      "Epoch 5/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0608 - mae: 0.1613 - val_loss: 0.0503 - val_mae: 0.1568\n",
      "Epoch 6/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0497 - mae: 0.1566 - val_loss: 0.0441 - val_mae: 0.1537\n",
      "Epoch 7/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0445 - mae: 0.1532 - val_loss: 0.0416 - val_mae: 0.1521\n",
      "Epoch 8/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0420 - mae: 0.1498 - val_loss: 0.0404 - val_mae: 0.1511\n",
      "Epoch 9/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0421 - mae: 0.1517 - val_loss: 0.0393 - val_mae: 0.1510\n",
      "Epoch 10/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0409 - mae: 0.1505 - val_loss: 0.0392 - val_mae: 0.1504\n",
      "Epoch 11/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0406 - mae: 0.1500 - val_loss: 0.0385 - val_mae: 0.1477\n",
      "Epoch 12/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0405 - mae: 0.1488 - val_loss: 0.0383 - val_mae: 0.1488\n",
      "Epoch 13/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0394 - mae: 0.1467 - val_loss: 0.0376 - val_mae: 0.1462\n",
      "Epoch 14/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0401 - mae: 0.1481 - val_loss: 0.0374 - val_mae: 0.1454\n",
      "Epoch 15/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0383 - mae: 0.1451 - val_loss: 0.0373 - val_mae: 0.1452\n",
      "Epoch 16/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0392 - mae: 0.1482 - val_loss: 0.0370 - val_mae: 0.1462\n",
      "Epoch 17/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0374 - mae: 0.1441 - val_loss: 0.0367 - val_mae: 0.1453\n",
      "Epoch 18/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0394 - mae: 0.1498 - val_loss: 0.0365 - val_mae: 0.1444\n",
      "Epoch 19/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0390 - mae: 0.1486 - val_loss: 0.0362 - val_mae: 0.1439\n",
      "Epoch 20/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0393 - mae: 0.1476 - val_loss: 0.0363 - val_mae: 0.1431\n",
      "Epoch 21/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0383 - mae: 0.1451 - val_loss: 0.0368 - val_mae: 0.1469\n",
      "Epoch 22/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0383 - mae: 0.1479 - val_loss: 0.0362 - val_mae: 0.1442\n",
      "Epoch 23/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0383 - mae: 0.1474 - val_loss: 0.0364 - val_mae: 0.1466\n",
      "Epoch 24/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0378 - mae: 0.1461 - val_loss: 0.0359 - val_mae: 0.1415\n",
      "Epoch 25/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0374 - mae: 0.1431 - val_loss: 0.0358 - val_mae: 0.1421\n",
      "Epoch 26/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0379 - mae: 0.1455 - val_loss: 0.0356 - val_mae: 0.1433\n",
      "Epoch 27/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0382 - mae: 0.1469 - val_loss: 0.0354 - val_mae: 0.1426\n",
      "Epoch 28/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0374 - mae: 0.1452 - val_loss: 0.0359 - val_mae: 0.1454\n",
      "Epoch 29/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0366 - mae: 0.1431 - val_loss: 0.0353 - val_mae: 0.1418\n",
      "Epoch 30/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0367 - mae: 0.1437 - val_loss: 0.0360 - val_mae: 0.1441\n",
      "Epoch 31/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0367 - mae: 0.1429 - val_loss: 0.0353 - val_mae: 0.1428\n",
      "Epoch 32/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0360 - mae: 0.1420 - val_loss: 0.0352 - val_mae: 0.1432\n",
      "Epoch 33/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0357 - mae: 0.1423 - val_loss: 0.0350 - val_mae: 0.1430\n",
      "Epoch 34/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0358 - mae: 0.1431 - val_loss: 0.0347 - val_mae: 0.1405\n",
      "Epoch 35/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0365 - mae: 0.1435 - val_loss: 0.0351 - val_mae: 0.1420\n",
      "Epoch 36/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0358 - mae: 0.1412 - val_loss: 0.0343 - val_mae: 0.1401\n",
      "Epoch 37/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0360 - mae: 0.1426 - val_loss: 0.0347 - val_mae: 0.1405\n",
      "Epoch 38/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0364 - mae: 0.1443 - val_loss: 0.0343 - val_mae: 0.1406\n",
      "Epoch 39/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0358 - mae: 0.1422 - val_loss: 0.0345 - val_mae: 0.1411\n",
      "Epoch 40/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0333 - mae: 0.1360 - val_loss: 0.0339 - val_mae: 0.1391\n",
      "Epoch 41/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0366 - mae: 0.1436 - val_loss: 0.0342 - val_mae: 0.1414\n",
      "Epoch 42/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0351 - mae: 0.1404 - val_loss: 0.0343 - val_mae: 0.1403\n",
      "Epoch 43/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0351 - mae: 0.1411 - val_loss: 0.0341 - val_mae: 0.1400\n",
      "Epoch 44/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0364 - mae: 0.1428 - val_loss: 0.0342 - val_mae: 0.1396\n",
      "Epoch 45/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0362 - mae: 0.1425 - val_loss: 0.0338 - val_mae: 0.1401\n",
      "Epoch 46/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0357 - mae: 0.1413 - val_loss: 0.0338 - val_mae: 0.1385\n",
      "Epoch 47/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0343 - mae: 0.1391 - val_loss: 0.0338 - val_mae: 0.1404\n",
      "Epoch 48/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0359 - mae: 0.1417 - val_loss: 0.0338 - val_mae: 0.1396\n",
      "Epoch 49/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0358 - mae: 0.1422 - val_loss: 0.0339 - val_mae: 0.1410\n",
      "Epoch 50/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0350 - mae: 0.1408 - val_loss: 0.0338 - val_mae: 0.1405\n",
      "Epoch 51/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0343 - mae: 0.1395 - val_loss: 0.0336 - val_mae: 0.1399\n",
      "Epoch 52/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0361 - mae: 0.1423 - val_loss: 0.0337 - val_mae: 0.1394\n",
      "Epoch 53/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0363 - mae: 0.1438 - val_loss: 0.0337 - val_mae: 0.1385\n",
      "Epoch 54/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0349 - mae: 0.1390 - val_loss: 0.0334 - val_mae: 0.1383\n",
      "Epoch 55/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0371 - mae: 0.1472 - val_loss: 0.0339 - val_mae: 0.1399\n",
      "Epoch 56/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0352 - mae: 0.1418 - val_loss: 0.0334 - val_mae: 0.1393\n",
      "Epoch 57/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0340 - mae: 0.1383 - val_loss: 0.0334 - val_mae: 0.1391\n",
      "Epoch 58/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0353 - mae: 0.1411 - val_loss: 0.0335 - val_mae: 0.1391\n",
      "Epoch 59/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0358 - mae: 0.1398 - val_loss: 0.0336 - val_mae: 0.1400\n",
      "Epoch 60/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0346 - mae: 0.1398 - val_loss: 0.0328 - val_mae: 0.1382\n",
      "Epoch 61/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0363 - mae: 0.1448 - val_loss: 0.0333 - val_mae: 0.1398\n",
      "Epoch 62/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0355 - mae: 0.1425 - val_loss: 0.0335 - val_mae: 0.1393\n",
      "Epoch 63/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0326 - mae: 0.1354 - val_loss: 0.0330 - val_mae: 0.1394\n",
      "Epoch 64/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0348 - mae: 0.1421 - val_loss: 0.0332 - val_mae: 0.1397\n",
      "Epoch 65/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0333 - mae: 0.1369 - val_loss: 0.0330 - val_mae: 0.1386\n",
      "Epoch 66/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0346 - mae: 0.1391 - val_loss: 0.0330 - val_mae: 0.1385\n",
      "Epoch 67/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0334 - mae: 0.1384 - val_loss: 0.0325 - val_mae: 0.1393\n",
      "Epoch 68/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0350 - mae: 0.1416 - val_loss: 0.0325 - val_mae: 0.1374\n",
      "Epoch 69/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0335 - mae: 0.1372 - val_loss: 0.0332 - val_mae: 0.1391\n",
      "Epoch 70/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0353 - mae: 0.1424 - val_loss: 0.0333 - val_mae: 0.1398\n",
      "Epoch 71/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0338 - mae: 0.1378 - val_loss: 0.0322 - val_mae: 0.1369\n",
      "Epoch 72/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0332 - mae: 0.1381 - val_loss: 0.0326 - val_mae: 0.1395\n",
      "Epoch 73/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0353 - mae: 0.1434 - val_loss: 0.0330 - val_mae: 0.1381\n",
      "Epoch 74/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0350 - mae: 0.1417 - val_loss: 0.0324 - val_mae: 0.1385\n",
      "Epoch 75/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0342 - mae: 0.1424 - val_loss: 0.0330 - val_mae: 0.1374\n",
      "Epoch 76/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0344 - mae: 0.1403 - val_loss: 0.0328 - val_mae: 0.1387\n",
      "Epoch 77/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0336 - mae: 0.1372 - val_loss: 0.0329 - val_mae: 0.1406\n",
      "Epoch 78/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0349 - mae: 0.1416 - val_loss: 0.0328 - val_mae: 0.1375\n",
      "Epoch 79/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0346 - mae: 0.1401 - val_loss: 0.0326 - val_mae: 0.1378\n",
      "Epoch 80/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0327 - mae: 0.1366 - val_loss: 0.0331 - val_mae: 0.1395\n",
      "Epoch 81/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0340 - mae: 0.1404 - val_loss: 0.0322 - val_mae: 0.1375\n",
      "Epoch 82/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0346 - mae: 0.1412 - val_loss: 0.0324 - val_mae: 0.1375\n",
      "Epoch 83/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0333 - mae: 0.1371 - val_loss: 0.0325 - val_mae: 0.1384\n",
      "Epoch 84/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0338 - mae: 0.1397 - val_loss: 0.0326 - val_mae: 0.1384\n",
      "Epoch 85/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0349 - mae: 0.1423 - val_loss: 0.0331 - val_mae: 0.1384\n",
      "Epoch 86/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0334 - mae: 0.1390 - val_loss: 0.0321 - val_mae: 0.1356\n",
      "Epoch 87/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0342 - mae: 0.1400 - val_loss: 0.0328 - val_mae: 0.1381\n",
      "Epoch 88/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0350 - mae: 0.1420 - val_loss: 0.0321 - val_mae: 0.1358\n",
      "Epoch 89/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0332 - mae: 0.1375 - val_loss: 0.0329 - val_mae: 0.1378\n",
      "Epoch 90/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0342 - mae: 0.1400 - val_loss: 0.0321 - val_mae: 0.1373\n",
      "Epoch 91/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0337 - mae: 0.1390 - val_loss: 0.0322 - val_mae: 0.1389\n",
      "Epoch 92/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0324 - mae: 0.1367 - val_loss: 0.0323 - val_mae: 0.1371\n",
      "Epoch 93/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0335 - mae: 0.1409 - val_loss: 0.0326 - val_mae: 0.1380\n",
      "Epoch 94/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0339 - mae: 0.1392 - val_loss: 0.0318 - val_mae: 0.1375\n",
      "Epoch 95/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0341 - mae: 0.1402 - val_loss: 0.0318 - val_mae: 0.1367\n",
      "Epoch 96/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0336 - mae: 0.1392 - val_loss: 0.0323 - val_mae: 0.1381\n",
      "Epoch 97/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0333 - mae: 0.1391 - val_loss: 0.0318 - val_mae: 0.1369\n",
      "Epoch 98/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0324 - mae: 0.1349 - val_loss: 0.0325 - val_mae: 0.1368\n",
      "Epoch 99/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0325 - mae: 0.1357 - val_loss: 0.0320 - val_mae: 0.1361\n",
      "Epoch 100/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0359 - mae: 0.1430 - val_loss: 0.0320 - val_mae: 0.1378\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0335 - mae: 0.1407 \n",
      "---------------------------------------------------------\n",
      "USER 4\n",
      "---------------------------------------------------------\n",
      "K 0 FOLD\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elped\\AppData\\Local\\Temp\\ipykernel_13956\\4226922763.py:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[features] = scaler.fit_transform(x[features])\n",
      "c:\\Users\\elped\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.4179 - mae: 0.2175 - val_loss: 0.3026 - val_mae: 0.1999\n",
      "Epoch 2/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2776 - mae: 0.1947 - val_loss: 0.2026 - val_mae: 0.1877\n",
      "Epoch 3/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1837 - mae: 0.1764 - val_loss: 0.1395 - val_mae: 0.1822\n",
      "Epoch 4/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1261 - mae: 0.1719 - val_loss: 0.0996 - val_mae: 0.1756\n",
      "Epoch 5/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0942 - mae: 0.1726 - val_loss: 0.0750 - val_mae: 0.1707\n",
      "Epoch 6/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0705 - mae: 0.1648 - val_loss: 0.0599 - val_mae: 0.1647\n",
      "Epoch 7/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0609 - mae: 0.1682 - val_loss: 0.0511 - val_mae: 0.1615\n",
      "Epoch 8/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0500 - mae: 0.1573 - val_loss: 0.0460 - val_mae: 0.1572\n",
      "Epoch 9/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0449 - mae: 0.1527 - val_loss: 0.0429 - val_mae: 0.1547\n",
      "Epoch 10/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0470 - mae: 0.1599 - val_loss: 0.0412 - val_mae: 0.1518\n",
      "Epoch 11/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0421 - mae: 0.1514 - val_loss: 0.0400 - val_mae: 0.1515\n",
      "Epoch 12/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0406 - mae: 0.1504 - val_loss: 0.0396 - val_mae: 0.1522\n",
      "Epoch 13/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0400 - mae: 0.1487 - val_loss: 0.0391 - val_mae: 0.1518\n",
      "Epoch 14/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0412 - mae: 0.1536 - val_loss: 0.0388 - val_mae: 0.1505\n",
      "Epoch 15/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0399 - mae: 0.1500 - val_loss: 0.0389 - val_mae: 0.1519\n",
      "Epoch 16/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0410 - mae: 0.1540 - val_loss: 0.0384 - val_mae: 0.1502\n",
      "Epoch 17/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0400 - mae: 0.1516 - val_loss: 0.0378 - val_mae: 0.1481\n",
      "Epoch 18/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0382 - mae: 0.1467 - val_loss: 0.0382 - val_mae: 0.1509\n",
      "Epoch 19/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0407 - mae: 0.1529 - val_loss: 0.0383 - val_mae: 0.1512\n",
      "Epoch 20/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0407 - mae: 0.1544 - val_loss: 0.0375 - val_mae: 0.1476\n",
      "Epoch 21/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0386 - mae: 0.1474 - val_loss: 0.0373 - val_mae: 0.1486\n",
      "Epoch 22/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0391 - mae: 0.1500 - val_loss: 0.0376 - val_mae: 0.1502\n",
      "Epoch 23/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0381 - mae: 0.1469 - val_loss: 0.0373 - val_mae: 0.1474\n",
      "Epoch 24/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0376 - mae: 0.1458 - val_loss: 0.0370 - val_mae: 0.1457\n",
      "Epoch 25/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0388 - mae: 0.1493 - val_loss: 0.0372 - val_mae: 0.1491\n",
      "Epoch 26/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0381 - mae: 0.1486 - val_loss: 0.0368 - val_mae: 0.1476\n",
      "Epoch 27/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0394 - mae: 0.1527 - val_loss: 0.0366 - val_mae: 0.1466\n",
      "Epoch 28/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0392 - mae: 0.1507 - val_loss: 0.0365 - val_mae: 0.1456\n",
      "Epoch 29/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0392 - mae: 0.1493 - val_loss: 0.0368 - val_mae: 0.1482\n",
      "Epoch 30/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0356 - mae: 0.1409 - val_loss: 0.0362 - val_mae: 0.1464\n",
      "Epoch 31/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0391 - mae: 0.1511 - val_loss: 0.0359 - val_mae: 0.1441\n",
      "Epoch 32/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0372 - mae: 0.1474 - val_loss: 0.0365 - val_mae: 0.1463\n",
      "Epoch 33/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0374 - mae: 0.1460 - val_loss: 0.0357 - val_mae: 0.1456\n",
      "Epoch 34/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0396 - mae: 0.1532 - val_loss: 0.0358 - val_mae: 0.1455\n",
      "Epoch 35/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0356 - mae: 0.1432 - val_loss: 0.0358 - val_mae: 0.1456\n",
      "Epoch 36/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0381 - mae: 0.1496 - val_loss: 0.0357 - val_mae: 0.1447\n",
      "Epoch 37/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0367 - mae: 0.1447 - val_loss: 0.0354 - val_mae: 0.1442\n",
      "Epoch 38/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0362 - mae: 0.1428 - val_loss: 0.0353 - val_mae: 0.1444\n",
      "Epoch 39/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0371 - mae: 0.1470 - val_loss: 0.0354 - val_mae: 0.1452\n",
      "Epoch 40/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0365 - mae: 0.1437 - val_loss: 0.0361 - val_mae: 0.1473\n",
      "Epoch 41/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0372 - mae: 0.1475 - val_loss: 0.0364 - val_mae: 0.1477\n",
      "Epoch 42/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0381 - mae: 0.1487 - val_loss: 0.0354 - val_mae: 0.1450\n",
      "Epoch 43/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0371 - mae: 0.1463 - val_loss: 0.0355 - val_mae: 0.1436\n",
      "Epoch 44/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0369 - mae: 0.1456 - val_loss: 0.0353 - val_mae: 0.1436\n",
      "Epoch 45/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0363 - mae: 0.1437 - val_loss: 0.0353 - val_mae: 0.1441\n",
      "Epoch 46/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0378 - mae: 0.1471 - val_loss: 0.0355 - val_mae: 0.1446\n",
      "Epoch 47/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0379 - mae: 0.1476 - val_loss: 0.0355 - val_mae: 0.1448\n",
      "Epoch 48/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0370 - mae: 0.1451 - val_loss: 0.0349 - val_mae: 0.1438\n",
      "Epoch 49/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0358 - mae: 0.1427 - val_loss: 0.0355 - val_mae: 0.1469\n",
      "Epoch 50/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0365 - mae: 0.1450 - val_loss: 0.0350 - val_mae: 0.1428\n",
      "Epoch 51/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0364 - mae: 0.1444 - val_loss: 0.0348 - val_mae: 0.1432\n",
      "Epoch 52/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0356 - mae: 0.1439 - val_loss: 0.0346 - val_mae: 0.1414\n",
      "Epoch 53/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0371 - mae: 0.1464 - val_loss: 0.0352 - val_mae: 0.1438\n",
      "Epoch 54/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0358 - mae: 0.1427 - val_loss: 0.0347 - val_mae: 0.1437\n",
      "Epoch 55/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0358 - mae: 0.1426 - val_loss: 0.0347 - val_mae: 0.1440\n",
      "Epoch 56/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0368 - mae: 0.1462 - val_loss: 0.0345 - val_mae: 0.1425\n",
      "Epoch 57/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0366 - mae: 0.1462 - val_loss: 0.0346 - val_mae: 0.1436\n",
      "Epoch 58/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0371 - mae: 0.1472 - val_loss: 0.0348 - val_mae: 0.1438\n",
      "Epoch 59/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0339 - mae: 0.1399 - val_loss: 0.0352 - val_mae: 0.1458\n",
      "Epoch 60/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0356 - mae: 0.1444 - val_loss: 0.0347 - val_mae: 0.1443\n",
      "Epoch 61/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0351 - mae: 0.1419 - val_loss: 0.0344 - val_mae: 0.1431\n",
      "Epoch 62/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0363 - mae: 0.1465 - val_loss: 0.0345 - val_mae: 0.1421\n",
      "Epoch 63/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0356 - mae: 0.1422 - val_loss: 0.0343 - val_mae: 0.1436\n",
      "Epoch 64/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0371 - mae: 0.1486 - val_loss: 0.0349 - val_mae: 0.1443\n",
      "Epoch 65/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0365 - mae: 0.1448 - val_loss: 0.0343 - val_mae: 0.1417\n",
      "Epoch 66/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0367 - mae: 0.1464 - val_loss: 0.0340 - val_mae: 0.1404\n",
      "Epoch 67/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0359 - mae: 0.1434 - val_loss: 0.0340 - val_mae: 0.1413\n",
      "Epoch 68/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0369 - mae: 0.1470 - val_loss: 0.0342 - val_mae: 0.1427\n",
      "Epoch 69/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0361 - mae: 0.1457 - val_loss: 0.0339 - val_mae: 0.1409\n",
      "Epoch 70/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0352 - mae: 0.1424 - val_loss: 0.0349 - val_mae: 0.1451\n",
      "Epoch 71/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0348 - mae: 0.1436 - val_loss: 0.0345 - val_mae: 0.1448\n",
      "Epoch 72/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0352 - mae: 0.1452 - val_loss: 0.0341 - val_mae: 0.1431\n",
      "Epoch 73/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0365 - mae: 0.1471 - val_loss: 0.0347 - val_mae: 0.1440\n",
      "Epoch 74/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0366 - mae: 0.1453 - val_loss: 0.0344 - val_mae: 0.1444\n",
      "Epoch 75/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0367 - mae: 0.1470 - val_loss: 0.0344 - val_mae: 0.1421\n",
      "Epoch 76/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0351 - mae: 0.1433 - val_loss: 0.0338 - val_mae: 0.1420\n",
      "Epoch 77/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0366 - mae: 0.1471 - val_loss: 0.0336 - val_mae: 0.1422\n",
      "Epoch 78/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0351 - mae: 0.1433 - val_loss: 0.0340 - val_mae: 0.1427\n",
      "Epoch 79/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0352 - mae: 0.1420 - val_loss: 0.0338 - val_mae: 0.1404\n",
      "Epoch 80/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0353 - mae: 0.1436 - val_loss: 0.0341 - val_mae: 0.1432\n",
      "Epoch 81/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0368 - mae: 0.1484 - val_loss: 0.0342 - val_mae: 0.1423\n",
      "Epoch 82/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0355 - mae: 0.1445 - val_loss: 0.0342 - val_mae: 0.1419\n",
      "Epoch 83/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0359 - mae: 0.1458 - val_loss: 0.0340 - val_mae: 0.1418\n",
      "Epoch 84/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0344 - mae: 0.1404 - val_loss: 0.0348 - val_mae: 0.1470\n",
      "Epoch 85/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0368 - mae: 0.1471 - val_loss: 0.0338 - val_mae: 0.1389\n",
      "Epoch 86/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0348 - mae: 0.1424 - val_loss: 0.0332 - val_mae: 0.1400\n",
      "Epoch 87/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0349 - mae: 0.1425 - val_loss: 0.0334 - val_mae: 0.1406\n",
      "Epoch 88/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0350 - mae: 0.1427 - val_loss: 0.0337 - val_mae: 0.1423\n",
      "Epoch 89/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0345 - mae: 0.1409 - val_loss: 0.0341 - val_mae: 0.1408\n",
      "Epoch 90/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0363 - mae: 0.1457 - val_loss: 0.0336 - val_mae: 0.1412\n",
      "Epoch 91/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0344 - mae: 0.1415 - val_loss: 0.0333 - val_mae: 0.1410\n",
      "Epoch 92/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0362 - mae: 0.1473 - val_loss: 0.0333 - val_mae: 0.1422\n",
      "Epoch 93/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0366 - mae: 0.1493 - val_loss: 0.0335 - val_mae: 0.1410\n",
      "Epoch 94/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0345 - mae: 0.1400 - val_loss: 0.0338 - val_mae: 0.1410\n",
      "Epoch 95/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0347 - mae: 0.1412 - val_loss: 0.0338 - val_mae: 0.1434\n",
      "Epoch 96/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0349 - mae: 0.1424 - val_loss: 0.0338 - val_mae: 0.1434\n",
      "Epoch 97/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0350 - mae: 0.1450 - val_loss: 0.0330 - val_mae: 0.1404\n",
      "Epoch 98/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0344 - mae: 0.1419 - val_loss: 0.0346 - val_mae: 0.1441\n",
      "Epoch 99/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0351 - mae: 0.1430 - val_loss: 0.0330 - val_mae: 0.1399\n",
      "Epoch 100/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0337 - mae: 0.1407 - val_loss: 0.0331 - val_mae: 0.1406\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0328 - mae: 0.1396 \n",
      "---------------------------------------------------------\n",
      "K 1 FOLD\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elped\\AppData\\Local\\Temp\\ipykernel_13956\\4226922763.py:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[features] = scaler.fit_transform(x[features])\n",
      "c:\\Users\\elped\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.4209 - mae: 0.2065 - val_loss: 0.3055 - val_mae: 0.1837\n",
      "Epoch 2/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2787 - mae: 0.1854 - val_loss: 0.2061 - val_mae: 0.1790\n",
      "Epoch 3/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1866 - mae: 0.1769 - val_loss: 0.1412 - val_mae: 0.1728\n",
      "Epoch 4/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1313 - mae: 0.1773 - val_loss: 0.1002 - val_mae: 0.1674\n",
      "Epoch 5/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0931 - mae: 0.1697 - val_loss: 0.0759 - val_mae: 0.1641\n",
      "Epoch 6/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0709 - mae: 0.1636 - val_loss: 0.0608 - val_mae: 0.1583\n",
      "Epoch 7/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0594 - mae: 0.1641 - val_loss: 0.0522 - val_mae: 0.1554\n",
      "Epoch 8/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0506 - mae: 0.1596 - val_loss: 0.0467 - val_mae: 0.1522\n",
      "Epoch 9/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0455 - mae: 0.1538 - val_loss: 0.0435 - val_mae: 0.1494\n",
      "Epoch 10/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0450 - mae: 0.1574 - val_loss: 0.0417 - val_mae: 0.1479\n",
      "Epoch 11/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0421 - mae: 0.1519 - val_loss: 0.0406 - val_mae: 0.1477\n",
      "Epoch 12/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0424 - mae: 0.1561 - val_loss: 0.0401 - val_mae: 0.1474\n",
      "Epoch 13/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0401 - mae: 0.1499 - val_loss: 0.0399 - val_mae: 0.1481\n",
      "Epoch 14/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0400 - mae: 0.1514 - val_loss: 0.0392 - val_mae: 0.1459\n",
      "Epoch 15/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0405 - mae: 0.1515 - val_loss: 0.0389 - val_mae: 0.1460\n",
      "Epoch 16/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0386 - mae: 0.1480 - val_loss: 0.0388 - val_mae: 0.1453\n",
      "Epoch 17/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0384 - mae: 0.1466 - val_loss: 0.0385 - val_mae: 0.1445\n",
      "Epoch 18/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0396 - mae: 0.1502 - val_loss: 0.0384 - val_mae: 0.1445\n",
      "Epoch 19/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0392 - mae: 0.1487 - val_loss: 0.0382 - val_mae: 0.1446\n",
      "Epoch 20/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0398 - mae: 0.1500 - val_loss: 0.0383 - val_mae: 0.1452\n",
      "Epoch 21/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0390 - mae: 0.1487 - val_loss: 0.0380 - val_mae: 0.1449\n",
      "Epoch 22/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0379 - mae: 0.1467 - val_loss: 0.0381 - val_mae: 0.1450\n",
      "Epoch 23/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0388 - mae: 0.1500 - val_loss: 0.0379 - val_mae: 0.1450\n",
      "Epoch 24/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0390 - mae: 0.1499 - val_loss: 0.0379 - val_mae: 0.1433\n",
      "Epoch 25/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0378 - mae: 0.1460 - val_loss: 0.0375 - val_mae: 0.1434\n",
      "Epoch 26/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0382 - mae: 0.1485 - val_loss: 0.0376 - val_mae: 0.1446\n",
      "Epoch 27/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0390 - mae: 0.1513 - val_loss: 0.0373 - val_mae: 0.1437\n",
      "Epoch 28/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0388 - mae: 0.1497 - val_loss: 0.0373 - val_mae: 0.1427\n",
      "Epoch 29/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0381 - mae: 0.1455 - val_loss: 0.0376 - val_mae: 0.1451\n",
      "Epoch 30/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0381 - mae: 0.1505 - val_loss: 0.0369 - val_mae: 0.1419\n",
      "Epoch 31/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0377 - mae: 0.1461 - val_loss: 0.0373 - val_mae: 0.1438\n",
      "Epoch 32/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0365 - mae: 0.1437 - val_loss: 0.0376 - val_mae: 0.1445\n",
      "Epoch 33/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0380 - mae: 0.1483 - val_loss: 0.0369 - val_mae: 0.1440\n",
      "Epoch 34/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0369 - mae: 0.1472 - val_loss: 0.0367 - val_mae: 0.1429\n",
      "Epoch 35/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0391 - mae: 0.1520 - val_loss: 0.0370 - val_mae: 0.1420\n",
      "Epoch 36/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0356 - mae: 0.1436 - val_loss: 0.0365 - val_mae: 0.1426\n",
      "Epoch 37/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0369 - mae: 0.1457 - val_loss: 0.0368 - val_mae: 0.1425\n",
      "Epoch 38/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0376 - mae: 0.1470 - val_loss: 0.0367 - val_mae: 0.1430\n",
      "Epoch 39/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0383 - mae: 0.1490 - val_loss: 0.0364 - val_mae: 0.1419\n",
      "Epoch 40/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0369 - mae: 0.1466 - val_loss: 0.0361 - val_mae: 0.1410\n",
      "Epoch 41/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0374 - mae: 0.1468 - val_loss: 0.0364 - val_mae: 0.1423\n",
      "Epoch 42/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0363 - mae: 0.1455 - val_loss: 0.0363 - val_mae: 0.1422\n",
      "Epoch 43/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0360 - mae: 0.1442 - val_loss: 0.0363 - val_mae: 0.1422\n",
      "Epoch 44/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0371 - mae: 0.1477 - val_loss: 0.0362 - val_mae: 0.1422\n",
      "Epoch 45/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0370 - mae: 0.1468 - val_loss: 0.0357 - val_mae: 0.1406\n",
      "Epoch 46/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0381 - mae: 0.1482 - val_loss: 0.0357 - val_mae: 0.1419\n",
      "Epoch 47/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0359 - mae: 0.1442 - val_loss: 0.0360 - val_mae: 0.1419\n",
      "Epoch 48/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0372 - mae: 0.1483 - val_loss: 0.0358 - val_mae: 0.1408\n",
      "Epoch 49/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0362 - mae: 0.1446 - val_loss: 0.0363 - val_mae: 0.1431\n",
      "Epoch 50/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0373 - mae: 0.1484 - val_loss: 0.0358 - val_mae: 0.1417\n",
      "Epoch 51/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0365 - mae: 0.1470 - val_loss: 0.0358 - val_mae: 0.1409\n",
      "Epoch 52/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0371 - mae: 0.1468 - val_loss: 0.0358 - val_mae: 0.1412\n",
      "Epoch 53/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0378 - mae: 0.1485 - val_loss: 0.0358 - val_mae: 0.1429\n",
      "Epoch 54/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0355 - mae: 0.1446 - val_loss: 0.0357 - val_mae: 0.1404\n",
      "Epoch 55/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0377 - mae: 0.1481 - val_loss: 0.0357 - val_mae: 0.1408\n",
      "Epoch 56/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0356 - mae: 0.1424 - val_loss: 0.0363 - val_mae: 0.1430\n",
      "Epoch 57/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0354 - mae: 0.1423 - val_loss: 0.0354 - val_mae: 0.1404\n",
      "Epoch 58/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0359 - mae: 0.1445 - val_loss: 0.0356 - val_mae: 0.1410\n",
      "Epoch 59/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0369 - mae: 0.1469 - val_loss: 0.0358 - val_mae: 0.1419\n",
      "Epoch 60/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0366 - mae: 0.1480 - val_loss: 0.0354 - val_mae: 0.1397\n",
      "Epoch 61/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0376 - mae: 0.1472 - val_loss: 0.0351 - val_mae: 0.1400\n",
      "Epoch 62/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0357 - mae: 0.1443 - val_loss: 0.0351 - val_mae: 0.1397\n",
      "Epoch 63/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0349 - mae: 0.1422 - val_loss: 0.0362 - val_mae: 0.1443\n",
      "Epoch 64/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0372 - mae: 0.1481 - val_loss: 0.0355 - val_mae: 0.1402\n",
      "Epoch 65/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0361 - mae: 0.1453 - val_loss: 0.0351 - val_mae: 0.1412\n",
      "Epoch 66/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0361 - mae: 0.1470 - val_loss: 0.0353 - val_mae: 0.1403\n",
      "Epoch 67/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0348 - mae: 0.1430 - val_loss: 0.0357 - val_mae: 0.1427\n",
      "Epoch 68/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0355 - mae: 0.1447 - val_loss: 0.0351 - val_mae: 0.1388\n",
      "Epoch 69/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0356 - mae: 0.1444 - val_loss: 0.0350 - val_mae: 0.1395\n",
      "Epoch 70/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0350 - mae: 0.1419 - val_loss: 0.0350 - val_mae: 0.1399\n",
      "Epoch 71/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0364 - mae: 0.1465 - val_loss: 0.0349 - val_mae: 0.1410\n",
      "Epoch 72/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0363 - mae: 0.1468 - val_loss: 0.0347 - val_mae: 0.1385\n",
      "Epoch 73/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0345 - mae: 0.1410 - val_loss: 0.0351 - val_mae: 0.1420\n",
      "Epoch 74/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0338 - mae: 0.1406 - val_loss: 0.0349 - val_mae: 0.1404\n",
      "Epoch 75/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0361 - mae: 0.1454 - val_loss: 0.0346 - val_mae: 0.1394\n",
      "Epoch 76/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0340 - mae: 0.1403 - val_loss: 0.0342 - val_mae: 0.1383\n",
      "Epoch 77/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0363 - mae: 0.1456 - val_loss: 0.0349 - val_mae: 0.1384\n",
      "Epoch 78/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0351 - mae: 0.1437 - val_loss: 0.0345 - val_mae: 0.1397\n",
      "Epoch 79/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0365 - mae: 0.1481 - val_loss: 0.0348 - val_mae: 0.1388\n",
      "Epoch 80/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0340 - mae: 0.1399 - val_loss: 0.0346 - val_mae: 0.1393\n",
      "Epoch 81/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0347 - mae: 0.1428 - val_loss: 0.0346 - val_mae: 0.1391\n",
      "Epoch 82/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0340 - mae: 0.1391 - val_loss: 0.0342 - val_mae: 0.1382\n",
      "Epoch 83/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0358 - mae: 0.1447 - val_loss: 0.0353 - val_mae: 0.1413\n",
      "Epoch 84/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0359 - mae: 0.1457 - val_loss: 0.0348 - val_mae: 0.1397\n",
      "Epoch 85/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0342 - mae: 0.1405 - val_loss: 0.0345 - val_mae: 0.1386\n",
      "Epoch 86/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0343 - mae: 0.1430 - val_loss: 0.0343 - val_mae: 0.1386\n",
      "Epoch 87/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0334 - mae: 0.1393 - val_loss: 0.0344 - val_mae: 0.1395\n",
      "Epoch 88/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0347 - mae: 0.1422 - val_loss: 0.0345 - val_mae: 0.1391\n",
      "Epoch 89/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0354 - mae: 0.1451 - val_loss: 0.0341 - val_mae: 0.1380\n",
      "Epoch 90/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0360 - mae: 0.1479 - val_loss: 0.0347 - val_mae: 0.1393\n",
      "Epoch 91/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0341 - mae: 0.1400 - val_loss: 0.0342 - val_mae: 0.1390\n",
      "Epoch 92/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0328 - mae: 0.1387 - val_loss: 0.0343 - val_mae: 0.1395\n",
      "Epoch 93/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0346 - mae: 0.1420 - val_loss: 0.0342 - val_mae: 0.1386\n",
      "Epoch 94/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0356 - mae: 0.1436 - val_loss: 0.0341 - val_mae: 0.1379\n",
      "Epoch 95/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0362 - mae: 0.1480 - val_loss: 0.0346 - val_mae: 0.1401\n",
      "Epoch 96/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0354 - mae: 0.1433 - val_loss: 0.0341 - val_mae: 0.1370\n",
      "Epoch 97/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0351 - mae: 0.1444 - val_loss: 0.0341 - val_mae: 0.1381\n",
      "Epoch 98/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0341 - mae: 0.1405 - val_loss: 0.0338 - val_mae: 0.1374\n",
      "Epoch 99/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0342 - mae: 0.1416 - val_loss: 0.0340 - val_mae: 0.1374\n",
      "Epoch 100/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0350 - mae: 0.1419 - val_loss: 0.0340 - val_mae: 0.1379\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0351 - mae: 0.1382 \n",
      "---------------------------------------------------------\n",
      "K 2 FOLD\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elped\\AppData\\Local\\Temp\\ipykernel_13956\\4226922763.py:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[features] = scaler.fit_transform(x[features])\n",
      "c:\\Users\\elped\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.4370 - mae: 0.2099 - val_loss: 0.3102 - val_mae: 0.1816\n",
      "Epoch 2/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2864 - mae: 0.1894 - val_loss: 0.2070 - val_mae: 0.1757\n",
      "Epoch 3/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1938 - mae: 0.1843 - val_loss: 0.1406 - val_mae: 0.1705\n",
      "Epoch 4/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1333 - mae: 0.1797 - val_loss: 0.0984 - val_mae: 0.1640\n",
      "Epoch 5/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0959 - mae: 0.1737 - val_loss: 0.0727 - val_mae: 0.1594\n",
      "Epoch 6/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0728 - mae: 0.1675 - val_loss: 0.0577 - val_mae: 0.1552\n",
      "Epoch 7/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0578 - mae: 0.1603 - val_loss: 0.0495 - val_mae: 0.1527\n",
      "Epoch 8/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0517 - mae: 0.1613 - val_loss: 0.0447 - val_mae: 0.1504\n",
      "Epoch 9/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0466 - mae: 0.1570 - val_loss: 0.0419 - val_mae: 0.1484\n",
      "Epoch 10/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0439 - mae: 0.1531 - val_loss: 0.0404 - val_mae: 0.1477\n",
      "Epoch 11/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0449 - mae: 0.1598 - val_loss: 0.0396 - val_mae: 0.1470\n",
      "Epoch 12/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0422 - mae: 0.1556 - val_loss: 0.0390 - val_mae: 0.1464\n",
      "Epoch 13/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0418 - mae: 0.1513 - val_loss: 0.0389 - val_mae: 0.1468\n",
      "Epoch 14/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0420 - mae: 0.1535 - val_loss: 0.0384 - val_mae: 0.1463\n",
      "Epoch 15/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0403 - mae: 0.1511 - val_loss: 0.0384 - val_mae: 0.1480\n",
      "Epoch 16/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0419 - mae: 0.1552 - val_loss: 0.0382 - val_mae: 0.1458\n",
      "Epoch 17/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0401 - mae: 0.1488 - val_loss: 0.0377 - val_mae: 0.1439\n",
      "Epoch 18/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0416 - mae: 0.1547 - val_loss: 0.0374 - val_mae: 0.1441\n",
      "Epoch 19/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0392 - mae: 0.1493 - val_loss: 0.0373 - val_mae: 0.1440\n",
      "Epoch 20/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0384 - mae: 0.1466 - val_loss: 0.0375 - val_mae: 0.1441\n",
      "Epoch 21/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0423 - mae: 0.1560 - val_loss: 0.0369 - val_mae: 0.1433\n",
      "Epoch 22/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0380 - mae: 0.1463 - val_loss: 0.0371 - val_mae: 0.1428\n",
      "Epoch 23/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0378 - mae: 0.1454 - val_loss: 0.0369 - val_mae: 0.1431\n",
      "Epoch 24/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0403 - mae: 0.1505 - val_loss: 0.0370 - val_mae: 0.1430\n",
      "Epoch 25/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0397 - mae: 0.1517 - val_loss: 0.0367 - val_mae: 0.1444\n",
      "Epoch 26/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0378 - mae: 0.1454 - val_loss: 0.0365 - val_mae: 0.1426\n",
      "Epoch 27/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0403 - mae: 0.1516 - val_loss: 0.0366 - val_mae: 0.1441\n",
      "Epoch 28/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0389 - mae: 0.1496 - val_loss: 0.0363 - val_mae: 0.1439\n",
      "Epoch 29/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0385 - mae: 0.1495 - val_loss: 0.0364 - val_mae: 0.1427\n",
      "Epoch 30/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0385 - mae: 0.1491 - val_loss: 0.0364 - val_mae: 0.1431\n",
      "Epoch 31/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0379 - mae: 0.1472 - val_loss: 0.0360 - val_mae: 0.1430\n",
      "Epoch 32/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0383 - mae: 0.1487 - val_loss: 0.0363 - val_mae: 0.1433\n",
      "Epoch 33/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0389 - mae: 0.1496 - val_loss: 0.0365 - val_mae: 0.1433\n",
      "Epoch 34/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0382 - mae: 0.1481 - val_loss: 0.0361 - val_mae: 0.1419\n",
      "Epoch 35/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0391 - mae: 0.1508 - val_loss: 0.0356 - val_mae: 0.1421\n",
      "Epoch 36/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0386 - mae: 0.1485 - val_loss: 0.0367 - val_mae: 0.1430\n",
      "Epoch 37/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0377 - mae: 0.1468 - val_loss: 0.0356 - val_mae: 0.1418\n",
      "Epoch 38/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0368 - mae: 0.1432 - val_loss: 0.0355 - val_mae: 0.1420\n",
      "Epoch 39/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0405 - mae: 0.1515 - val_loss: 0.0355 - val_mae: 0.1427\n",
      "Epoch 40/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0394 - mae: 0.1500 - val_loss: 0.0355 - val_mae: 0.1425\n",
      "Epoch 41/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0376 - mae: 0.1478 - val_loss: 0.0357 - val_mae: 0.1425\n",
      "Epoch 42/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0378 - mae: 0.1470 - val_loss: 0.0351 - val_mae: 0.1424\n",
      "Epoch 43/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0356 - mae: 0.1431 - val_loss: 0.0351 - val_mae: 0.1420\n",
      "Epoch 44/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0359 - mae: 0.1439 - val_loss: 0.0360 - val_mae: 0.1413\n",
      "Epoch 45/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0372 - mae: 0.1444 - val_loss: 0.0353 - val_mae: 0.1426\n",
      "Epoch 46/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0363 - mae: 0.1440 - val_loss: 0.0349 - val_mae: 0.1410\n",
      "Epoch 47/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0365 - mae: 0.1448 - val_loss: 0.0353 - val_mae: 0.1431\n",
      "Epoch 48/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0358 - mae: 0.1431 - val_loss: 0.0351 - val_mae: 0.1402\n",
      "Epoch 49/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0369 - mae: 0.1454 - val_loss: 0.0354 - val_mae: 0.1420\n",
      "Epoch 50/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0360 - mae: 0.1429 - val_loss: 0.0350 - val_mae: 0.1421\n",
      "Epoch 51/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0361 - mae: 0.1438 - val_loss: 0.0360 - val_mae: 0.1423\n",
      "Epoch 52/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0364 - mae: 0.1457 - val_loss: 0.0347 - val_mae: 0.1430\n",
      "Epoch 53/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0381 - mae: 0.1488 - val_loss: 0.0346 - val_mae: 0.1407\n",
      "Epoch 54/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0359 - mae: 0.1433 - val_loss: 0.0350 - val_mae: 0.1409\n",
      "Epoch 55/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0367 - mae: 0.1467 - val_loss: 0.0353 - val_mae: 0.1410\n",
      "Epoch 56/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0378 - mae: 0.1489 - val_loss: 0.0346 - val_mae: 0.1414\n",
      "Epoch 57/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0373 - mae: 0.1475 - val_loss: 0.0345 - val_mae: 0.1409\n",
      "Epoch 58/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0370 - mae: 0.1463 - val_loss: 0.0345 - val_mae: 0.1409\n",
      "Epoch 59/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0365 - mae: 0.1450 - val_loss: 0.0346 - val_mae: 0.1405\n",
      "Epoch 60/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0373 - mae: 0.1457 - val_loss: 0.0349 - val_mae: 0.1400\n",
      "Epoch 61/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0375 - mae: 0.1460 - val_loss: 0.0346 - val_mae: 0.1407\n",
      "Epoch 62/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0362 - mae: 0.1447 - val_loss: 0.0347 - val_mae: 0.1412\n",
      "Epoch 63/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0360 - mae: 0.1441 - val_loss: 0.0344 - val_mae: 0.1397\n",
      "Epoch 64/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0351 - mae: 0.1416 - val_loss: 0.0342 - val_mae: 0.1410\n",
      "Epoch 65/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0371 - mae: 0.1476 - val_loss: 0.0343 - val_mae: 0.1411\n",
      "Epoch 66/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0365 - mae: 0.1462 - val_loss: 0.0349 - val_mae: 0.1412\n",
      "Epoch 67/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0354 - mae: 0.1433 - val_loss: 0.0345 - val_mae: 0.1412\n",
      "Epoch 68/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0370 - mae: 0.1466 - val_loss: 0.0340 - val_mae: 0.1397\n",
      "Epoch 69/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0378 - mae: 0.1480 - val_loss: 0.0352 - val_mae: 0.1416\n",
      "Epoch 70/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0367 - mae: 0.1459 - val_loss: 0.0341 - val_mae: 0.1394\n",
      "Epoch 71/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0349 - mae: 0.1420 - val_loss: 0.0347 - val_mae: 0.1412\n",
      "Epoch 72/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0371 - mae: 0.1474 - val_loss: 0.0339 - val_mae: 0.1415\n",
      "Epoch 73/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0353 - mae: 0.1442 - val_loss: 0.0342 - val_mae: 0.1401\n",
      "Epoch 74/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0337 - mae: 0.1395 - val_loss: 0.0339 - val_mae: 0.1411\n",
      "Epoch 75/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0357 - mae: 0.1428 - val_loss: 0.0341 - val_mae: 0.1403\n",
      "Epoch 76/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0344 - mae: 0.1409 - val_loss: 0.0339 - val_mae: 0.1390\n",
      "Epoch 77/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0389 - mae: 0.1512 - val_loss: 0.0342 - val_mae: 0.1397\n",
      "Epoch 78/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0369 - mae: 0.1463 - val_loss: 0.0341 - val_mae: 0.1412\n",
      "Epoch 79/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0349 - mae: 0.1429 - val_loss: 0.0341 - val_mae: 0.1402\n",
      "Epoch 80/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0353 - mae: 0.1424 - val_loss: 0.0340 - val_mae: 0.1422\n",
      "Epoch 81/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0355 - mae: 0.1434 - val_loss: 0.0341 - val_mae: 0.1408\n",
      "Epoch 82/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0351 - mae: 0.1422 - val_loss: 0.0344 - val_mae: 0.1409\n",
      "Epoch 83/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0357 - mae: 0.1447 - val_loss: 0.0338 - val_mae: 0.1408\n",
      "Epoch 84/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0360 - mae: 0.1435 - val_loss: 0.0342 - val_mae: 0.1403\n",
      "Epoch 85/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0368 - mae: 0.1470 - val_loss: 0.0343 - val_mae: 0.1401\n",
      "Epoch 86/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0350 - mae: 0.1417 - val_loss: 0.0344 - val_mae: 0.1422\n",
      "Epoch 87/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0358 - mae: 0.1446 - val_loss: 0.0345 - val_mae: 0.1408\n",
      "Epoch 88/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0355 - mae: 0.1438 - val_loss: 0.0334 - val_mae: 0.1405\n",
      "Epoch 89/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0352 - mae: 0.1433 - val_loss: 0.0334 - val_mae: 0.1406\n",
      "Epoch 90/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0345 - mae: 0.1409 - val_loss: 0.0339 - val_mae: 0.1395\n",
      "Epoch 91/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0344 - mae: 0.1412 - val_loss: 0.0337 - val_mae: 0.1408\n",
      "Epoch 92/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0360 - mae: 0.1458 - val_loss: 0.0345 - val_mae: 0.1403\n",
      "Epoch 93/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0356 - mae: 0.1443 - val_loss: 0.0338 - val_mae: 0.1398\n",
      "Epoch 94/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0352 - mae: 0.1444 - val_loss: 0.0333 - val_mae: 0.1410\n",
      "Epoch 95/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0364 - mae: 0.1472 - val_loss: 0.0332 - val_mae: 0.1401\n",
      "Epoch 96/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0349 - mae: 0.1440 - val_loss: 0.0331 - val_mae: 0.1392\n",
      "Epoch 97/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0361 - mae: 0.1456 - val_loss: 0.0334 - val_mae: 0.1397\n",
      "Epoch 98/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0348 - mae: 0.1418 - val_loss: 0.0334 - val_mae: 0.1401\n",
      "Epoch 99/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0360 - mae: 0.1443 - val_loss: 0.0334 - val_mae: 0.1398\n",
      "Epoch 100/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0348 - mae: 0.1430 - val_loss: 0.0336 - val_mae: 0.1408\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0339 - mae: 0.1413 \n",
      "---------------------------------------------------------\n",
      "K 3 FOLD\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elped\\AppData\\Local\\Temp\\ipykernel_13956\\4226922763.py:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[features] = scaler.fit_transform(x[features])\n",
      "c:\\Users\\elped\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.4377 - mae: 0.2217 - val_loss: 0.3188 - val_mae: 0.2011\n",
      "Epoch 2/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2914 - mae: 0.2005 - val_loss: 0.2133 - val_mae: 0.1898\n",
      "Epoch 3/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1954 - mae: 0.1896 - val_loss: 0.1450 - val_mae: 0.1815\n",
      "Epoch 4/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1316 - mae: 0.1744 - val_loss: 0.1019 - val_mae: 0.1737\n",
      "Epoch 5/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0945 - mae: 0.1703 - val_loss: 0.0749 - val_mae: 0.1648\n",
      "Epoch 6/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0704 - mae: 0.1624 - val_loss: 0.0593 - val_mae: 0.1591\n",
      "Epoch 7/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0584 - mae: 0.1603 - val_loss: 0.0504 - val_mae: 0.1555\n",
      "Epoch 8/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0519 - mae: 0.1617 - val_loss: 0.0454 - val_mae: 0.1530\n",
      "Epoch 9/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0450 - mae: 0.1515 - val_loss: 0.0426 - val_mae: 0.1520\n",
      "Epoch 10/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0435 - mae: 0.1548 - val_loss: 0.0408 - val_mae: 0.1502\n",
      "Epoch 11/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0426 - mae: 0.1541 - val_loss: 0.0401 - val_mae: 0.1505\n",
      "Epoch 12/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0425 - mae: 0.1554 - val_loss: 0.0389 - val_mae: 0.1484\n",
      "Epoch 13/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0400 - mae: 0.1503 - val_loss: 0.0390 - val_mae: 0.1497\n",
      "Epoch 14/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0392 - mae: 0.1493 - val_loss: 0.0382 - val_mae: 0.1484\n",
      "Epoch 15/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0414 - mae: 0.1550 - val_loss: 0.0385 - val_mae: 0.1475\n",
      "Epoch 16/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0394 - mae: 0.1496 - val_loss: 0.0379 - val_mae: 0.1484\n",
      "Epoch 17/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0374 - mae: 0.1464 - val_loss: 0.0374 - val_mae: 0.1462\n",
      "Epoch 18/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0391 - mae: 0.1485 - val_loss: 0.0374 - val_mae: 0.1470\n",
      "Epoch 19/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0390 - mae: 0.1495 - val_loss: 0.0376 - val_mae: 0.1467\n",
      "Epoch 20/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0374 - mae: 0.1465 - val_loss: 0.0369 - val_mae: 0.1443\n",
      "Epoch 21/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0390 - mae: 0.1480 - val_loss: 0.0367 - val_mae: 0.1449\n",
      "Epoch 22/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0388 - mae: 0.1487 - val_loss: 0.0365 - val_mae: 0.1451\n",
      "Epoch 23/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0380 - mae: 0.1472 - val_loss: 0.0370 - val_mae: 0.1464\n",
      "Epoch 24/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0364 - mae: 0.1413 - val_loss: 0.0366 - val_mae: 0.1456\n",
      "Epoch 25/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0383 - mae: 0.1480 - val_loss: 0.0361 - val_mae: 0.1436\n",
      "Epoch 26/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0377 - mae: 0.1462 - val_loss: 0.0364 - val_mae: 0.1454\n",
      "Epoch 27/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0378 - mae: 0.1479 - val_loss: 0.0363 - val_mae: 0.1447\n",
      "Epoch 28/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0370 - mae: 0.1455 - val_loss: 0.0369 - val_mae: 0.1453\n",
      "Epoch 29/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0381 - mae: 0.1469 - val_loss: 0.0362 - val_mae: 0.1441\n",
      "Epoch 30/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0378 - mae: 0.1467 - val_loss: 0.0359 - val_mae: 0.1448\n",
      "Epoch 31/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0399 - mae: 0.1530 - val_loss: 0.0364 - val_mae: 0.1453\n",
      "Epoch 32/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0358 - mae: 0.1425 - val_loss: 0.0362 - val_mae: 0.1435\n",
      "Epoch 33/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0390 - mae: 0.1495 - val_loss: 0.0358 - val_mae: 0.1439\n",
      "Epoch 34/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0374 - mae: 0.1478 - val_loss: 0.0353 - val_mae: 0.1430\n",
      "Epoch 35/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0369 - mae: 0.1459 - val_loss: 0.0355 - val_mae: 0.1424\n",
      "Epoch 36/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0379 - mae: 0.1487 - val_loss: 0.0354 - val_mae: 0.1438\n",
      "Epoch 37/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0369 - mae: 0.1464 - val_loss: 0.0352 - val_mae: 0.1426\n",
      "Epoch 38/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0363 - mae: 0.1436 - val_loss: 0.0357 - val_mae: 0.1438\n",
      "Epoch 39/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0367 - mae: 0.1457 - val_loss: 0.0351 - val_mae: 0.1430\n",
      "Epoch 40/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0369 - mae: 0.1453 - val_loss: 0.0360 - val_mae: 0.1440\n",
      "Epoch 41/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0371 - mae: 0.1471 - val_loss: 0.0351 - val_mae: 0.1415\n",
      "Epoch 42/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0375 - mae: 0.1481 - val_loss: 0.0352 - val_mae: 0.1433\n",
      "Epoch 43/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0370 - mae: 0.1459 - val_loss: 0.0350 - val_mae: 0.1418\n",
      "Epoch 44/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0369 - mae: 0.1442 - val_loss: 0.0352 - val_mae: 0.1435\n",
      "Epoch 45/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0363 - mae: 0.1442 - val_loss: 0.0351 - val_mae: 0.1419\n",
      "Epoch 46/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0357 - mae: 0.1437 - val_loss: 0.0350 - val_mae: 0.1430\n",
      "Epoch 47/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0371 - mae: 0.1472 - val_loss: 0.0348 - val_mae: 0.1422\n",
      "Epoch 48/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0366 - mae: 0.1468 - val_loss: 0.0349 - val_mae: 0.1431\n",
      "Epoch 49/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0366 - mae: 0.1449 - val_loss: 0.0346 - val_mae: 0.1413\n",
      "Epoch 50/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0370 - mae: 0.1469 - val_loss: 0.0347 - val_mae: 0.1426\n",
      "Epoch 51/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0345 - mae: 0.1418 - val_loss: 0.0352 - val_mae: 0.1440\n",
      "Epoch 52/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0367 - mae: 0.1473 - val_loss: 0.0345 - val_mae: 0.1407\n",
      "Epoch 53/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0359 - mae: 0.1438 - val_loss: 0.0345 - val_mae: 0.1426\n",
      "Epoch 54/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0369 - mae: 0.1470 - val_loss: 0.0341 - val_mae: 0.1405\n",
      "Epoch 55/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0357 - mae: 0.1435 - val_loss: 0.0342 - val_mae: 0.1402\n",
      "Epoch 56/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0365 - mae: 0.1457 - val_loss: 0.0341 - val_mae: 0.1409\n",
      "Epoch 57/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0355 - mae: 0.1434 - val_loss: 0.0342 - val_mae: 0.1407\n",
      "Epoch 58/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0366 - mae: 0.1459 - val_loss: 0.0346 - val_mae: 0.1412\n",
      "Epoch 59/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0355 - mae: 0.1439 - val_loss: 0.0341 - val_mae: 0.1396\n",
      "Epoch 60/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0358 - mae: 0.1441 - val_loss: 0.0344 - val_mae: 0.1422\n",
      "Epoch 61/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0366 - mae: 0.1496 - val_loss: 0.0343 - val_mae: 0.1399\n",
      "Epoch 62/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0367 - mae: 0.1441 - val_loss: 0.0343 - val_mae: 0.1404\n",
      "Epoch 63/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0355 - mae: 0.1436 - val_loss: 0.0342 - val_mae: 0.1423\n",
      "Epoch 64/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0374 - mae: 0.1488 - val_loss: 0.0342 - val_mae: 0.1407\n",
      "Epoch 65/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0342 - mae: 0.1418 - val_loss: 0.0340 - val_mae: 0.1403\n",
      "Epoch 66/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0361 - mae: 0.1463 - val_loss: 0.0347 - val_mae: 0.1420\n",
      "Epoch 67/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0347 - mae: 0.1417 - val_loss: 0.0337 - val_mae: 0.1399\n",
      "Epoch 68/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0354 - mae: 0.1442 - val_loss: 0.0340 - val_mae: 0.1403\n",
      "Epoch 69/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0363 - mae: 0.1462 - val_loss: 0.0334 - val_mae: 0.1385\n",
      "Epoch 70/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0348 - mae: 0.1410 - val_loss: 0.0339 - val_mae: 0.1418\n",
      "Epoch 71/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0369 - mae: 0.1471 - val_loss: 0.0338 - val_mae: 0.1395\n",
      "Epoch 72/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0356 - mae: 0.1436 - val_loss: 0.0338 - val_mae: 0.1401\n",
      "Epoch 73/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0355 - mae: 0.1439 - val_loss: 0.0336 - val_mae: 0.1404\n",
      "Epoch 74/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0348 - mae: 0.1428 - val_loss: 0.0337 - val_mae: 0.1393\n",
      "Epoch 75/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0334 - mae: 0.1369 - val_loss: 0.0333 - val_mae: 0.1384\n",
      "Epoch 76/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0361 - mae: 0.1455 - val_loss: 0.0344 - val_mae: 0.1396\n",
      "Epoch 77/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0364 - mae: 0.1483 - val_loss: 0.0332 - val_mae: 0.1372\n",
      "Epoch 78/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0350 - mae: 0.1439 - val_loss: 0.0333 - val_mae: 0.1376\n",
      "Epoch 79/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0344 - mae: 0.1392 - val_loss: 0.0337 - val_mae: 0.1409\n",
      "Epoch 80/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0346 - mae: 0.1423 - val_loss: 0.0340 - val_mae: 0.1402\n",
      "Epoch 81/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0334 - mae: 0.1395 - val_loss: 0.0334 - val_mae: 0.1391\n",
      "Epoch 82/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0337 - mae: 0.1388 - val_loss: 0.0335 - val_mae: 0.1398\n",
      "Epoch 83/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0349 - mae: 0.1433 - val_loss: 0.0342 - val_mae: 0.1412\n",
      "Epoch 84/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0361 - mae: 0.1448 - val_loss: 0.0335 - val_mae: 0.1402\n",
      "Epoch 85/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0355 - mae: 0.1446 - val_loss: 0.0333 - val_mae: 0.1392\n",
      "Epoch 86/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0364 - mae: 0.1453 - val_loss: 0.0343 - val_mae: 0.1425\n",
      "Epoch 87/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0352 - mae: 0.1436 - val_loss: 0.0333 - val_mae: 0.1396\n",
      "Epoch 88/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0340 - mae: 0.1399 - val_loss: 0.0338 - val_mae: 0.1401\n",
      "Epoch 89/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0357 - mae: 0.1451 - val_loss: 0.0330 - val_mae: 0.1384\n",
      "Epoch 90/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0364 - mae: 0.1477 - val_loss: 0.0332 - val_mae: 0.1382\n",
      "Epoch 91/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0356 - mae: 0.1430 - val_loss: 0.0339 - val_mae: 0.1414\n",
      "Epoch 92/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0348 - mae: 0.1427 - val_loss: 0.0336 - val_mae: 0.1397\n",
      "Epoch 93/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0363 - mae: 0.1453 - val_loss: 0.0329 - val_mae: 0.1390\n",
      "Epoch 94/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0355 - mae: 0.1444 - val_loss: 0.0332 - val_mae: 0.1389\n",
      "Epoch 95/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0358 - mae: 0.1460 - val_loss: 0.0331 - val_mae: 0.1393\n",
      "Epoch 96/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0332 - mae: 0.1408 - val_loss: 0.0340 - val_mae: 0.1412\n",
      "Epoch 97/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0365 - mae: 0.1456 - val_loss: 0.0331 - val_mae: 0.1398\n",
      "Epoch 98/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0344 - mae: 0.1416 - val_loss: 0.0326 - val_mae: 0.1381\n",
      "Epoch 99/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0354 - mae: 0.1443 - val_loss: 0.0333 - val_mae: 0.1405\n",
      "Epoch 100/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0360 - mae: 0.1462 - val_loss: 0.0328 - val_mae: 0.1406\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - loss: 0.0313 - mae: 0.1353\n",
      "---------------------------------------------------------\n",
      "K 4 FOLD\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elped\\AppData\\Local\\Temp\\ipykernel_13956\\4226922763.py:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[features] = scaler.fit_transform(x[features])\n",
      "c:\\Users\\elped\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.4349 - mae: 0.2041 - val_loss: 0.3075 - val_mae: 0.1854\n",
      "Epoch 2/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2807 - mae: 0.1863 - val_loss: 0.2010 - val_mae: 0.1796\n",
      "Epoch 3/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1853 - mae: 0.1807 - val_loss: 0.1334 - val_mae: 0.1724\n",
      "Epoch 4/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1241 - mae: 0.1722 - val_loss: 0.0924 - val_mae: 0.1670\n",
      "Epoch 5/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0902 - mae: 0.1723 - val_loss: 0.0688 - val_mae: 0.1636\n",
      "Epoch 6/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0702 - mae: 0.1704 - val_loss: 0.0551 - val_mae: 0.1601\n",
      "Epoch 7/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0554 - mae: 0.1612 - val_loss: 0.0471 - val_mae: 0.1563\n",
      "Epoch 8/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0502 - mae: 0.1587 - val_loss: 0.0432 - val_mae: 0.1524\n",
      "Epoch 9/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0461 - mae: 0.1577 - val_loss: 0.0410 - val_mae: 0.1519\n",
      "Epoch 10/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0435 - mae: 0.1542 - val_loss: 0.0394 - val_mae: 0.1498\n",
      "Epoch 11/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0426 - mae: 0.1535 - val_loss: 0.0390 - val_mae: 0.1498\n",
      "Epoch 12/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0413 - mae: 0.1514 - val_loss: 0.0382 - val_mae: 0.1486\n",
      "Epoch 13/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0410 - mae: 0.1509 - val_loss: 0.0378 - val_mae: 0.1474\n",
      "Epoch 14/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0411 - mae: 0.1507 - val_loss: 0.0374 - val_mae: 0.1468\n",
      "Epoch 15/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0408 - mae: 0.1525 - val_loss: 0.0373 - val_mae: 0.1469\n",
      "Epoch 16/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0411 - mae: 0.1543 - val_loss: 0.0373 - val_mae: 0.1476\n",
      "Epoch 17/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0413 - mae: 0.1557 - val_loss: 0.0370 - val_mae: 0.1456\n",
      "Epoch 18/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0404 - mae: 0.1519 - val_loss: 0.0369 - val_mae: 0.1452\n",
      "Epoch 19/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0392 - mae: 0.1472 - val_loss: 0.0362 - val_mae: 0.1444\n",
      "Epoch 20/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0401 - mae: 0.1513 - val_loss: 0.0361 - val_mae: 0.1443\n",
      "Epoch 21/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0389 - mae: 0.1485 - val_loss: 0.0366 - val_mae: 0.1453\n",
      "Epoch 22/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0409 - mae: 0.1535 - val_loss: 0.0364 - val_mae: 0.1437\n",
      "Epoch 23/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0384 - mae: 0.1468 - val_loss: 0.0358 - val_mae: 0.1426\n",
      "Epoch 24/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0388 - mae: 0.1479 - val_loss: 0.0359 - val_mae: 0.1440\n",
      "Epoch 25/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0391 - mae: 0.1482 - val_loss: 0.0357 - val_mae: 0.1438\n",
      "Epoch 26/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0389 - mae: 0.1476 - val_loss: 0.0357 - val_mae: 0.1457\n",
      "Epoch 27/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0397 - mae: 0.1511 - val_loss: 0.0351 - val_mae: 0.1423\n",
      "Epoch 28/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0402 - mae: 0.1533 - val_loss: 0.0354 - val_mae: 0.1428\n",
      "Epoch 29/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0379 - mae: 0.1469 - val_loss: 0.0359 - val_mae: 0.1447\n",
      "Epoch 30/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0392 - mae: 0.1497 - val_loss: 0.0357 - val_mae: 0.1426\n",
      "Epoch 31/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0376 - mae: 0.1460 - val_loss: 0.0350 - val_mae: 0.1424\n",
      "Epoch 32/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0395 - mae: 0.1498 - val_loss: 0.0353 - val_mae: 0.1423\n",
      "Epoch 33/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0379 - mae: 0.1450 - val_loss: 0.0351 - val_mae: 0.1430\n",
      "Epoch 34/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0377 - mae: 0.1455 - val_loss: 0.0351 - val_mae: 0.1417\n",
      "Epoch 35/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0400 - mae: 0.1525 - val_loss: 0.0348 - val_mae: 0.1414\n",
      "Epoch 36/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0381 - mae: 0.1488 - val_loss: 0.0346 - val_mae: 0.1425\n",
      "Epoch 37/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0385 - mae: 0.1489 - val_loss: 0.0356 - val_mae: 0.1445\n",
      "Epoch 38/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0383 - mae: 0.1475 - val_loss: 0.0349 - val_mae: 0.1435\n",
      "Epoch 39/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0386 - mae: 0.1486 - val_loss: 0.0340 - val_mae: 0.1405\n",
      "Epoch 40/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0396 - mae: 0.1520 - val_loss: 0.0347 - val_mae: 0.1424\n",
      "Epoch 41/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0378 - mae: 0.1467 - val_loss: 0.0344 - val_mae: 0.1419\n",
      "Epoch 42/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0367 - mae: 0.1454 - val_loss: 0.0346 - val_mae: 0.1425\n",
      "Epoch 43/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0369 - mae: 0.1455 - val_loss: 0.0344 - val_mae: 0.1407\n",
      "Epoch 44/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0380 - mae: 0.1471 - val_loss: 0.0342 - val_mae: 0.1403\n",
      "Epoch 45/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0380 - mae: 0.1466 - val_loss: 0.0343 - val_mae: 0.1407\n",
      "Epoch 46/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0360 - mae: 0.1441 - val_loss: 0.0337 - val_mae: 0.1406\n",
      "Epoch 47/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0375 - mae: 0.1506 - val_loss: 0.0342 - val_mae: 0.1410\n",
      "Epoch 48/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0370 - mae: 0.1464 - val_loss: 0.0342 - val_mae: 0.1421\n",
      "Epoch 49/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0389 - mae: 0.1517 - val_loss: 0.0341 - val_mae: 0.1408\n",
      "Epoch 50/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0375 - mae: 0.1465 - val_loss: 0.0339 - val_mae: 0.1412\n",
      "Epoch 51/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0369 - mae: 0.1458 - val_loss: 0.0339 - val_mae: 0.1416\n",
      "Epoch 52/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0362 - mae: 0.1443 - val_loss: 0.0335 - val_mae: 0.1408\n",
      "Epoch 53/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0350 - mae: 0.1393 - val_loss: 0.0340 - val_mae: 0.1412\n",
      "Epoch 54/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0362 - mae: 0.1435 - val_loss: 0.0337 - val_mae: 0.1404\n",
      "Epoch 55/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0351 - mae: 0.1416 - val_loss: 0.0338 - val_mae: 0.1414\n",
      "Epoch 56/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0377 - mae: 0.1484 - val_loss: 0.0339 - val_mae: 0.1403\n",
      "Epoch 57/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0364 - mae: 0.1451 - val_loss: 0.0332 - val_mae: 0.1396\n",
      "Epoch 58/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0358 - mae: 0.1434 - val_loss: 0.0335 - val_mae: 0.1404\n",
      "Epoch 59/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0373 - mae: 0.1474 - val_loss: 0.0342 - val_mae: 0.1414\n",
      "Epoch 60/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0375 - mae: 0.1488 - val_loss: 0.0336 - val_mae: 0.1396\n",
      "Epoch 61/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0362 - mae: 0.1435 - val_loss: 0.0347 - val_mae: 0.1421\n",
      "Epoch 62/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0370 - mae: 0.1468 - val_loss: 0.0329 - val_mae: 0.1391\n",
      "Epoch 63/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0368 - mae: 0.1479 - val_loss: 0.0332 - val_mae: 0.1399\n",
      "Epoch 64/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0367 - mae: 0.1452 - val_loss: 0.0337 - val_mae: 0.1404\n",
      "Epoch 65/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0359 - mae: 0.1437 - val_loss: 0.0333 - val_mae: 0.1409\n",
      "Epoch 66/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0360 - mae: 0.1438 - val_loss: 0.0334 - val_mae: 0.1405\n",
      "Epoch 67/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0348 - mae: 0.1416 - val_loss: 0.0334 - val_mae: 0.1404\n",
      "Epoch 68/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0376 - mae: 0.1483 - val_loss: 0.0336 - val_mae: 0.1410\n",
      "Epoch 69/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0366 - mae: 0.1474 - val_loss: 0.0334 - val_mae: 0.1401\n",
      "Epoch 70/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0372 - mae: 0.1469 - val_loss: 0.0335 - val_mae: 0.1419\n",
      "Epoch 71/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0355 - mae: 0.1446 - val_loss: 0.0330 - val_mae: 0.1404\n",
      "Epoch 72/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0362 - mae: 0.1445 - val_loss: 0.0338 - val_mae: 0.1408\n",
      "Epoch 73/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0384 - mae: 0.1511 - val_loss: 0.0328 - val_mae: 0.1389\n",
      "Epoch 74/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0365 - mae: 0.1444 - val_loss: 0.0331 - val_mae: 0.1405\n",
      "Epoch 75/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0358 - mae: 0.1443 - val_loss: 0.0331 - val_mae: 0.1401\n",
      "Epoch 76/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0350 - mae: 0.1432 - val_loss: 0.0333 - val_mae: 0.1395\n",
      "Epoch 77/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0362 - mae: 0.1465 - val_loss: 0.0326 - val_mae: 0.1388\n",
      "Epoch 78/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0352 - mae: 0.1434 - val_loss: 0.0325 - val_mae: 0.1381\n",
      "Epoch 79/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0365 - mae: 0.1461 - val_loss: 0.0332 - val_mae: 0.1394\n",
      "Epoch 80/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0352 - mae: 0.1419 - val_loss: 0.0332 - val_mae: 0.1400\n",
      "Epoch 81/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0347 - mae: 0.1423 - val_loss: 0.0324 - val_mae: 0.1383\n",
      "Epoch 82/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0344 - mae: 0.1409 - val_loss: 0.0338 - val_mae: 0.1409\n",
      "Epoch 83/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0365 - mae: 0.1461 - val_loss: 0.0326 - val_mae: 0.1392\n",
      "Epoch 84/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0359 - mae: 0.1453 - val_loss: 0.0331 - val_mae: 0.1402\n",
      "Epoch 85/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0345 - mae: 0.1427 - val_loss: 0.0331 - val_mae: 0.1393\n",
      "Epoch 86/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0364 - mae: 0.1460 - val_loss: 0.0327 - val_mae: 0.1399\n",
      "Epoch 87/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0350 - mae: 0.1430 - val_loss: 0.0324 - val_mae: 0.1375\n",
      "Epoch 88/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0357 - mae: 0.1450 - val_loss: 0.0324 - val_mae: 0.1386\n",
      "Epoch 89/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0355 - mae: 0.1449 - val_loss: 0.0324 - val_mae: 0.1387\n",
      "Epoch 90/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0349 - mae: 0.1427 - val_loss: 0.0328 - val_mae: 0.1385\n",
      "Epoch 91/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0346 - mae: 0.1408 - val_loss: 0.0327 - val_mae: 0.1391\n",
      "Epoch 92/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0351 - mae: 0.1442 - val_loss: 0.0324 - val_mae: 0.1380\n",
      "Epoch 93/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0374 - mae: 0.1475 - val_loss: 0.0337 - val_mae: 0.1392\n",
      "Epoch 94/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0345 - mae: 0.1393 - val_loss: 0.0319 - val_mae: 0.1370\n",
      "Epoch 95/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0358 - mae: 0.1450 - val_loss: 0.0320 - val_mae: 0.1379\n",
      "Epoch 96/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0342 - mae: 0.1394 - val_loss: 0.0326 - val_mae: 0.1395\n",
      "Epoch 97/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0354 - mae: 0.1424 - val_loss: 0.0322 - val_mae: 0.1375\n",
      "Epoch 98/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0341 - mae: 0.1400 - val_loss: 0.0322 - val_mae: 0.1364\n",
      "Epoch 99/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0332 - mae: 0.1377 - val_loss: 0.0325 - val_mae: 0.1390\n",
      "Epoch 100/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0350 - mae: 0.1431 - val_loss: 0.0320 - val_mae: 0.1379\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0305 - mae: 0.1342 \n"
     ]
    }
   ],
   "source": [
    "dizio_model_user = {} #in this dizio we store the model for each user\n",
    "dizio_accuracy = {}\n",
    "\n",
    "# DICTIONARY TO STORE SONG RECOMMENDATION PER USER\n",
    "reccomandations_songs_per_user={}\n",
    "\n",
    "#value of folder\n",
    "k = 5\n",
    "\n",
    "#loop creation user and model\n",
    "for i in range(0, len(merge_unique_numain_df['User'].unique())): #i indica lo user   \n",
    "    \n",
    "    print('---------------------------------------------------------')\n",
    "    print(f'USER {i}')\n",
    "    \n",
    "    #select user\n",
    "    mask_user = merge_unique_numain_df['User'] == i\n",
    "    #display(mask_user)\n",
    "    user_i_df = merge_unique_numain_df[mask_user]\n",
    "    #display(user_i_df) \n",
    "\n",
    "    kf = KFold(n_splits = k, shuffle= True, random_state= 42)\n",
    "    score_fold = []\n",
    "\n",
    "    loop = 0\n",
    "    for train_index, test_index in kf.split(user_i_df):\n",
    "\n",
    "        print('---------------------------------------------------------')\n",
    "        print(f'K {loop} FOLD') #print(f'K {} FOLD = test set')\n",
    "        loop = loop + 1\n",
    "\n",
    "        #return train and test\n",
    "        x_train,x_test,y_train,y_test = return_train_test_for_cross(train_index, test_index, user_i_df) #da modificare\n",
    "\n",
    "        #creation model for the specific user\n",
    "        model_user_i = create_model_user(x_train.shape[1])\n",
    "        \n",
    "        #fit the model with the different x, y train (for different user)\n",
    "        history_model_user_i = fit_model(model_user_i, x_train, y_train, x_test, y_test)\n",
    "\n",
    "        #y_hat = model_user_i.predict(x_test)\n",
    "\n",
    "        test_loss, test_mae = model_user_i.evaluate(x_test,y_test,verbose=1)\n",
    "        score_fold.append(test_mae)\n",
    "\n",
    "        \n",
    "    dizio_model_user[f\"User{i}\"] = {#'model_user_i' : model_user_i,\n",
    "                                    #'history_model_user_i': history_model_user_i,\n",
    "                                    #'x_train': x_train,\n",
    "                                    #'x_test': x_test,\n",
    "                                    #'y_train': y_train,\n",
    "                                    #'y_test': y_test,\n",
    "                                    #'y_hat': y_hat,\n",
    "                                    #'recommendations:': reccomandation_df\n",
    "                                    'score_fold': score_fold\n",
    "                                    } \n",
    "    #save accuracy \n",
    "    dizio_accuracy[f'User{i}'] = {\n",
    "        #'MAE' : mean_absolute_error(y_test, y_hat),\n",
    "        #'MSE' : mean_squared_error(y_test, y_hat)\n",
    "        'Mean MAE': np.mean(score_fold)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DISPLAY DICTIONARY ACCURAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'User0': {'Mean MAE': 0.14134439527988435},\n",
       " 'User1': {'Mean MAE': 0.13658384680747987},\n",
       " 'User2': {'Mean MAE': 0.10007672011852264},\n",
       " 'User3': {'Mean MAE': 0.1349403440952301},\n",
       " 'User4': {'Mean MAE': 0.1395527243614197}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dizio_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
